{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rrHhvw2fa0ax"
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, Sequential, layers\n",
    "from tensorflow.keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import utils\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oPpBkQH1a0az"
   },
   "outputs": [],
   "source": [
    "class DataLoader(object):\n",
    "    \"\"\"\n",
    "    class to load MNIST data\n",
    "    \"\"\"\n",
    "    def __init__(self, Xtrainpath, Ytrainpath, Xtestpath, Ytestpath):\n",
    "        self.Xtrainpath = Xtrainpath\n",
    "        self.Ytrainpath = Ytrainpath\n",
    "        self.Xtestpath = Xtestpath\n",
    "        self.Ytestpath = Ytestpath\n",
    "\n",
    "    @staticmethod\n",
    "    def get_images(f):\n",
    "        with gzip.GzipFile(fileobj=f) as bytefile:\n",
    "            magic = np.frombuffer(bytefile.read(4), dtype=np.dtype(np.uint32).newbyteorder('>'))[0]\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Invalid magic number {} for file {}.'.format(magic, f.name))\n",
    "            params = list()\n",
    "            for _ in range(3):\n",
    "                params.append(np.frombuffer(bytefile.read(4), dtype=np.dtype(np.uint32).newbyteorder('>'))[0])\n",
    "            buffer = bytefile.read(params[0] * params[1] * params[2])\n",
    "            images = np.frombuffer(buffer, dtype=np.uint8)\n",
    "            return images.reshape(params[0], params[1], params[2])\n",
    "\n",
    "    @staticmethod\n",
    "    def get_labels(f):\n",
    "        with gzip.GzipFile(fileobj=f) as bytefile:\n",
    "            magic = np.frombuffer(bytefile.read(4), dtype=np.dtype(np.uint32).newbyteorder('>'))[0]\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Invalid magic number {} for file {}.'.format(magic, f.name))\n",
    "            param = np.frombuffer(bytefile.read(4), dtype=np.dtype(np.uint32).newbyteorder('>'))[0]\n",
    "            buffer = bytefile.read(param)\n",
    "            labels = np.frombuffer(buffer, dtype=np.uint8)\n",
    "            return labels\n",
    "\n",
    "    def load_data(self):\n",
    "        with open(self.Xtrainpath, 'rb') as f:\n",
    "            Xtrain = self.get_images(f)\n",
    "        with open(self.Ytrainpath, 'rb') as f:\n",
    "            Ytrain = self.get_labels(f)\n",
    "        with open(self.Xtestpath, 'rb') as f:\n",
    "            Xtest = self.get_images(f)\n",
    "        with open(self.Ytestpath, 'rb') as f:\n",
    "            Ytest = self.get_labels(f)\n",
    "        return Xtrain, Ytrain, Xtest, Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzvWVA3pa0a0"
   },
   "outputs": [],
   "source": [
    "Xtrainpath_ = 'train-images-idx3-ubyte.gz'\n",
    "Ytrainpath_ = 'train-labels-idx1-ubyte.gz'\n",
    "Xtestpath_ = 't10k-images-idx3-ubyte.gz'\n",
    "Ytestpath_ = 't10k-labels-idx1-ubyte.gz'\n",
    "datax = DataLoader(Xtrainpath_, Ytrainpath_, Xtestpath_, Ytestpath_)\n",
    "Xtrain, Ytrain, Xtest, Ytest = datax.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ivk1i9yIa0a1"
   },
   "source": [
    "# Problem 1. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M15QtOWMa0a1"
   },
   "outputs": [],
   "source": [
    "def sig(z_value):\n",
    "    sig = 1/(1+np.exp(-z_value))\n",
    "    return sig\n",
    "##########################\n",
    "class logi:\n",
    "    def __init__(self, learning_rate=0.01, iter=90):\n",
    "        self.learning_rate  = learning_rate\n",
    "        self.acuy = []\n",
    "        self.iter = iter\n",
    "        self.eps = 1e-7\n",
    "        self.likelihoods = []\n",
    "\n",
    "    def predict(self, X):\n",
    "      z = np.dot(X, self.w)\n",
    "      prob = sig(z)\n",
    "      binary_pred = []\n",
    "      for i in prob:\n",
    "        if i > 0.5:\n",
    "            binary_pred.append(1)\n",
    "        else:\n",
    "            binary_pred.append(0)\n",
    "      return binary_pred\n",
    "\n",
    "    def likeli(self, y_true, y_pred):\n",
    "        likelihood = (y_true*np.log(y_pred)+(1-y_true)*np.log(1-y_pred))        \n",
    "        return np.mean(likelihood)\n",
    "\n",
    "    def accuracy(self, y,y_pred):\n",
    "      count=0\n",
    "      diff = y_pred - y\n",
    "      num = np.count_nonzero(diff==0)   \n",
    "      acuy = (num/len(y_pred))*100\n",
    "      return acuy\n",
    "\n",
    "    def fitting(self, X, y, xtest, ytest):\n",
    "        \n",
    "        self.w = np.zeros((X.shape[1]))\n",
    "        for i in range(self.iter):\n",
    "            z  = np.dot(X,self.w)\n",
    "            y_pred = sig(z)\n",
    "            grad =  np.dot((y-y_pred),X)\n",
    "            grad = grad.reshape(grad.shape[1])\n",
    "            self.w +=  self.learning_rate*grad\n",
    "            likelihood = self.likeli(y,y_pred)\n",
    "            self.likelihoods.append(likelihood)\n",
    "            y_pred = self.predict(xtest)\n",
    "            accuracy_point = self.accuracy(ytest, y_pred)\n",
    "            self.acuy.append(accuracy_point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "siRC2D5X08E0",
    "outputId": "3bc8a8c6-4fc9-4ae3-8459-fa760375503f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.06"
      ]
     },
     "execution_count": 122,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################\n",
    "##########################\n",
    "# data preprocessing\n",
    "X_train_logi = Xtrain.reshape(60000, -1)\n",
    "X_test_logi = Xtest.reshape(10000, -1)\n",
    "Y_train_logi = Ytrain\n",
    "Y_test_logi = Ytest\n",
    "X_train_norm = X_train_logi/255.0\n",
    "X_test_norm = X_test_logi/255.0\n",
    "########\n",
    "# 2 2 2 2 2\n",
    "Xtrain_flatten = np.reshape(Xtrain, (60000, 784)) / 255\n",
    "Xtest_flatten = np.reshape(Xtest, (10000, 784)) / 255\n",
    "Ytrain_logistic = (Ytrain > 0) * 1\n",
    "Ytest_logistic = (Ytest>0)*1\n",
    "\n",
    "Xtrainn_flatten = Xtrain_flatten[:1000]\n",
    "Ytrainn = Ytrain[:1000]\n",
    "Ytestt = Ytest[:200]\n",
    "# 2 2 2 2 2\n",
    "########\n",
    "X_train_T = X_train_norm.T\n",
    "X_test_T = X_test_norm.T\n",
    "Y_train_T = Y_train_logi.reshape(1, Y_train_logi.shape[0])\n",
    "Y_test_T = Y_test_logi.reshape(1, Y_test_logi.shape[0])\n",
    "Y_train_normal = np.where(Y_train_T == 0,1,0)\n",
    "Y_test_normal = np.where(Y_test_T == 0,1,0)\n",
    "##########################\n",
    "# data to be used\n",
    "xtrain = X_train_norm\n",
    "ytrain = Y_train_normal\n",
    "xtest = X_test_norm\n",
    "ytest = Y_test_normal\n",
    "# training and preidction\n",
    "model = logi(1/len(xtrain), 100)\n",
    "model.fitting(xtrain,ytrain,xtest,ytest)\n",
    "##########################\n",
    "#\n",
    "def pred(X):\n",
    "    z_value = np.dot(X, model.w)\n",
    "    prob = sig(z_value)\n",
    "    predd = []\n",
    "    for i in prob:\n",
    "        if i > 0.5:\n",
    "            predd.append(1)\n",
    "        if i <= 0.5:\n",
    "            predd.append(0)\n",
    "    return predd\n",
    "y_pred = pred(xtest)\n",
    "##########################\n",
    "def getacuy(y,pred):\n",
    "    count=0\n",
    "    diff = pred - y\n",
    "    num = np.count_nonzero(diff==0)   \n",
    "    accuracy = (num/len(pred))*100\n",
    "    return accuracy\n",
    "##########################\n",
    "getacuy(ytest,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "arvIdzEl08HN",
    "outputId": "ffedcf4c-2788-4b0c-a64a-1520fdea239e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy curve')"
      ]
     },
     "execution_count": 123,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEICAYAAABcVE8dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZxcV33n/c+3uqs3La3diyxZBgkvccY2CAcebDDgEEMIDiQBEwYMATzJkGCYmRDzQBLCC+YxM0nwk4FJYrDNEhazGuEYYwMGkwkYS4kx8r5gWZu1q7X0Vstv/rinuqtb3ZJa3a1q1f2+X6pX3/2eU1f9rdPn3rpXEYGZmTW/QqMLYGZmx4cD38wsJxz4ZmY54cA3M8sJB76ZWU448M3McsKBbyc8Sf8g6c/T8CWSNh3DNkasJ+kBSZek4Q9J+qcpK/D4ZVghKSS1Tve+LJ/8H8smTdJTwDsi4nvTuI9LgH+KiNNGz4uIP5zq/UXEr0z1Ns0azS18sxxRxr/3OeUDb9NGUruk6yRtSa/rJLXXzX+fpK1p3jtSd8bKY9jPZyR9ZJx575b0oKTTUnn+WtLTkralrqDOcdZ7StKldZPaJH1O0v7U3bO6btmzJf1Q0t407zV187rTejskbZD0wVrgSmpJ5dkp6UngN49Qz2WSvpG2tUvSJ9L0EV1Oo7uGUtk+Kun/AL3An0paO2rb75W0Jg0f9ftkJxYHvk2nDwAvAM4HzgMuBD4IIOky4L8AlwIrgUumeueS/gJ4K/CSiNgEXAs8J5VnJbAU+Iuj3NxrgC8D84A1QC1si8C3gTuAJcCfAF+QdGZa738B3cCzgJcAbwHelua9E3g1cAGwGvjdw9SlBbgV2ACsSGX/8lGWHeDNwFXAHOAfgDMlraqb//vAF9PwZN4nm8Ec+Dad3gR8OCK2R8QO4K/Iggfg9cBNEfFARPQCH5rC/UrS3wKvAF4aETskiSzw3hsRuyNiP/DfgSuOcpv/EhG3RUQF+DzZBxhkH2izgWsjYjAifkAWzG9MIX0F8P6I2B8RTwF/w8j34LqI2BgRu4H/7zD7vxA4FfjTiDgYEf0R8S9HWXaAz6T3uhwRPcC3gDcCpOA/C1gzBe+TzWA+aWvT6VSyFmnNhjStNq++W2FjbUDScuDB2nhEzJ7gfueRhdYbUrgBLAa6gHVZpmW7AlqOcpvP1A33Ah2py+RUYGNEVOvmbyBrFS8Cihz6HixNw6dSV+9Ry422DNgQEeWjLO9oG0eNf5Hsw+fDZK37WyKiV9ISJvc+2QzmFr5Npy3A6XXjy9M0gK1A/RU3y2oDEfF0RMyuvY5hv3vIukpukvSiNG0n0Af8SkTMS6/uY9x+vS3AslEnQpcDm9M+Sxz6HmxOw1upq3eaN56NwPJxLtk8SBbSNSePsczo2+LeCSyWdD5ZS7/WnTNd75PNAA58mypFSR11r1bgS8AHJS2WtIisH7h2cvErwNvSCc8u4M+PZiej9tGhumZovYj4IVmX0jckXZha4J8CPp5asUhaKuk3JlNp4B6yFv/7JBXT5aO/BXw5df98BfiopDmSTic7b1H/Hrw7nVCeD1xzmP38jOwD4lpJs1Ldax9m9wEvlrRcUjfw/iMVOiJKwFeB/wksIPsAYBrfJ5sBHPg2VW4jaxnWXh8CPkLWbXM/8Avg39I0IuI7wN8BdwGPAz9N2xk4zD6WjtpHH/Ds8RaOiDuBPwC+Lem5wJ/V9iVpH/A94Mzx1j8aETFIFvCvJGsd/2/gLRHxcFrkT8ha4E8C/0LWkr4xzfsU8F3g52TvzTcOs59K2s9K4GlgE/CGunreTPY+ryM7h3A0vkh20vyro7qKpvx9splBfgCKzQSSzgbWA+2T6Kc2s8NwC98aRtJr0zXf84GPAd922JtNHwe+NdJ/ArYDTwAV4I8aWxyz5uYuHTOznJiSFr6kyyQ9IulxSYdcaZD+bL85zb9H0oqp2K+ZmR29SX/xKn2b8JPAr5NdOXCvpDUR8WDdYm8H9kTESklXkPXXvuFw2120aFGsWLFissUzM8uVdevW7YyIxWPNm4pv2l4IPB4RTwJI+jJwOXXflEzjH0rDXwM+IUlxmP6kFStWsHbt2vFmm5nZGCSN+43tqejSWcrIr21vYvir44csk67C6AEWjt6QpKskrZW0dseOHVNQNDMzq5lRV+lExPURsToiVi9ePOZfJGZmdoymoktnMyPvB3Iaw/cKGb3MpvSV+25g1xTs22aYiKAaUKkG1ai9yH5W64YjqFaHh2PEOsPbqV82GJ4WYywTQ8PZvIi0TtpP1JWvtuzwtNr6aV2Gt1GN4X2T5lWrtWWy7cDobWbrRBy6nWze8LbGWi/9q6vHyG3W3utD9pXGGdr3ofMO2f7Q9JHb5ZD9jbWftGDdNuq3WZtb33s78r2pLRMjlq8NxKhtjyjfqOkcMr1u3VHbHqs8teH6WtWWi7qVD5let51D6jKq07p+vZH7Grn/c5d2c+Nbn89Um4rAvxdYJekMsmC/guzue/XWAFcCPyG75/cPDtd/36wiglIlGChXGCxXGShXGSxXGaxUh8ZLleHXYDkoVaqUq1VK5aBUrVIqVylVsuFyJShXqpSrkb0qkS1bCSrVbHp1xLy66ZFNq0Zt+qhXCuhKCtvR0yrVkfOrkQ3n76hOjpTdirIgpeFsgtK8QrpVUDYulEaGxjVyntICqtuGGLnc0H7HmFd/f8xDtzu8PKOWH542cpuMKD91wxpRvhH7rC0rEIVDtl2/v7HKoXGmM2rd8etVt22GNzji/Ru1nfqyDE0bY9v1y4+oe/32BKfNr78X3tSZdOBHRFnSH5PdE6QFuDEiHpD0YWBtRKwBbgA+L+lxYDcnwL21I4J9/WX29g6yv7/Mvr4S+/rLHBgoc6C/xMHBCgcHytlrsELfYIW+UoXewTJ9pSoDpWy8v1Shv1RloFxhoFydlkAstoiWgmgtFGhtST8LSsOiUBDFQoGWgoZeQ9NbCnQU03QNzy/UjRckWgrUDQ//rJ9fUP18KNTm1YJJokXZdlBt+9l/+kJtHQ0PizQ/bbc2n9pyqq2bApNs27Vf7try0shArV9+eJ5GBC8wohyFoQBK0+qWZyg8R+6nPlTr16m9F2bH25TcDz8ibiO7eVb9tL+oG+4Hfm8q9jUd1m/u4a6Ht/PLnQd5cudBtvb0sfvgIKXK4dO5tSBmtbfS1dZCZ1tL9rPYQndnkY457XQUs/GOYoH2YgsdrQXa0quj2EJby/D46OHWltq0LMCLrQWKBdHakoV6W0sW6lnAOTzM7Mhy/wCUHz6ynas+v47BcpVTujt41uJZvOQ5i1k4u52Fs9qY19VGd2eRuR2tzO5oZW5HkVntrcxqb6G91c+EMLMTR64Dvxb2KxfP5nNvv5BFs9uPvJKZ2Qkqt4H/w0e2c9Xn1rHqpNl84R2/xryutkYXycxsWs2o6/CPpw9/+0FWLOpy2JtZbuQ28J/Z18/FqxY77M0sN3IZ+P2lCr2DFRbMctibWX7kMvB3HRwEYKED38xyJJeBv/tAFvhu4ZtZnuQy8HcdHABg4WwHvpnlRy4Df3fq0pnvE7ZmliO5DvyFs/xFKzPLj1wG/q6Dg7QWxNzO3H7vzMxyKJeBv/vAIPNntfmmY2aWK7kM/F0HB31JppnlTi4Df0/voC/JNLPcyWXg7z7owDez/Mll4O86MOAuHTPLndwFfqlSZV9/mQW+JNPMciZ3gb8nXYO/wN+yNbOcyV3g+8ZpZpZXuQv82rdsfdLWzPImd4HvFr6Z5VXuAn/3gexOmW7hm1ne5C/wDw4i4Ucbmlnu5C7wdx0cZH5XGy0F30fHzPJlUoEvaYGkOyU9ln7OH2e5iqT70mvNZPY5Wf6WrZnl1WRb+NcA34+IVcD30/hY+iLi/PR6zST3OSm7HPhmllOTDfzLgc+m4c8Cvz3J7U273QcHWeD+ezPLockG/kkRsTUNPwOcNM5yHZLWSvqppHE/FCRdlZZbu2PHjkkWbWy7Dw76W7ZmlktHfOSTpO8BJ48x6wP1IxERkmKczZweEZslPQv4gaRfRMQToxeKiOuB6wFWr1493raOWaUa7On1vfDNLJ+OGPgRcel48yRtk3RKRGyVdAqwfZxtbE4/n5T0Q+AC4JDAn257eweJ8DX4ZpZPk+3SWQNcmYavBL41egFJ8yW1p+FFwIuABye532Oyp9e3VTCz/Jps4F8L/Lqkx4BL0ziSVkv6dFrmbGCtpJ8DdwHXRkRDAn/XgdptFXxrZDPLnyN26RxOROwCXj7G9LXAO9LwvwK/Opn9TBXfOM3M8ixX37QdunGar9IxsxzKVeDXWvjzfR2+meVQ7gJ/Tkcrba25qraZGZCzwN910Nfgm1l+5Srwdx8c8AlbM8utXAX+rgODLPAlmWaWU00X+P2lCj98ZDsbd/ceMm+3u3TMLMeaLvAPDJR560338oOHR97lISLY21ti3qxig0pmZtZYTRf43Z1ZoO/tLY2Y3l+qMlipDs03M8ubpgv8YkuBWW0t9PSNDPzauAPfzPKq6QIfslDf2zc4Ylot8Od1ug/fzPKpOQO/q419o1r4e9OdMt3CN7O8as7A72x1l46Z2ShNGfjzOtsOOWnrwDezvGvKwO/uLI7fwu9y4JtZPjVn4HeNHfgSzGmf1CMAzMxOWM0Z+J1FBspV+kuVoWk9fSXmdhQpFNTAkpmZNU7TBj4wopXf01dy/72Z5VpTBv68rkO/bevAN7O8a8rAH6+FP88nbM0sx/IT+L0l5rqFb2Y51pSBX7t9Qu3bteAuHTOzpgz80S38iHDgm1nuNWXgz+loRRoO/N7BCuVqOPDNLNeaMvALBTG3Y/jLV3uH7pTpwDez/JpU4Ev6PUkPSKpKWn2Y5S6T9IikxyVdM5l9Hq15dd+27en1fXTMzCbbwl8PvA64e7wFJLUAnwReCZwDvFHSOZPc7xF1dxaHrsP3jdPMzGBSN5aJiIcApMPeruBC4PGIeDIt+2XgcuDByez7SOpvoFb76csyzSzPjkcf/lJgY934pjRtWnV3FocegtKTnn7lL16ZWZ4dsYUv6XvAyWPM+kBEfGsqCyPpKuAqgOXLl09qW9ljDt2lY2ZWc8TAj4hLJ7mPzcCyuvHT0rSx9nU9cD3A6tWrYzI7rZ20rV2D31IQs31rZDPLsePRpXMvsErSGZLagCuANdO90+7OIpVqcGCgnG6N3Hqkcw1mZk1tspdlvlbSJuCFwD9L+m6afqqk2wAiogz8MfBd4CHgKxHxwOSKfWT137bt6Su7O8fMcm+yV+l8E/jmGNO3AK+qG78NuG0y+5qo7nQ/nZ6+Ent7B+nuajueuzczm3Ga8pu2UNfC7y2xz/fRMTNr3sCvXYKZdek48M3MmjbwR/bhl+ju9BU6ZpZvTRv4tRb+nt4s8Gv3yDczy6umDfzOYgvFFrF5by/V8JeuzMyaNvAl0d1Z5OndfYAD38ysaQMfspDfuLsX8I3TzMyaPvA37ekdGjYzy7OmDvx5XW2UKpGGHfhmlm9NHfj1rXq38M0s7xz4ZmY5kYvAby2IrraWBpfGzKyxchH43Z1F3xrZzHKvqQO/dqK22ydszcyaO/DrW/hmZnnX1IE/1MJ34JuZNXfgu4VvZjasqQO/djuFeQ58M7PmDvzuziItBbFgVnuji2Jm1nBN/VSQ9tYWPvO253POKXMbXRQzs4Zr6sAHuHjV4kYXwcxsRmjqLh0zMxvmwDczywlFRKPLMCZJO4ANE1xtEbBzGoozk+WxzpDPeuexzpDPek+mzqdHxJh92TM28I+FpLURsbrR5Tie8lhnyGe981hnyGe9p6vO7tIxM8sJB76ZWU40W+Bf3+gCNEAe6wz5rHce6wz5rPe01Lmp+vDNzGx8zdbCtxOYpB9K2iPJ98IwmwYOfJsRJK0ALgYCeM1x3vcJ9Y3zE628NnM0ReBLukzSI5Iel3RNo8szXSQtk3SXpAclPSDp6jR9gaQ7JT2Wfs5vdFmPwVuAnwKfAa6sn5Hq/Q1JJUmDkj4h6QxJ90jaLmmfpP3pfXluWickrazbxmckfSQNXyJpk6Q/k/QMcJOk+ZJulbQj/ZVxq6TT6tZfIOkmSVvS/FvS9PWSfqtuuaKknZIuGKuSki6XdF8q8xOSLkvTn5J0ad1y10raIOnh9P86JL1bUh+wP+3jT0dt++eSXpeGz0r/F3an343XH8tBOd4kvTf9314v6UuSOuqO9eOSbpbU1uhyTpakG9P/3fV108b8PVbm71L976/9Hz8mEXFCv4AW4AngWUAb8HPgnEaXa5rqegrw3DQ8B3gUOAf4H8A1afo1wMcaXdZjqNvjwH8GngeUgJPqju/PgR8BNwO3ARcBXwE+DmwGvg78EbCS7EsnkP2lsLJu+58BPpKGLwHKwMeAdqATWAj8DtCV3tuvArfUrf/Paf/zgSLwkjT9fcDNdctdDvxinDpeCPQAv07W2FoKnJXmPQVcWrfsfcBP0vCqVJ/1wJ+n8t4MbKpb/hxgb6rPLGAj8Day+2VdQPYlnhn9e5Hej18CnWn8K8Bb088r0rR/AP6o0WWdgrq+GHgusL5u2pi/x8CrgO8AAl4A3HPM+210xafgjXsh8N268fcD7290uY5T3b+VwuMR4JQ07RTgkUaXbYL1uCiF/KI0/jDw3rrjuwv4AfAy4Nb0H38ncAdw9ej/A2m9IwX+INBxmDKdD+ype0+rwPwxljsV2A/MTeNfA943zjb/Efj4OPOGAh/oBvYA/5TGV6T6PFl3nFemMp2exj8K3JiG3wD8eIx9/2Wjj/UR/h8sTR9UC9IH1a3Ab6Rj3Vr3/+G7jSznFNZ3xajAH/P3OB27N4613ERfzdClU/tPUrMpTWtqqc/7AuAestbw1jTrGeCkBhXrWF0J3BERta+Sf5Hhbp1lZAH/p2QBB1lrfC9wGtlfd8dyzHdERH9tRFKXpH9M3Sj7gLuBeZJaUhl2R8Se0RuJiC3A/wF+R9I84JXAF8bZ57JU3iM5A+gFXijp34Fr0/QFdcf5CbK/Uq5I42+s2+/pwK9J2lt7AW8CTj6KfTdMRGwG/hp4GthK9tfQOmBvRJTTYs38+z3e7/GUZVwzBH7uSJpN1o3xnojYVz8vsibACXOtraRO4PXASyQ9k/rU3wucJ+k8YDnQQdatM9pG4NnjbLqXrHumZnTYjX6P/itwJvBrETGX7E9uyD5sNgILUqCP5bPAfwR+j6wbZvM4yx2uvAfryttK1sJ7NCIuSHUZWfjsOA8Cb5T0QrL36K66/fwoIubVvWZHxB+Ns+8ZIfVZX072gXcqWdfUZQ0tVINM1+9xMwT+ZrKWU81paVpTklQkC/svRMQ30uRtkk5J808BtjeqfMfgt4EKWR/0+el1NvBjshO5i8gCcBdZv/XLyFqy84Abgf8GvBzYLGmlpNPTdu8Dfl9SSzox+pIjlGMO0AfslbQA+MvajNTq+g7wv9PJ3aKkF9etewtZf+zVwOcOs48bgLdJermkgqSlks6qK+8V6fguJPtl35XmfSf9HH2ct5C15j9Mdh6h9hfQrcBzJL05lbUo6fmSzj7Ce9BolwK/jIgdEVECvgG8iOwvrdqVSc38+z3e7/GUZVwzBP69wKp0Jr+N7E/cNQ0u07SQJLLQeCgi/rZu1hqGu0CuJOvbP1FcCdwUEU9HxDO1F/AJsm6ID5L1V99F1optJevDvIus9f1R4DqyQL+FrP8XsvD9LbKunzeleYdzHdnJ0J1kVwvdPmr+m8nOMzxM9ov4ntqMiOgj+xA+gyykxhQRPyM7kfpxsu6KH5EFNmQnY59N1nf/brI/6WuPantR+vltRh7nW9L+LiXrBqvtZz/wCrLfhS1pW7UT1DPZ08ALUveayD7IHyQ71r+bljnR/n9PxHi/x2uAt6SrdV4A9NR1/UxMo09cTNHJj1eRXbHyBPCBRpdnGut5EVnL736yFuF9qe4Lge8DjwHfI+vrbXh5p6H+lwC3puFnAT8ju7rnq0B7g8v2F6STrFO0vfOBtelY30J2dVDTH2fgr8g+VNcDnyf7kJpRx3qK6vklsvMUJbI++bePd3zJGjafTPn2C2D1se7Xt1Ywm6TUBfTvwJsj4u5Gl8dsPM3QpWPWMJLeSXaS9DsOe5vp3MI3M8sJt/DNzHJixt6EadGiRbFixYpGF8PM7ISybt26nTHOM21nbOCvWLGCtWvXNroYZmYnFEkbxpvnLh0zs5yYsS18M2tOEUF/qcqBgfKRFwbaWgt0FAu0tRQoV4P+UoWBcnXo50CpSnWci09KlerQsuMtMxPN7SiyesWCIy84QQ58s2lSrmShVk05ExEMVrKAGiiPH1Lj6ekr8fTuXjbu7mVvb2loeiWGQ7BUrh5mC5lqwGAlC8HBcnX4hi0RDJSrDJZHli9iODgHyhUq1SOXu6Ug2ltbaG8tUGwpIGXTS5Uq+/rKDFaOXM48O3/ZPG5514uOvOAEOfDtuBtMwdHe2kKxJUuC3sEKPX0lDta1+kqVYMeBAbbt62fXgUH6ShUGUrDVK7aIjmILbS0F+krZdnr6SkPBFAHlapX+0qGBVa4GA6Uq/eUK5crYQVYoMBRerS0FBlJQji5HTTWC/f3lo27BTlRB0N1ZRClFC8rK11HMwvVIJNHeWqC9tcCcjlYKtTSm1prO3sv6TRVb0vTWAq0FjbHVkWrv60C5Qqku3FsKBbo7i3R3Fpnd3gI6wrbSh1Dt1daSPkiKBTrSz/bWwog61Cu2FNIyLUdV7pmiq61lWrbrwDcAegfL9A1W6E9//u5Lobmvv0z/YIWBcmUoMPtL2TK7ewfZsX+A7fsG6C9XhrbV3lpgbkcxhRLs6ysPhXBPX4m+0vCyBUFBonwUrcbattvqfsEjglIl6C9XiIDWgujuLDK3szj0YQLpF7+1kIJxeHpLQUPB0VoYOyyrEQym96VUDdrntNNRzD6sxKEhIsGcjla6O4vM6SiOCJrh7okWjiKbR5jV3sryBV2cOq/zqILdbDQHfpOL1EKq2ddf4t827GXdht3cv6mHbfv62b5/gN7BymG2MlJB0FFsYX5XG4vntHP6wq4RLZL+UpWevhJbe/oJoLuzlRWLuoY+BLo7i3QUWxgoV4a6DmrzutpbqeVji8TiOe0smdPBojltdBZbhlq1Y9WzVIkshI/UajTLKQf+CWr3wUEe27afLT199PSW6Okrs69/uBW9t3eQbfsG2L6/n/7SoV0Pba0FfuXUufzqafNYMqedRbPbmdXeMtTandtRZG5n1krtbGsd6gLoKGZ/Gs+0UJVEW+vMKpPZTOPAn6Gq1eCXuw6yfnMP6zf3sLWnP+ti6SuxeW8fOw8MHrJOV1vLUAt6XleRC5ZnYT6vq22oC6S9tcB5y+Zx7tK5tLdOTz+hmc1MDvwZoHewzBPbD/Lotv08sGUf67f08OCWfUMn/dpaC5w2r5O5nUXmdbVx5slzeM5Jc1i5ZDbLFnRlfdYdRdpa3a9rZuNz4B9HEcFDW/fz48d28OSOgzy9u5end/eyeW/f0DIdxQJnnzKX1z13Keee2s25S7tZddJsn6Qzs0lz4E+znt4SP3lyJz9+bCd3PbydLT3Zc7MXzW5n+YJOVq+YzxsWL2PVktmsOmk2KxbOotXhbmbTwIE/BQbLVR7dtp9fbO7hsW0H2Ns7SE9fiWf29fPg1n1EwKy2Fi5atYj3XPocLjlrMUvmdDS62GaWMw78YxQRrNuwh5v+9SnufGDb0DcHu9paWDCrje7OIgtmtXH1y1dx0cpFnLdsnrtlzKyhHPgT9MudB/n+Q9u45b7NrN+8j7kdrfz+ry3n+SsWcO7SuSxf0DXjLlk0MwMH/lHZtKeXr9y7kVvv38qTOw8CcNbJc/joa8/ltRcspavNb6OZzXwTSipJVwPvJHuK+qci4jpJNwNnpkXmAXsj4vwx1n0K2A9UgHJErJ5MwadbtRrc9ch2PveTDdz92A4AXvTsRVz5/6zgZWctYdmCrgaX0MxsYo468CWdSxb2FwKDwO2Sbo2IN9Qt8zdAz2E289KI2HmshT0eBstV1vx8C9ff/QSPbjvAyXM7+JOXruT1z1/GafMd8mZ24ppIC/9s4J6I6AWQ9CPgdcD/SOMCXg+8bKoLeTzs7y/x5Z9t5IZ/+SXP7OvnrJPncN0bzuc3/8MpPtlqZk1hIoG/HviopIVAH/AqoP4ZhBcD2yLisXHWD+AOSQH8Y0RcP3oBSVcBVwEsX758AkU7dj19JT5195N89idPsb+/zAuftZBrf+dXeclzFvvkq5k1laMO/Ih4SNLHgDuAg8B9ZP3xNW8EvnSYTVwUEZslLQHulPRwRNw9ah/XA9cDrF69elofT9M3WOEz//oU//CjJ+jpK/HKc0/mD1/ybM5bNm86d2tm1jATOmkbETcANwBI+u/ApjTcSta987zDrLs5/dwu6Ztk5wLuHm/56fb2z97Lvz6xi5eeuZj/9htn8iundjeqKGZmx8VEr9JZkgJ7OVnAvyDNuhR4OCI2jbPeLKAQEfvT8CuAD0+i3JMyWK7ys1/u5u0XncGfv/qcRhXDzOy4mugF5F9Pffgl4F0RsTdNv4JR3TmSTgU+HRGvAk4Cvpn6xFuBL0bE7ZMq+SRs2HWQcjX41aVu1ZtZfky0S+ficaa/dYxpW8hO7BIRTwLnHUP5psVj2w8AsHLJ7AaXxMzs+Mnl9YaPbtuP5MA3s3zJZeA/tv0Ayxd00VH0E5/MLD9yGfiPbzvAKrfuzSxnchf45UqVJ3ceYOWSOY0uipnZcZW7wN+wu5dSJdzCN7PcyV3gP7Ytu0LnOSe5hW9m+ZLDwN8PwLOXzGpwSczMjq/8Bf72A5w2v9MPLTGz3Mll4Lv/3szyKFeBX6kGT+w4wCr335tZDuUq8Dfu7mWwXPU3bM0sl3IV+LV76PgKHTPLo1wF/qPpCh238M0sj3IV+I9vP8Cp3R3MbvcVOmaWP7kK/Me272elu3PMLKdyFfgbdvbyrEX+wpWZ5dOEAl/S1ZLWS3pA0nvStA9J2izpvvR61TjrXibpEUmPS7pmKgo/EZVqsH+gTHdn8Xjv2sxsRjjqzmxJ5wLvJHv4+CBwux3y0OcAAAn+SURBVKRb0+yPR8RfH2bdFuCTwK+TPfj8XklrIuLBYy75BB0YKAMwp8P992aWTxNp4Z8N3BMRvRFRBn5E9iDzo3Eh8HhEPBkRg8CXgcsnVtTJ2d9fAhz4ZpZfEwn89cDFkhZK6iJ7Xu2yNO+PJd0v6UZJ88dYdymwsW58U5p23Ozvr7Xw3aVjZvl01IEfEQ8BHwPuAG4H7gMqwN8DzwbOB7YCf3OshZF0laS1ktbu2LHjWDczpuHAdwvfzPJpQidtI+KGiHheRLwY2AM8GhHbIqISEVXgU2TdN6NtZvivAYDT0rTR278+IlZHxOrFixdPpGhHNNyl4xa+meXTRK/SWZJ+Lifrv/+ipFPqFnktWdfPaPcCqySdIakNuAJYc2xFPjY+aWtmeTfR9Pu6pIVACXhXROyV9L8knQ8E8BTwnwAknQp8OiJeFRFlSX8MfBdoAW6MiAemrBZHYZ+7dMws5yaUfhFx8RjT3jzOslvITuzWxm8DbptoAafKUJdOu7t0zCyfcvNN2/39ZVoLoqOYmyqbmY2Qm/Tb319iTkcrkhpdFDOzhshR4Jd9hY6Z5VrOAt8nbM0sv3IT+Acc+GaWc7kJ/H39JXfpmFmu5Sbw3aVjZnmXo8AvMcePNjSzHMtF4EcEBwZ8lY6Z5VsuAv/gYIVq+LYKZpZvuQh83ynTzCwngX/AN04zM8tH4PtOmWZmOQl8d+mYmeUm8N3CNzNz4JuZ5UROAt9dOmZmE32m7dWS1kt6QNJ70rT/KelhSfdL+qakeeOs+5SkX0i6T9LaqSj80drfX6YgmNXWcjx3a2Y2oxx14Es6F3gncCFwHvBqSSuBO4FzI+I/AI8C7z/MZl4aEedHxOpJlHnCDgyUmd3uh5+YWb5NpIV/NnBPRPRGRBn4EfC6iLgjjQP8FDhtqgs5Wb5TppnZxAJ/PXCxpIWSusgeUL5s1DJ/AHxnnPUDuEPSOklXjbWApKskrZW0dseOHRMo2uH5TplmZnDUKRgRD0n6GHAHcBC4D6jU5kv6AFAGvjDOJi6KiM2SlgB3Sno4Iu4etY/rgesBVq9eHROqyWHUnmdrZpZnEzppGxE3RMTzIuLFwB6yPnskvRV4NfCmiBgzqCNic/q5Hfgm2bmA48LPszUzm/hVOkvSz+XA64AvSroMeB/wmojoHWe9WZLm1IaBV5B1ER0X7tIxM5tAl07ydUkLgRLwrojYK+kTQDtZNw3ATyPiDyWdCnw6Il4FnAR8M81vBb4YEbdPWS2OwF06ZmYTDPyIuHiMaSvHWXYL2YldIuJJsks5jzs//MTMLNP037QdKFcpVcItfDPLvaYP/H2+rYKZGZCDwB+6cZofYG5mOZefwHeXjpnlXA4C3106ZmaQi8B3C9/MDHIQ+H6AuZlZpukD31fpmJllmj7wa106s32VjpnlXC4Cf1ZbCy0FP/zEzPItB4Hvh5+YmUEuAt93yjQzgzwE/oDvlGlmBjkI/AN++ImZGZCDwHeXjplZpukDf59b+GZmwAQfgCLpauCdgIBPRcR1khYANwMrgKeA10fEnjHWvRL4YBr9SER8dhLlHlffYIUv3LNhaHxfn/vwzcxgAoEv6VyysL8QGARul3QrcBXw/Yi4VtI1wDXAn41adwHwl8BqIIB1ktaM9cEwWb2DZT7yzw+NmLZyyeyp3o2Z2QlnIk3fs4F7ag8ql/QjsgeZXw5ckpb5LPBDRgU+8BvAnRGxO617J3AZ8KVjLfh45ne1cf+HXjE0XpD8LVszMybWh78euFjSQkldZM+rXQacFBFb0zLPkD2wfLSlwMa68U1p2giSrpK0VtLaHTt2TKBowwoFMbejOPRy2JuZZY468CPiIeBjwB3A7cB9QGXUMkHWZXNMIuL6iFgdEasXL158rJsxM7MxTOgqnYi4ISKeFxEvBvYAjwLbJJ0CkH5uH2PVzWR/DdSclqaZmdlxoqxRfpQLS0siYruk5WQt/RcAHwB21Z20XRAR7xu13gJgHfDcNOnfgOfV+vTH2dcOYMN488exCNg5wXVOdHmsM+Sz3nmsM+Sz3pOp8+kRMWYXyUQD/8fAQqAE/JeI+L6khcBXgOVkAf36iNgtaTXwhxHxjrTuHwD/b9rURyPipmOszOHKtzYiVk/1dmeyPNYZ8lnvPNYZ8lnv6arzhM5oRsTFY0zbBbx8jOlrgXfUjd8I3HgMZTQzsynQ9N+0NTOzTLMF/vWNLkAD5LHOkM9657HOkM96T0udJ9SHb2ZmJ65ma+Gbmdk4HPhmZjnRFIEv6TJJj0h6PH0XoClJWibpLkkPSnog3b0USQsk3SnpsfRzfqPLOtUktUj693TDPiSdIemedMxvltTW6DJOJUnzJH1N0sOSHpL0wpwc5/em/9vrJX1JUkczHmtJN0raLml93bQxj68yf5fqf7+k546/5cM74QNfUgvwSeCVwDnAGyWd09hSTZsy8F8j4hyyL729K9X1GrI7lq4Cvp/Gm83VQP1tUD8GfDwiVpJ96/vtDSnV9Pn/gdsj4izgPLK6N/VxlrQUeDewOiLOBVqAK2jOY/0ZshtI1hvv+L4SWJVeVwF/f6w7PeEDn+x2zY9HxJMRMQh8mewOnk0nIrZGxL+l4f1kIbCUrL615wt8FvjtxpRwekg6DfhN4NNpXMDLgK+lRZqqzpK6gRcDNwBExGBE7KXJj3PSCnRKagW6gK004bGOiLuB0XcaGO/4Xg58LjI/BebVbmczUc0Q+Ed1J85mI2kFcAFwD0d3x9IT2XXA+4BqGl8I7I2IchpvtmN+BrADuCl1Y31a0iya/DhHxGbgr4GnyYK+h+yWLM18rOuNd3ynLOOaIfBzR9Js4OvAeyJiX/28yd6xdKaR9Gpge0Ssa3RZjqNWsvtO/X1EXAAcZFT3TbMdZ4DUZ3052QfeqcAsDu32yIXpOr7NEPi5uhOnpCJZ2H8hIr6RJh/NHUtPVC8CXiPpKbLuupeR9W/PS3/2Q/Md803Apoi4J41/jewDoJmPM8ClwC8jYkdElIBvkB3/Zj7W9cY7vlOWcc0Q+PcCq9KZ/DaykzxrGlymaZH6rm8AHoqIv62btQa4Mg1fCXzreJdtukTE+yPitIhYQXZsfxARbwLuAn43LdZsdX4G2CjpzDTp5cCDNPFxTp4GXiCpK/1fr9W7aY/1KOMd3zXAW9LVOi8Aeuq6fiYmIk74F9nTtx4FngA+0OjyTGM9LyL7M+9+sgfQ3JfqvpDsrP5jwPfIblHd8PJOQ/0vAW5Nw88CfgY8DnwVaG90+aa4rucDa9OxvgWYn4fjDPwV8DDZE/Y+D7Q347Eme7zrVrI7D28iu/JozOMLiOxKxCeAX5BdxXRM+/WtFczMcqIZunTMzOwoOPDNzHLCgW9mlhMOfDOznHDgm5nlhAPfzCwnHPhmZjnxfwE7cDzyC/UQBgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Log-Likelihood curve\n",
    "fig, axs = plt.subplots(2)\n",
    "axs[0].plot([i+1 for i in range(len(model.likelihoods))], model.likelihoods)\n",
    "axs[0].set_title('Log-Likelihood curve')\n",
    "axs[1].plot([i+1 for i in range(len(model.acuy))], model.acuy)\n",
    "axs[1].set_title('Accuracy curve')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKxGs6DZa0a1"
   },
   "source": [
    "# Problem 2. K-Nearest Neighbor Classifier (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0OQaUyIa0a2"
   },
   "outputs": [],
   "source": [
    "def distd(c,b,a):\n",
    "  dist = 0\n",
    "  for i in range(len(c)):\n",
    "    dist += abs(c[i]-b[i]) ** a\n",
    "  dist = dist**(1/a)\n",
    "  return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9DjF5V8FWntR"
   },
   "outputs": [],
   "source": [
    "def pred(train, label, b, n, p):\n",
    "  distance = []\n",
    "  for i in range(len(train)):\n",
    "    dist = distd(train[i], b, p)\n",
    "    distance.append((label[i], dist))\n",
    "  distance.sort(key=lambda a: a[1])\n",
    "  result = []\n",
    "  for i in range(n):\n",
    "    result.append(distance[i][0])\n",
    "  prediction = max(set(result), key=result.count)\n",
    "  return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OhA3qDEGWv0b"
   },
   "outputs": [],
   "source": [
    "preidction = []\n",
    "accuracy = []\n",
    "for p in [1,2]:\n",
    "  for K in [1,2,5,7,9]:\n",
    "    predictions = []\n",
    "    for i in range(200):\n",
    "      predictions.append(pred(Xtrainn_flatten, Ytrainn, Xtest_flatten[i], K, p))\n",
    "    accuracy.append((predictions == Ytestt).sum()/200)\n",
    "    print((predictions == Ytestt).sum()/200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "YF47jShQWzge",
    "outputId": "73e81e98-3bd0-4d28-e6b1-2ee63c20aaed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots()\n",
    "axs.plot(accuracy[:5])\n",
    "print(\"plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "id": "H8RQCRA2Zhk1",
    "outputId": "9e943f89-926a-45c4-e6b3-416865fb70d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, '1'),\n",
       " Text(0, 0, '1'),\n",
       " Text(0, 0, '2'),\n",
       " Text(0, 0, '3'),\n",
       " Text(0, 0, '4'),\n",
       " Text(0, 0, '5'),\n",
       " Text(0, 0, '6'),\n",
       " Text(0, 0, '7'),\n",
       " Text(0, 0, '8'),\n",
       " Text(0, 0, '9')]"
      ]
     },
     "execution_count": 164,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots()\n",
    "axs.plot(accuracy[5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-im0xvLa0a2"
   },
   "source": [
    "# Problem 3. Multi-layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mqOQdlda0a2"
   },
   "outputs": [],
   "source": [
    "def keras_dense_model():\n",
    "# Initialize a set of linear layers\n",
    "    model = models.Sequential()\n",
    "# Fully Connected network layers (\"FC\")\n",
    "    model.add(layers.Flatten(input_shape=(28, 28)))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "POdWKCqYgltC",
    "outputId": "4b3cc002-9fc8-4a96-9f00-ef3a71223a13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 197.7629 - accuracy: 0.1259 - val_loss: 139.1778 - val_accuracy: 0.1708\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 137.5416 - accuracy: 0.1723 - val_loss: 108.7960 - val_accuracy: 0.1915\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 107.6679 - accuracy: 0.1931 - val_loss: 90.2269 - val_accuracy: 0.1920\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 89.4766 - accuracy: 0.1939 - val_loss: 75.3221 - val_accuracy: 0.1927\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 74.8848 - accuracy: 0.1964 - val_loss: 63.8252 - val_accuracy: 0.2002\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 63.6262 - accuracy: 0.2055 - val_loss: 56.0217 - val_accuracy: 0.2188\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 55.8976 - accuracy: 0.2174 - val_loss: 50.7346 - val_accuracy: 0.2263\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 50.6862 - accuracy: 0.2291 - val_loss: 46.2906 - val_accuracy: 0.2408\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 46.3440 - accuracy: 0.2441 - val_loss: 41.8657 - val_accuracy: 0.2650\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 42.0265 - accuracy: 0.2643 - val_loss: 37.4234 - val_accuracy: 0.2940\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 37.6605 - accuracy: 0.2916 - val_loss: 33.2042 - val_accuracy: 0.3254\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 33.5245 - accuracy: 0.3245 - val_loss: 29.4347 - val_accuracy: 0.3554\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 29.8920 - accuracy: 0.3580 - val_loss: 26.2308 - val_accuracy: 0.3889\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 26.8576 - accuracy: 0.3892 - val_loss: 23.6989 - val_accuracy: 0.4210\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 24.4401 - accuracy: 0.4171 - val_loss: 21.7787 - val_accuracy: 0.4434\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 22.5581 - accuracy: 0.4403 - val_loss: 20.2816 - val_accuracy: 0.4626\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 21.0727 - accuracy: 0.4591 - val_loss: 19.0340 - val_accuracy: 0.4799\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 19.8236 - accuracy: 0.4752 - val_loss: 17.9282 - val_accuracy: 0.4943\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 18.6722 - accuracy: 0.4899 - val_loss: 16.8595 - val_accuracy: 0.5089\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 17.5360 - accuracy: 0.5040 - val_loss: 15.7884 - val_accuracy: 0.5205\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 16.4088 - accuracy: 0.5179 - val_loss: 14.7541 - val_accuracy: 0.5338\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 15.3195 - accuracy: 0.5303 - val_loss: 13.7892 - val_accuracy: 0.5420\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 14.3039 - accuracy: 0.5419 - val_loss: 12.9262 - val_accuracy: 0.5548\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 13.4023 - accuracy: 0.5513 - val_loss: 12.1813 - val_accuracy: 0.5652\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 12.6200 - accuracy: 0.5603 - val_loss: 11.5305 - val_accuracy: 0.5717\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 11.9456 - accuracy: 0.5683 - val_loss: 10.9579 - val_accuracy: 0.5769\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 11.3614 - accuracy: 0.5750 - val_loss: 10.4511 - val_accuracy: 0.5848\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 10.8394 - accuracy: 0.5804 - val_loss: 9.9791 - val_accuracy: 0.5908\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 10.3546 - accuracy: 0.5861 - val_loss: 9.5276 - val_accuracy: 0.5957\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 9.8938 - accuracy: 0.5912 - val_loss: 9.0972 - val_accuracy: 0.6016\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 9.4536 - accuracy: 0.5966 - val_loss: 8.6830 - val_accuracy: 0.6066\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 9.0355 - accuracy: 0.6022 - val_loss: 8.2934 - val_accuracy: 0.6115\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 8.6432 - accuracy: 0.6069 - val_loss: 7.9276 - val_accuracy: 0.6168\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 8.2768 - accuracy: 0.6110 - val_loss: 7.5865 - val_accuracy: 0.6241\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 7.9384 - accuracy: 0.6147 - val_loss: 7.2733 - val_accuracy: 0.6287\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 7.6236 - accuracy: 0.6193 - val_loss: 6.9870 - val_accuracy: 0.6322\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 7.3265 - accuracy: 0.6220 - val_loss: 6.7245 - val_accuracy: 0.6339\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 7.0465 - accuracy: 0.6241 - val_loss: 6.4737 - val_accuracy: 0.6362\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 6.7811 - accuracy: 0.6252 - val_loss: 6.2413 - val_accuracy: 0.6374\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 6.5283 - accuracy: 0.6264 - val_loss: 6.0250 - val_accuracy: 0.6392\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.2874 - accuracy: 0.6277 - val_loss: 5.8177 - val_accuracy: 0.6399\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.0600 - accuracy: 0.6282 - val_loss: 5.6167 - val_accuracy: 0.6400\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 5.8431 - accuracy: 0.6292 - val_loss: 5.4235 - val_accuracy: 0.6383\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.6363 - accuracy: 0.6291 - val_loss: 5.2401 - val_accuracy: 0.6383\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.4397 - accuracy: 0.6289 - val_loss: 5.0613 - val_accuracy: 0.6369\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 5.2516 - accuracy: 0.6280 - val_loss: 4.8913 - val_accuracy: 0.6365\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 5.0722 - accuracy: 0.6270 - val_loss: 4.7302 - val_accuracy: 0.6372\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.9012 - accuracy: 0.6261 - val_loss: 4.5770 - val_accuracy: 0.6351\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 4.7388 - accuracy: 0.6252 - val_loss: 4.4306 - val_accuracy: 0.6351\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5847 - accuracy: 0.6232 - val_loss: 4.2931 - val_accuracy: 0.6324\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4378 - accuracy: 0.6214 - val_loss: 4.1627 - val_accuracy: 0.6302\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.2983 - accuracy: 0.6188 - val_loss: 4.0397 - val_accuracy: 0.6288\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.1651 - accuracy: 0.6168 - val_loss: 3.9219 - val_accuracy: 0.6256\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.0381 - accuracy: 0.6141 - val_loss: 3.8114 - val_accuracy: 0.6224\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 3.9163 - accuracy: 0.6119 - val_loss: 3.7075 - val_accuracy: 0.6184\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.7995 - accuracy: 0.6091 - val_loss: 3.6063 - val_accuracy: 0.6136\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.6877 - accuracy: 0.6059 - val_loss: 3.5075 - val_accuracy: 0.6101\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.5812 - accuracy: 0.6032 - val_loss: 3.4137 - val_accuracy: 0.6063\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4796 - accuracy: 0.6002 - val_loss: 3.3245 - val_accuracy: 0.6014\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.3827 - accuracy: 0.5975 - val_loss: 3.2392 - val_accuracy: 0.5966\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 3.2902 - accuracy: 0.5945 - val_loss: 3.1574 - val_accuracy: 0.5925\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 3.2020 - accuracy: 0.5914 - val_loss: 3.0787 - val_accuracy: 0.5883\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.1178 - accuracy: 0.5879 - val_loss: 3.0024 - val_accuracy: 0.5848\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.0377 - accuracy: 0.5855 - val_loss: 2.9290 - val_accuracy: 0.5825\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 2.9619 - accuracy: 0.5828 - val_loss: 2.8593 - val_accuracy: 0.5805\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.8900 - accuracy: 0.5796 - val_loss: 2.7932 - val_accuracy: 0.5771\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.8220 - accuracy: 0.5772 - val_loss: 2.7309 - val_accuracy: 0.5746\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.7577 - accuracy: 0.5750 - val_loss: 2.6715 - val_accuracy: 0.5723\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.6966 - accuracy: 0.5724 - val_loss: 2.6159 - val_accuracy: 0.5717\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.6390 - accuracy: 0.5699 - val_loss: 2.5628 - val_accuracy: 0.5804\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5847 - accuracy: 0.5769 - val_loss: 2.5131 - val_accuracy: 0.5780\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.5333 - accuracy: 0.5747 - val_loss: 2.4657 - val_accuracy: 0.5762\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 2.4845 - accuracy: 0.5725 - val_loss: 2.4212 - val_accuracy: 0.5740\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.4381 - accuracy: 0.5705 - val_loss: 2.3796 - val_accuracy: 0.5707\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.3940 - accuracy: 0.5685 - val_loss: 2.3398 - val_accuracy: 0.5671\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.3525 - accuracy: 0.5669 - val_loss: 2.3021 - val_accuracy: 0.6182\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.3130 - accuracy: 0.6125 - val_loss: 2.2660 - val_accuracy: 0.6173\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.2755 - accuracy: 0.6110 - val_loss: 2.2314 - val_accuracy: 0.6164\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.2397 - accuracy: 0.6099 - val_loss: 2.1985 - val_accuracy: 0.6167\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.2058 - accuracy: 0.6088 - val_loss: 2.1678 - val_accuracy: 0.6149\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.1737 - accuracy: 0.6079 - val_loss: 2.1387 - val_accuracy: 0.6134\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.1433 - accuracy: 0.6070 - val_loss: 2.1111 - val_accuracy: 0.6124\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.1143 - accuracy: 0.6062 - val_loss: 2.0848 - val_accuracy: 0.6110\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0868 - accuracy: 0.6056 - val_loss: 2.0594 - val_accuracy: 0.6101\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 2.0608 - accuracy: 0.6047 - val_loss: 2.0351 - val_accuracy: 0.6090\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0361 - accuracy: 0.6038 - val_loss: 2.0120 - val_accuracy: 0.6073\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0127 - accuracy: 0.6031 - val_loss: 1.9898 - val_accuracy: 0.6068\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.9902 - accuracy: 0.6026 - val_loss: 1.9689 - val_accuracy: 0.6065\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9688 - accuracy: 0.6016 - val_loss: 1.9492 - val_accuracy: 0.6059\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9482 - accuracy: 0.6011 - val_loss: 1.9307 - val_accuracy: 0.6050\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.9287 - accuracy: 0.6007 - val_loss: 1.9131 - val_accuracy: 0.6039\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9101 - accuracy: 0.5999 - val_loss: 1.8960 - val_accuracy: 0.6043\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8922 - accuracy: 0.5997 - val_loss: 1.8795 - val_accuracy: 0.6028\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.8752 - accuracy: 0.5995 - val_loss: 1.8636 - val_accuracy: 0.6022\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8589 - accuracy: 0.5988 - val_loss: 1.8480 - val_accuracy: 0.6089\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.8432 - accuracy: 0.6066 - val_loss: 1.8332 - val_accuracy: 0.6083\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.8282 - accuracy: 0.6063 - val_loss: 1.8192 - val_accuracy: 0.6078\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8137 - accuracy: 0.6064 - val_loss: 1.8057 - val_accuracy: 0.6078\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.7999 - accuracy: 0.6064 - val_loss: 1.7927 - val_accuracy: 0.6086\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.7866 - accuracy: 0.6061 - val_loss: 1.7800 - val_accuracy: 0.6085\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.7737 - accuracy: 0.6058 - val_loss: 1.7679 - val_accuracy: 0.6076\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.7613 - accuracy: 0.6057 - val_loss: 1.7563 - val_accuracy: 0.6078\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.7494 - accuracy: 0.6058 - val_loss: 1.7452 - val_accuracy: 0.6079\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7380 - accuracy: 0.6055 - val_loss: 1.7345 - val_accuracy: 0.6070\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.7270 - accuracy: 0.6058 - val_loss: 1.7240 - val_accuracy: 0.6073\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.7162 - accuracy: 0.6057 - val_loss: 1.7140 - val_accuracy: 0.6081\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.7058 - accuracy: 0.6058 - val_loss: 1.7042 - val_accuracy: 0.6076\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6958 - accuracy: 0.6055 - val_loss: 1.6947 - val_accuracy: 0.6081\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.6861 - accuracy: 0.6058 - val_loss: 1.6854 - val_accuracy: 0.6078\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.6767 - accuracy: 0.6061 - val_loss: 1.6765 - val_accuracy: 0.6073\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.6676 - accuracy: 0.6064 - val_loss: 1.6678 - val_accuracy: 0.6078\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6588 - accuracy: 0.6066 - val_loss: 1.6595 - val_accuracy: 0.6083\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6503 - accuracy: 0.6069 - val_loss: 1.6513 - val_accuracy: 0.6078\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.6420 - accuracy: 0.6072 - val_loss: 1.6434 - val_accuracy: 0.6085\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6340 - accuracy: 0.6072 - val_loss: 1.6356 - val_accuracy: 0.6087\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6261 - accuracy: 0.6075 - val_loss: 1.6280 - val_accuracy: 0.6083\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6184 - accuracy: 0.6076 - val_loss: 1.6206 - val_accuracy: 0.6081\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6109 - accuracy: 0.6078 - val_loss: 1.6133 - val_accuracy: 0.6083\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6036 - accuracy: 0.6083 - val_loss: 1.6062 - val_accuracy: 0.6093\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5965 - accuracy: 0.6083 - val_loss: 1.5993 - val_accuracy: 0.6097\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5895 - accuracy: 0.6087 - val_loss: 1.5925 - val_accuracy: 0.6100\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5826 - accuracy: 0.6088 - val_loss: 1.5860 - val_accuracy: 0.6102\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5759 - accuracy: 0.6090 - val_loss: 1.5797 - val_accuracy: 0.6101\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.5693 - accuracy: 0.6092 - val_loss: 1.5734 - val_accuracy: 0.6099\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5628 - accuracy: 0.6094 - val_loss: 1.5673 - val_accuracy: 0.6100\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5565 - accuracy: 0.6097 - val_loss: 1.5614 - val_accuracy: 0.6103\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.5504 - accuracy: 0.6102 - val_loss: 1.5557 - val_accuracy: 0.6108\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.5445 - accuracy: 0.6105 - val_loss: 1.5503 - val_accuracy: 0.6119\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5386 - accuracy: 0.6108 - val_loss: 1.5450 - val_accuracy: 0.6127\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5329 - accuracy: 0.6113 - val_loss: 1.5398 - val_accuracy: 0.6129\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5272 - accuracy: 0.6120 - val_loss: 1.5347 - val_accuracy: 0.6137\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5216 - accuracy: 0.6125 - val_loss: 1.5297 - val_accuracy: 0.6135\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.5162 - accuracy: 0.6131 - val_loss: 1.5247 - val_accuracy: 0.6133\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5109 - accuracy: 0.6136 - val_loss: 1.5199 - val_accuracy: 0.6138\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5056 - accuracy: 0.6141 - val_loss: 1.5151 - val_accuracy: 0.6139\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.5005 - accuracy: 0.6145 - val_loss: 1.5104 - val_accuracy: 0.6149\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.4955 - accuracy: 0.6148 - val_loss: 1.5057 - val_accuracy: 0.6153\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4906 - accuracy: 0.6153 - val_loss: 1.5012 - val_accuracy: 0.6157\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4858 - accuracy: 0.6158 - val_loss: 1.4967 - val_accuracy: 0.6163\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4810 - accuracy: 0.6160 - val_loss: 1.4923 - val_accuracy: 0.6168\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.4763 - accuracy: 0.6164 - val_loss: 1.4878 - val_accuracy: 0.6181\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4717 - accuracy: 0.6170 - val_loss: 1.4834 - val_accuracy: 0.6185\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4672 - accuracy: 0.6176 - val_loss: 1.4790 - val_accuracy: 0.6197\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4627 - accuracy: 0.6180 - val_loss: 1.4747 - val_accuracy: 0.6203\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4582 - accuracy: 0.6183 - val_loss: 1.4706 - val_accuracy: 0.6203\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4538 - accuracy: 0.6189 - val_loss: 1.4665 - val_accuracy: 0.6208\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4494 - accuracy: 0.6194 - val_loss: 1.4626 - val_accuracy: 0.6217\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4451 - accuracy: 0.6198 - val_loss: 1.4587 - val_accuracy: 0.6223\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4409 - accuracy: 0.6202 - val_loss: 1.4549 - val_accuracy: 0.6228\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4368 - accuracy: 0.6207 - val_loss: 1.4511 - val_accuracy: 0.6234\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4327 - accuracy: 0.6212 - val_loss: 1.4474 - val_accuracy: 0.6242\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4286 - accuracy: 0.6216 - val_loss: 1.4438 - val_accuracy: 0.6247\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4246 - accuracy: 0.6221 - val_loss: 1.4402 - val_accuracy: 0.6258\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4207 - accuracy: 0.6227 - val_loss: 1.4366 - val_accuracy: 0.6264\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4168 - accuracy: 0.6231 - val_loss: 1.4330 - val_accuracy: 0.6278\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4130 - accuracy: 0.6235 - val_loss: 1.4294 - val_accuracy: 0.6281\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4092 - accuracy: 0.6241 - val_loss: 1.4258 - val_accuracy: 0.6289\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4055 - accuracy: 0.6247 - val_loss: 1.4222 - val_accuracy: 0.6288\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.4017 - accuracy: 0.6255 - val_loss: 1.4187 - val_accuracy: 0.6292\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3980 - accuracy: 0.6258 - val_loss: 1.4152 - val_accuracy: 0.6297\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3943 - accuracy: 0.6264 - val_loss: 1.4117 - val_accuracy: 0.6302\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3906 - accuracy: 0.6270 - val_loss: 1.4083 - val_accuracy: 0.6317\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3870 - accuracy: 0.6276 - val_loss: 1.4049 - val_accuracy: 0.6320\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3834 - accuracy: 0.6281 - val_loss: 1.4015 - val_accuracy: 0.6326\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3799 - accuracy: 0.6288 - val_loss: 1.3981 - val_accuracy: 0.6325\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3764 - accuracy: 0.6294 - val_loss: 1.3948 - val_accuracy: 0.6334\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3730 - accuracy: 0.6300 - val_loss: 1.3915 - val_accuracy: 0.6342\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3696 - accuracy: 0.6302 - val_loss: 1.3883 - val_accuracy: 0.6344\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3662 - accuracy: 0.6308 - val_loss: 1.3852 - val_accuracy: 0.6345\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3629 - accuracy: 0.6314 - val_loss: 1.3822 - val_accuracy: 0.6348\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3595 - accuracy: 0.6317 - val_loss: 1.3793 - val_accuracy: 0.6350\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3562 - accuracy: 0.6323 - val_loss: 1.3764 - val_accuracy: 0.6355\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.3530 - accuracy: 0.6328 - val_loss: 1.3736 - val_accuracy: 0.6364\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3497 - accuracy: 0.6334 - val_loss: 1.3708 - val_accuracy: 0.6370\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3465 - accuracy: 0.6338 - val_loss: 1.3680 - val_accuracy: 0.6373\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.3433 - accuracy: 0.6342 - val_loss: 1.3652 - val_accuracy: 0.6378\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3401 - accuracy: 0.6345 - val_loss: 1.3625 - val_accuracy: 0.6382\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3370 - accuracy: 0.6349 - val_loss: 1.3597 - val_accuracy: 0.6392\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3339 - accuracy: 0.6356 - val_loss: 1.3570 - val_accuracy: 0.6397\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3309 - accuracy: 0.6364 - val_loss: 1.3543 - val_accuracy: 0.6401\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3278 - accuracy: 0.6368 - val_loss: 1.3516 - val_accuracy: 0.6401\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3248 - accuracy: 0.6372 - val_loss: 1.3489 - val_accuracy: 0.6405\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3219 - accuracy: 0.6377 - val_loss: 1.3463 - val_accuracy: 0.6404\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3189 - accuracy: 0.6385 - val_loss: 1.3436 - val_accuracy: 0.6412\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3159 - accuracy: 0.6389 - val_loss: 1.3410 - val_accuracy: 0.6412\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3130 - accuracy: 0.6394 - val_loss: 1.3383 - val_accuracy: 0.6418\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3100 - accuracy: 0.6400 - val_loss: 1.3356 - val_accuracy: 0.6427\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3071 - accuracy: 0.6407 - val_loss: 1.3329 - val_accuracy: 0.6428\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.3042 - accuracy: 0.6413 - val_loss: 1.3302 - val_accuracy: 0.6439\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3013 - accuracy: 0.6419 - val_loss: 1.3275 - val_accuracy: 0.6441\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2983 - accuracy: 0.6427 - val_loss: 1.3249 - val_accuracy: 0.6447\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2954 - accuracy: 0.6434 - val_loss: 1.3223 - val_accuracy: 0.6454\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2925 - accuracy: 0.6440 - val_loss: 1.3196 - val_accuracy: 0.6470\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2896 - accuracy: 0.6448 - val_loss: 1.3170 - val_accuracy: 0.6470\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2867 - accuracy: 0.6453 - val_loss: 1.3144 - val_accuracy: 0.6476\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2839 - accuracy: 0.6459 - val_loss: 1.3118 - val_accuracy: 0.6490\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.2811 - accuracy: 0.6462 - val_loss: 1.3092 - val_accuracy: 0.6494\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2782 - accuracy: 0.6467 - val_loss: 1.3067 - val_accuracy: 0.6503\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2754 - accuracy: 0.6471 - val_loss: 1.3041 - val_accuracy: 0.6505\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2726 - accuracy: 0.6479 - val_loss: 1.3016 - val_accuracy: 0.6507\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2698 - accuracy: 0.6487 - val_loss: 1.2990 - val_accuracy: 0.6510\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2670 - accuracy: 0.6491 - val_loss: 1.2966 - val_accuracy: 0.6517\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2643 - accuracy: 0.6496 - val_loss: 1.2941 - val_accuracy: 0.6525\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2615 - accuracy: 0.6501 - val_loss: 1.2917 - val_accuracy: 0.6527\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2588 - accuracy: 0.6507 - val_loss: 1.2893 - val_accuracy: 0.6529\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.2561 - accuracy: 0.6513 - val_loss: 1.2869 - val_accuracy: 0.6538\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2535 - accuracy: 0.6517 - val_loss: 1.2844 - val_accuracy: 0.6544\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2508 - accuracy: 0.6521 - val_loss: 1.2819 - val_accuracy: 0.6552\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2482 - accuracy: 0.6527 - val_loss: 1.2794 - val_accuracy: 0.6551\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2456 - accuracy: 0.6532 - val_loss: 1.2769 - val_accuracy: 0.6560\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2430 - accuracy: 0.6536 - val_loss: 1.2745 - val_accuracy: 0.6562\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2405 - accuracy: 0.6540 - val_loss: 1.2720 - val_accuracy: 0.6571\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2380 - accuracy: 0.6542 - val_loss: 1.2697 - val_accuracy: 0.6574\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2356 - accuracy: 0.6546 - val_loss: 1.2673 - val_accuracy: 0.6581\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2331 - accuracy: 0.6549 - val_loss: 1.2650 - val_accuracy: 0.6585\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2307 - accuracy: 0.6554 - val_loss: 1.2628 - val_accuracy: 0.6592\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2283 - accuracy: 0.6558 - val_loss: 1.2607 - val_accuracy: 0.6595\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2258 - accuracy: 0.6564 - val_loss: 1.2585 - val_accuracy: 0.6601\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2234 - accuracy: 0.6568 - val_loss: 1.2563 - val_accuracy: 0.6606\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2211 - accuracy: 0.6571 - val_loss: 1.2542 - val_accuracy: 0.6609\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2187 - accuracy: 0.6574 - val_loss: 1.2521 - val_accuracy: 0.6613\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2164 - accuracy: 0.6578 - val_loss: 1.2499 - val_accuracy: 0.6616\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2141 - accuracy: 0.6582 - val_loss: 1.2478 - val_accuracy: 0.6620\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2118 - accuracy: 0.6586 - val_loss: 1.2458 - val_accuracy: 0.6625\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2095 - accuracy: 0.6589 - val_loss: 1.2438 - val_accuracy: 0.6624\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2073 - accuracy: 0.6593 - val_loss: 1.2418 - val_accuracy: 0.6625\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2050 - accuracy: 0.6596 - val_loss: 1.2398 - val_accuracy: 0.6627\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2027 - accuracy: 0.6598 - val_loss: 1.2378 - val_accuracy: 0.6632\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2005 - accuracy: 0.6603 - val_loss: 1.2359 - val_accuracy: 0.6637\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1983 - accuracy: 0.6608 - val_loss: 1.2339 - val_accuracy: 0.6640\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1960 - accuracy: 0.6613 - val_loss: 1.2319 - val_accuracy: 0.6645\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1938 - accuracy: 0.6617 - val_loss: 1.2299 - val_accuracy: 0.6652\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1916 - accuracy: 0.6622 - val_loss: 1.2280 - val_accuracy: 0.6661\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1894 - accuracy: 0.6627 - val_loss: 1.2260 - val_accuracy: 0.6665\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1872 - accuracy: 0.6633 - val_loss: 1.2241 - val_accuracy: 0.6673\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1850 - accuracy: 0.6638 - val_loss: 1.2222 - val_accuracy: 0.6679\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1828 - accuracy: 0.6640 - val_loss: 1.2203 - val_accuracy: 0.6682\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1807 - accuracy: 0.6645 - val_loss: 1.2184 - val_accuracy: 0.6687\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1786 - accuracy: 0.6649 - val_loss: 1.2166 - val_accuracy: 0.6697\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1765 - accuracy: 0.6653 - val_loss: 1.2147 - val_accuracy: 0.6697\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1744 - accuracy: 0.6656 - val_loss: 1.2129 - val_accuracy: 0.6702\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1723 - accuracy: 0.6660 - val_loss: 1.2110 - val_accuracy: 0.6706\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1702 - accuracy: 0.6666 - val_loss: 1.2092 - val_accuracy: 0.6707\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1681 - accuracy: 0.6670 - val_loss: 1.2074 - val_accuracy: 0.6712\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1660 - accuracy: 0.6674 - val_loss: 1.2056 - val_accuracy: 0.6718\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1639 - accuracy: 0.6678 - val_loss: 1.2038 - val_accuracy: 0.6719\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1618 - accuracy: 0.6682 - val_loss: 1.2021 - val_accuracy: 0.6721\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1598 - accuracy: 0.6686 - val_loss: 1.2004 - val_accuracy: 0.6726\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1577 - accuracy: 0.6691 - val_loss: 1.1987 - val_accuracy: 0.6726\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1556 - accuracy: 0.6695 - val_loss: 1.1969 - val_accuracy: 0.6729\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1536 - accuracy: 0.6699 - val_loss: 1.1951 - val_accuracy: 0.6733\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1515 - accuracy: 0.6704 - val_loss: 1.1933 - val_accuracy: 0.6738\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1495 - accuracy: 0.6708 - val_loss: 1.1915 - val_accuracy: 0.6744\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1474 - accuracy: 0.6712 - val_loss: 1.1897 - val_accuracy: 0.6747\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1454 - accuracy: 0.6715 - val_loss: 1.1879 - val_accuracy: 0.6752\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1433 - accuracy: 0.6722 - val_loss: 1.1861 - val_accuracy: 0.6759\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1413 - accuracy: 0.6727 - val_loss: 1.1843 - val_accuracy: 0.6759\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1393 - accuracy: 0.6732 - val_loss: 1.1826 - val_accuracy: 0.6764\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1373 - accuracy: 0.6735 - val_loss: 1.1808 - val_accuracy: 0.6769\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1353 - accuracy: 0.6741 - val_loss: 1.1791 - val_accuracy: 0.6772\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1333 - accuracy: 0.6744 - val_loss: 1.1775 - val_accuracy: 0.6782\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.1313 - accuracy: 0.6749 - val_loss: 1.1758 - val_accuracy: 0.6787\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1293 - accuracy: 0.6755 - val_loss: 1.1742 - val_accuracy: 0.6787\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1273 - accuracy: 0.6759 - val_loss: 1.1726 - val_accuracy: 0.6791\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1254 - accuracy: 0.6762 - val_loss: 1.1709 - val_accuracy: 0.6795\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1234 - accuracy: 0.6766 - val_loss: 1.1693 - val_accuracy: 0.6796\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1214 - accuracy: 0.6772 - val_loss: 1.1677 - val_accuracy: 0.6805\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1194 - accuracy: 0.6777 - val_loss: 1.1661 - val_accuracy: 0.6814\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1174 - accuracy: 0.6782 - val_loss: 1.1646 - val_accuracy: 0.6816\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1155 - accuracy: 0.6786 - val_loss: 1.1631 - val_accuracy: 0.6821\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.1135 - accuracy: 0.6791 - val_loss: 1.1616 - val_accuracy: 0.6828\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1115 - accuracy: 0.6796 - val_loss: 1.1601 - val_accuracy: 0.6830\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1095 - accuracy: 0.6804 - val_loss: 1.1587 - val_accuracy: 0.6836\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.1075 - accuracy: 0.6809 - val_loss: 1.1573 - val_accuracy: 0.6846\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1055 - accuracy: 0.6815 - val_loss: 1.1559 - val_accuracy: 0.6849\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1035 - accuracy: 0.6820 - val_loss: 1.1546 - val_accuracy: 0.6853\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1015 - accuracy: 0.6824 - val_loss: 1.1533 - val_accuracy: 0.6853\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0995 - accuracy: 0.6831 - val_loss: 1.1520 - val_accuracy: 0.6855\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0975 - accuracy: 0.6838 - val_loss: 1.1508 - val_accuracy: 0.6856\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0955 - accuracy: 0.6844 - val_loss: 1.1495 - val_accuracy: 0.6862\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0935 - accuracy: 0.6848 - val_loss: 1.1482 - val_accuracy: 0.6868\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0916 - accuracy: 0.6854 - val_loss: 1.1469 - val_accuracy: 0.6873\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0896 - accuracy: 0.6860 - val_loss: 1.1455 - val_accuracy: 0.6876\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0877 - accuracy: 0.6863 - val_loss: 1.1442 - val_accuracy: 0.6880\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0858 - accuracy: 0.6868 - val_loss: 1.1429 - val_accuracy: 0.6886\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0839 - accuracy: 0.6873 - val_loss: 1.1416 - val_accuracy: 0.6892\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0819 - accuracy: 0.6878 - val_loss: 1.1402 - val_accuracy: 0.6897\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0800 - accuracy: 0.6884 - val_loss: 1.1389 - val_accuracy: 0.6899\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0781 - accuracy: 0.6888 - val_loss: 1.1376 - val_accuracy: 0.6901\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0762 - accuracy: 0.6892 - val_loss: 1.1362 - val_accuracy: 0.6905\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0742 - accuracy: 0.6899 - val_loss: 1.1348 - val_accuracy: 0.6913\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0723 - accuracy: 0.6902 - val_loss: 1.1335 - val_accuracy: 0.6919\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0703 - accuracy: 0.6908 - val_loss: 1.1321 - val_accuracy: 0.6927\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0684 - accuracy: 0.6912 - val_loss: 1.1307 - val_accuracy: 0.6929\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0664 - accuracy: 0.6915 - val_loss: 1.1293 - val_accuracy: 0.6944\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0645 - accuracy: 0.6919 - val_loss: 1.1279 - val_accuracy: 0.6949\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0626 - accuracy: 0.6923 - val_loss: 1.1265 - val_accuracy: 0.6953\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0607 - accuracy: 0.6928 - val_loss: 1.1251 - val_accuracy: 0.6961\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0588 - accuracy: 0.6933 - val_loss: 1.1236 - val_accuracy: 0.6975\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0569 - accuracy: 0.6938 - val_loss: 1.1221 - val_accuracy: 0.6979\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0551 - accuracy: 0.6941 - val_loss: 1.1207 - val_accuracy: 0.6985\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0532 - accuracy: 0.6945 - val_loss: 1.1192 - val_accuracy: 0.6985\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0514 - accuracy: 0.6950 - val_loss: 1.1176 - val_accuracy: 0.6988\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0496 - accuracy: 0.6956 - val_loss: 1.1161 - val_accuracy: 0.6993\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0477 - accuracy: 0.6963 - val_loss: 1.1146 - val_accuracy: 0.7001\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0459 - accuracy: 0.6966 - val_loss: 1.1132 - val_accuracy: 0.7006\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0441 - accuracy: 0.6972 - val_loss: 1.1117 - val_accuracy: 0.7007\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0423 - accuracy: 0.6977 - val_loss: 1.1103 - val_accuracy: 0.7009\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0405 - accuracy: 0.6979 - val_loss: 1.1089 - val_accuracy: 0.7010\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0387 - accuracy: 0.6983 - val_loss: 1.1075 - val_accuracy: 0.7016\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0369 - accuracy: 0.6989 - val_loss: 1.1061 - val_accuracy: 0.7024\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0352 - accuracy: 0.6993 - val_loss: 1.1046 - val_accuracy: 0.7024\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0334 - accuracy: 0.6997 - val_loss: 1.1032 - val_accuracy: 0.7027\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0317 - accuracy: 0.7002 - val_loss: 1.1017 - val_accuracy: 0.7034\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0299 - accuracy: 0.7009 - val_loss: 1.1003 - val_accuracy: 0.7035\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0282 - accuracy: 0.7012 - val_loss: 1.0990 - val_accuracy: 0.7036\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0264 - accuracy: 0.7018 - val_loss: 1.0977 - val_accuracy: 0.7040\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0247 - accuracy: 0.7021 - val_loss: 1.0964 - val_accuracy: 0.7044\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0230 - accuracy: 0.7026 - val_loss: 1.0952 - val_accuracy: 0.7049\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0212 - accuracy: 0.7030 - val_loss: 1.0941 - val_accuracy: 0.7055\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0195 - accuracy: 0.7034 - val_loss: 1.0929 - val_accuracy: 0.7061\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0178 - accuracy: 0.7037 - val_loss: 1.0917 - val_accuracy: 0.7069\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0161 - accuracy: 0.7042 - val_loss: 1.0905 - val_accuracy: 0.7077\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0143 - accuracy: 0.7046 - val_loss: 1.0892 - val_accuracy: 0.7080\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0127 - accuracy: 0.7050 - val_loss: 1.0880 - val_accuracy: 0.7087\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0110 - accuracy: 0.7055 - val_loss: 1.0868 - val_accuracy: 0.7098\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0092 - accuracy: 0.7059 - val_loss: 1.0856 - val_accuracy: 0.7106\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0076 - accuracy: 0.7063 - val_loss: 1.0843 - val_accuracy: 0.7107\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0059 - accuracy: 0.7069 - val_loss: 1.0830 - val_accuracy: 0.7110\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0042 - accuracy: 0.7074 - val_loss: 1.0816 - val_accuracy: 0.7114\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0025 - accuracy: 0.7076 - val_loss: 1.0802 - val_accuracy: 0.7120\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0009 - accuracy: 0.7082 - val_loss: 1.0788 - val_accuracy: 0.7124\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9993 - accuracy: 0.7086 - val_loss: 1.0774 - val_accuracy: 0.7128\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9977 - accuracy: 0.7089 - val_loss: 1.0760 - val_accuracy: 0.7131\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9961 - accuracy: 0.7093 - val_loss: 1.0746 - val_accuracy: 0.7131\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9945 - accuracy: 0.7098 - val_loss: 1.0733 - val_accuracy: 0.7134\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9929 - accuracy: 0.7102 - val_loss: 1.0720 - val_accuracy: 0.7135\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9913 - accuracy: 0.7105 - val_loss: 1.0707 - val_accuracy: 0.7139\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9897 - accuracy: 0.7110 - val_loss: 1.0695 - val_accuracy: 0.7144\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9882 - accuracy: 0.7114 - val_loss: 1.0683 - val_accuracy: 0.7146\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9866 - accuracy: 0.7118 - val_loss: 1.0671 - val_accuracy: 0.7147\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9850 - accuracy: 0.7122 - val_loss: 1.0659 - val_accuracy: 0.7149\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9834 - accuracy: 0.7128 - val_loss: 1.0646 - val_accuracy: 0.7154\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9819 - accuracy: 0.7134 - val_loss: 1.0634 - val_accuracy: 0.7158\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9803 - accuracy: 0.7140 - val_loss: 1.0621 - val_accuracy: 0.7161\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9787 - accuracy: 0.7146 - val_loss: 1.0609 - val_accuracy: 0.7166\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9771 - accuracy: 0.7152 - val_loss: 1.0598 - val_accuracy: 0.7171\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9755 - accuracy: 0.7156 - val_loss: 1.0586 - val_accuracy: 0.7174\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9738 - accuracy: 0.7161 - val_loss: 1.0574 - val_accuracy: 0.7176\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9722 - accuracy: 0.7168 - val_loss: 1.0562 - val_accuracy: 0.7177\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9706 - accuracy: 0.7174 - val_loss: 1.0550 - val_accuracy: 0.7178\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9690 - accuracy: 0.7178 - val_loss: 1.0538 - val_accuracy: 0.7188\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9674 - accuracy: 0.7181 - val_loss: 1.0526 - val_accuracy: 0.7197\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9658 - accuracy: 0.7186 - val_loss: 1.0515 - val_accuracy: 0.7204\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9642 - accuracy: 0.7192 - val_loss: 1.0503 - val_accuracy: 0.7204\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9626 - accuracy: 0.7196 - val_loss: 1.0492 - val_accuracy: 0.7205\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9610 - accuracy: 0.7200 - val_loss: 1.0481 - val_accuracy: 0.7208\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9594 - accuracy: 0.7205 - val_loss: 1.0470 - val_accuracy: 0.7211\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9578 - accuracy: 0.7211 - val_loss: 1.0458 - val_accuracy: 0.7215\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9563 - accuracy: 0.7215 - val_loss: 1.0446 - val_accuracy: 0.7223\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9548 - accuracy: 0.7220 - val_loss: 1.0435 - val_accuracy: 0.7222\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9533 - accuracy: 0.7224 - val_loss: 1.0423 - val_accuracy: 0.7223\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9519 - accuracy: 0.7225 - val_loss: 1.0411 - val_accuracy: 0.7225\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9504 - accuracy: 0.7230 - val_loss: 1.0400 - val_accuracy: 0.7226\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9489 - accuracy: 0.7235 - val_loss: 1.0390 - val_accuracy: 0.7230\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9475 - accuracy: 0.7238 - val_loss: 1.0380 - val_accuracy: 0.7234\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9460 - accuracy: 0.7243 - val_loss: 1.0372 - val_accuracy: 0.7234\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9445 - accuracy: 0.7247 - val_loss: 1.0363 - val_accuracy: 0.7236\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9431 - accuracy: 0.7248 - val_loss: 1.0353 - val_accuracy: 0.7236\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9417 - accuracy: 0.7251 - val_loss: 1.0344 - val_accuracy: 0.7240\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9402 - accuracy: 0.7256 - val_loss: 1.0333 - val_accuracy: 0.7241\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9388 - accuracy: 0.7258 - val_loss: 1.0323 - val_accuracy: 0.7245\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9374 - accuracy: 0.7258 - val_loss: 1.0312 - val_accuracy: 0.7250\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9359 - accuracy: 0.7264 - val_loss: 1.0302 - val_accuracy: 0.7256\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9345 - accuracy: 0.7268 - val_loss: 1.0292 - val_accuracy: 0.7258\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9330 - accuracy: 0.7272 - val_loss: 1.0282 - val_accuracy: 0.7260\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9316 - accuracy: 0.7274 - val_loss: 1.0272 - val_accuracy: 0.7266\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9301 - accuracy: 0.7279 - val_loss: 1.0262 - val_accuracy: 0.7269\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9287 - accuracy: 0.7282 - val_loss: 1.0253 - val_accuracy: 0.7275\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9272 - accuracy: 0.7287 - val_loss: 1.0244 - val_accuracy: 0.7280\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9257 - accuracy: 0.7291 - val_loss: 1.0235 - val_accuracy: 0.7282\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9243 - accuracy: 0.7297 - val_loss: 1.0225 - val_accuracy: 0.7285\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9229 - accuracy: 0.7301 - val_loss: 1.0215 - val_accuracy: 0.7294\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9214 - accuracy: 0.7306 - val_loss: 1.0204 - val_accuracy: 0.7299\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9200 - accuracy: 0.7313 - val_loss: 1.0194 - val_accuracy: 0.7301\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9186 - accuracy: 0.7319 - val_loss: 1.0184 - val_accuracy: 0.7303\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9172 - accuracy: 0.7322 - val_loss: 1.0174 - val_accuracy: 0.7309\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9158 - accuracy: 0.7327 - val_loss: 1.0163 - val_accuracy: 0.7313\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9143 - accuracy: 0.7333 - val_loss: 1.0152 - val_accuracy: 0.7319\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9129 - accuracy: 0.7339 - val_loss: 1.0141 - val_accuracy: 0.7328\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9115 - accuracy: 0.7343 - val_loss: 1.0129 - val_accuracy: 0.7334\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9100 - accuracy: 0.7348 - val_loss: 1.0118 - val_accuracy: 0.7338\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9086 - accuracy: 0.7352 - val_loss: 1.0107 - val_accuracy: 0.7342\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9072 - accuracy: 0.7358 - val_loss: 1.0096 - val_accuracy: 0.7346\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9058 - accuracy: 0.7363 - val_loss: 1.0084 - val_accuracy: 0.7354\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9044 - accuracy: 0.7367 - val_loss: 1.0071 - val_accuracy: 0.7356\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9030 - accuracy: 0.7371 - val_loss: 1.0058 - val_accuracy: 0.7367\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9016 - accuracy: 0.7376 - val_loss: 1.0046 - val_accuracy: 0.7373\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9002 - accuracy: 0.7379 - val_loss: 1.0034 - val_accuracy: 0.7374\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8988 - accuracy: 0.7382 - val_loss: 1.0023 - val_accuracy: 0.7376\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8975 - accuracy: 0.7384 - val_loss: 1.0011 - val_accuracy: 0.7382\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8961 - accuracy: 0.7388 - val_loss: 1.0000 - val_accuracy: 0.7384\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8947 - accuracy: 0.7391 - val_loss: 0.9989 - val_accuracy: 0.7393\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8934 - accuracy: 0.7395 - val_loss: 0.9977 - val_accuracy: 0.7394\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8920 - accuracy: 0.7397 - val_loss: 0.9966 - val_accuracy: 0.7395\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8907 - accuracy: 0.7399 - val_loss: 0.9955 - val_accuracy: 0.7401\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8894 - accuracy: 0.7403 - val_loss: 0.9944 - val_accuracy: 0.7402\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8880 - accuracy: 0.7407 - val_loss: 0.9933 - val_accuracy: 0.7404\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8867 - accuracy: 0.7408 - val_loss: 0.9921 - val_accuracy: 0.7405\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8854 - accuracy: 0.7410 - val_loss: 0.9910 - val_accuracy: 0.7408\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8841 - accuracy: 0.7412 - val_loss: 0.9899 - val_accuracy: 0.7411\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8828 - accuracy: 0.7415 - val_loss: 0.9887 - val_accuracy: 0.7416\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8815 - accuracy: 0.7419 - val_loss: 0.9876 - val_accuracy: 0.7418\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8802 - accuracy: 0.7423 - val_loss: 0.9864 - val_accuracy: 0.7420\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8789 - accuracy: 0.7427 - val_loss: 0.9853 - val_accuracy: 0.7424\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8777 - accuracy: 0.7431 - val_loss: 0.9842 - val_accuracy: 0.7426\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8764 - accuracy: 0.7434 - val_loss: 0.9832 - val_accuracy: 0.7433\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8751 - accuracy: 0.7437 - val_loss: 0.9821 - val_accuracy: 0.7434\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8739 - accuracy: 0.7441 - val_loss: 0.9809 - val_accuracy: 0.7439\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8726 - accuracy: 0.7444 - val_loss: 0.9798 - val_accuracy: 0.7442\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8713 - accuracy: 0.7447 - val_loss: 0.9787 - val_accuracy: 0.7445\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8701 - accuracy: 0.7450 - val_loss: 0.9777 - val_accuracy: 0.7448\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8688 - accuracy: 0.7452 - val_loss: 0.9768 - val_accuracy: 0.7448\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8675 - accuracy: 0.7457 - val_loss: 0.9759 - val_accuracy: 0.7453\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8663 - accuracy: 0.7460 - val_loss: 0.9751 - val_accuracy: 0.7458\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8650 - accuracy: 0.7464 - val_loss: 0.9743 - val_accuracy: 0.7458\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8638 - accuracy: 0.7468 - val_loss: 0.9734 - val_accuracy: 0.7463\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8625 - accuracy: 0.7473 - val_loss: 0.9725 - val_accuracy: 0.7468\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8613 - accuracy: 0.7478 - val_loss: 0.9715 - val_accuracy: 0.7468\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8600 - accuracy: 0.7483 - val_loss: 0.9704 - val_accuracy: 0.7471\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8588 - accuracy: 0.7486 - val_loss: 0.9693 - val_accuracy: 0.7476\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8576 - accuracy: 0.7490 - val_loss: 0.9681 - val_accuracy: 0.7478\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8564 - accuracy: 0.7493 - val_loss: 0.9669 - val_accuracy: 0.7484\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8552 - accuracy: 0.7496 - val_loss: 0.9659 - val_accuracy: 0.7485\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8540 - accuracy: 0.7498 - val_loss: 0.9650 - val_accuracy: 0.7491\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8528 - accuracy: 0.7503 - val_loss: 0.9643 - val_accuracy: 0.7494\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8516 - accuracy: 0.7505 - val_loss: 0.9636 - val_accuracy: 0.7500\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8504 - accuracy: 0.7510 - val_loss: 0.9630 - val_accuracy: 0.7502\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8492 - accuracy: 0.7514 - val_loss: 0.9622 - val_accuracy: 0.7505\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8480 - accuracy: 0.7516 - val_loss: 0.9612 - val_accuracy: 0.7508\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8469 - accuracy: 0.7520 - val_loss: 0.9601 - val_accuracy: 0.7512\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8457 - accuracy: 0.7523 - val_loss: 0.9589 - val_accuracy: 0.7513\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8445 - accuracy: 0.7526 - val_loss: 0.9576 - val_accuracy: 0.7517\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8433 - accuracy: 0.7530 - val_loss: 0.9564 - val_accuracy: 0.7523\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8422 - accuracy: 0.7532 - val_loss: 0.9553 - val_accuracy: 0.7528\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8410 - accuracy: 0.7534 - val_loss: 0.9542 - val_accuracy: 0.7531\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8399 - accuracy: 0.7538 - val_loss: 0.9532 - val_accuracy: 0.7530\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8387 - accuracy: 0.7540 - val_loss: 0.9523 - val_accuracy: 0.7536\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8375 - accuracy: 0.7545 - val_loss: 0.9513 - val_accuracy: 0.7538\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8364 - accuracy: 0.7549 - val_loss: 0.9504 - val_accuracy: 0.7542\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8352 - accuracy: 0.7552 - val_loss: 0.9493 - val_accuracy: 0.7548\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8341 - accuracy: 0.7554 - val_loss: 0.9483 - val_accuracy: 0.7551\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8329 - accuracy: 0.7557 - val_loss: 0.9472 - val_accuracy: 0.7555\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8317 - accuracy: 0.7560 - val_loss: 0.9462 - val_accuracy: 0.7559\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8306 - accuracy: 0.7563 - val_loss: 0.9453 - val_accuracy: 0.7562\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8294 - accuracy: 0.7567 - val_loss: 0.9445 - val_accuracy: 0.7572\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8282 - accuracy: 0.7570 - val_loss: 0.9437 - val_accuracy: 0.7579\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8270 - accuracy: 0.7574 - val_loss: 0.9427 - val_accuracy: 0.7586\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8258 - accuracy: 0.7577 - val_loss: 0.9416 - val_accuracy: 0.7590\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8246 - accuracy: 0.7580 - val_loss: 0.9403 - val_accuracy: 0.7595\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8234 - accuracy: 0.7585 - val_loss: 0.9390 - val_accuracy: 0.7604\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8223 - accuracy: 0.7590 - val_loss: 0.9377 - val_accuracy: 0.7609\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8211 - accuracy: 0.7593 - val_loss: 0.9365 - val_accuracy: 0.7613\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8200 - accuracy: 0.7597 - val_loss: 0.9355 - val_accuracy: 0.7616\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8188 - accuracy: 0.7601 - val_loss: 0.9345 - val_accuracy: 0.7619\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8177 - accuracy: 0.7606 - val_loss: 0.9336 - val_accuracy: 0.7623\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8166 - accuracy: 0.7611 - val_loss: 0.9327 - val_accuracy: 0.7624\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8155 - accuracy: 0.7615 - val_loss: 0.9317 - val_accuracy: 0.7628\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8143 - accuracy: 0.7618 - val_loss: 0.9308 - val_accuracy: 0.7628\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8132 - accuracy: 0.7624 - val_loss: 0.9299 - val_accuracy: 0.7628\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8121 - accuracy: 0.7627 - val_loss: 0.9290 - val_accuracy: 0.7631\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8110 - accuracy: 0.7630 - val_loss: 0.9279 - val_accuracy: 0.7641\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8098 - accuracy: 0.7634 - val_loss: 0.9266 - val_accuracy: 0.7646\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8087 - accuracy: 0.7638 - val_loss: 0.9254 - val_accuracy: 0.7647\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8075 - accuracy: 0.7641 - val_loss: 0.9242 - val_accuracy: 0.7651\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8064 - accuracy: 0.7646 - val_loss: 0.9231 - val_accuracy: 0.7656\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8052 - accuracy: 0.7651 - val_loss: 0.9221 - val_accuracy: 0.7659\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8041 - accuracy: 0.7654 - val_loss: 0.9210 - val_accuracy: 0.7662\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8029 - accuracy: 0.7658 - val_loss: 0.9200 - val_accuracy: 0.7668\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8018 - accuracy: 0.7662 - val_loss: 0.9189 - val_accuracy: 0.7673\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8006 - accuracy: 0.7666 - val_loss: 0.9178 - val_accuracy: 0.7681\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7995 - accuracy: 0.7670 - val_loss: 0.9167 - val_accuracy: 0.7680\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7983 - accuracy: 0.7673 - val_loss: 0.9156 - val_accuracy: 0.7681\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7972 - accuracy: 0.7679 - val_loss: 0.9145 - val_accuracy: 0.7684\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7961 - accuracy: 0.7681 - val_loss: 0.9135 - val_accuracy: 0.7686\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7950 - accuracy: 0.7685 - val_loss: 0.9124 - val_accuracy: 0.7689\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7938 - accuracy: 0.7690 - val_loss: 0.9114 - val_accuracy: 0.7691\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7927 - accuracy: 0.7692 - val_loss: 0.9102 - val_accuracy: 0.7693\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7916 - accuracy: 0.7697 - val_loss: 0.9091 - val_accuracy: 0.7705\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7905 - accuracy: 0.7699 - val_loss: 0.9079 - val_accuracy: 0.7713\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7894 - accuracy: 0.7703 - val_loss: 0.9067 - val_accuracy: 0.7719\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7883 - accuracy: 0.7706 - val_loss: 0.9056 - val_accuracy: 0.7722\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7872 - accuracy: 0.7710 - val_loss: 0.9044 - val_accuracy: 0.7728\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7861 - accuracy: 0.7714 - val_loss: 0.9033 - val_accuracy: 0.7727\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7850 - accuracy: 0.7719 - val_loss: 0.9021 - val_accuracy: 0.7731\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7840 - accuracy: 0.7723 - val_loss: 0.9008 - val_accuracy: 0.7737\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7829 - accuracy: 0.7728 - val_loss: 0.8997 - val_accuracy: 0.7743\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7818 - accuracy: 0.7731 - val_loss: 0.8986 - val_accuracy: 0.7744\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7807 - accuracy: 0.7734 - val_loss: 0.8975 - val_accuracy: 0.7745\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7795 - accuracy: 0.7741 - val_loss: 0.8965 - val_accuracy: 0.7748\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7784 - accuracy: 0.7746 - val_loss: 0.8955 - val_accuracy: 0.7752\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7773 - accuracy: 0.7751 - val_loss: 0.8946 - val_accuracy: 0.7758\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7762 - accuracy: 0.7754 - val_loss: 0.8937 - val_accuracy: 0.7760\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7751 - accuracy: 0.7757 - val_loss: 0.8928 - val_accuracy: 0.7767\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7741 - accuracy: 0.7761 - val_loss: 0.8918 - val_accuracy: 0.7774\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7730 - accuracy: 0.7765 - val_loss: 0.8908 - val_accuracy: 0.7775\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7720 - accuracy: 0.7769 - val_loss: 0.8897 - val_accuracy: 0.7777\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7710 - accuracy: 0.7773 - val_loss: 0.8886 - val_accuracy: 0.7782\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7699 - accuracy: 0.7775 - val_loss: 0.8875 - val_accuracy: 0.7785\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7689 - accuracy: 0.7778 - val_loss: 0.8865 - val_accuracy: 0.7787\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7679 - accuracy: 0.7781 - val_loss: 0.8856 - val_accuracy: 0.7792\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7668 - accuracy: 0.7783 - val_loss: 0.8847 - val_accuracy: 0.7794\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7658 - accuracy: 0.7786 - val_loss: 0.8838 - val_accuracy: 0.7797\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7647 - accuracy: 0.7790 - val_loss: 0.8829 - val_accuracy: 0.7793\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7637 - accuracy: 0.7794 - val_loss: 0.8820 - val_accuracy: 0.7795\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7627 - accuracy: 0.7796 - val_loss: 0.8810 - val_accuracy: 0.7795\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7616 - accuracy: 0.7798 - val_loss: 0.8800 - val_accuracy: 0.7799\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7606 - accuracy: 0.7802 - val_loss: 0.8789 - val_accuracy: 0.7800\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7596 - accuracy: 0.7804 - val_loss: 0.8778 - val_accuracy: 0.7802\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7586 - accuracy: 0.7807 - val_loss: 0.8768 - val_accuracy: 0.7808\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7576 - accuracy: 0.7809 - val_loss: 0.8759 - val_accuracy: 0.7809\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7566 - accuracy: 0.7811 - val_loss: 0.8750 - val_accuracy: 0.7809\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7556 - accuracy: 0.7813 - val_loss: 0.8741 - val_accuracy: 0.7810\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7547 - accuracy: 0.7816 - val_loss: 0.8732 - val_accuracy: 0.7811\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7537 - accuracy: 0.7819 - val_loss: 0.8723 - val_accuracy: 0.7815\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7527 - accuracy: 0.7823 - val_loss: 0.8712 - val_accuracy: 0.7819\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7518 - accuracy: 0.7826 - val_loss: 0.8702 - val_accuracy: 0.7822\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7508 - accuracy: 0.7829 - val_loss: 0.8692 - val_accuracy: 0.7823\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7499 - accuracy: 0.7832 - val_loss: 0.8683 - val_accuracy: 0.7827\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7489 - accuracy: 0.7835 - val_loss: 0.8674 - val_accuracy: 0.7830\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7480 - accuracy: 0.7839 - val_loss: 0.8666 - val_accuracy: 0.7836\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7470 - accuracy: 0.7842 - val_loss: 0.8659 - val_accuracy: 0.7840\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7461 - accuracy: 0.7843 - val_loss: 0.8651 - val_accuracy: 0.7843\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7452 - accuracy: 0.7844 - val_loss: 0.8642 - val_accuracy: 0.7847\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7442 - accuracy: 0.7846 - val_loss: 0.8633 - val_accuracy: 0.7852\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7433 - accuracy: 0.7850 - val_loss: 0.8623 - val_accuracy: 0.7861\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7424 - accuracy: 0.7853 - val_loss: 0.8613 - val_accuracy: 0.7858\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7415 - accuracy: 0.7854 - val_loss: 0.8604 - val_accuracy: 0.7864\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7406 - accuracy: 0.7857 - val_loss: 0.8594 - val_accuracy: 0.7867\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7397 - accuracy: 0.7858 - val_loss: 0.8585 - val_accuracy: 0.7869\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7388 - accuracy: 0.7861 - val_loss: 0.8576 - val_accuracy: 0.7868\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7379 - accuracy: 0.7863 - val_loss: 0.8568 - val_accuracy: 0.7870\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7370 - accuracy: 0.7863 - val_loss: 0.8559 - val_accuracy: 0.7871\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7360 - accuracy: 0.7865 - val_loss: 0.8550 - val_accuracy: 0.7871\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7351 - accuracy: 0.7868 - val_loss: 0.8540 - val_accuracy: 0.7875\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7342 - accuracy: 0.7869 - val_loss: 0.8532 - val_accuracy: 0.7880\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7333 - accuracy: 0.7869 - val_loss: 0.8523 - val_accuracy: 0.7878\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7324 - accuracy: 0.7870 - val_loss: 0.8516 - val_accuracy: 0.7877\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7315 - accuracy: 0.7874 - val_loss: 0.8509 - val_accuracy: 0.7881\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7306 - accuracy: 0.7876 - val_loss: 0.8501 - val_accuracy: 0.7883\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7297 - accuracy: 0.7878 - val_loss: 0.8493 - val_accuracy: 0.7884\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7288 - accuracy: 0.7880 - val_loss: 0.8484 - val_accuracy: 0.7880\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7279 - accuracy: 0.7882 - val_loss: 0.8475 - val_accuracy: 0.7890\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7270 - accuracy: 0.7885 - val_loss: 0.8466 - val_accuracy: 0.7891\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7261 - accuracy: 0.7887 - val_loss: 0.8456 - val_accuracy: 0.7895\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7253 - accuracy: 0.7888 - val_loss: 0.8447 - val_accuracy: 0.7901\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7244 - accuracy: 0.7891 - val_loss: 0.8438 - val_accuracy: 0.7903\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7235 - accuracy: 0.7894 - val_loss: 0.8429 - val_accuracy: 0.7905\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7226 - accuracy: 0.7895 - val_loss: 0.8420 - val_accuracy: 0.7909\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7218 - accuracy: 0.7897 - val_loss: 0.8411 - val_accuracy: 0.7912\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7209 - accuracy: 0.7900 - val_loss: 0.8402 - val_accuracy: 0.7914\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7201 - accuracy: 0.7902 - val_loss: 0.8393 - val_accuracy: 0.7917\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7193 - accuracy: 0.7904 - val_loss: 0.8385 - val_accuracy: 0.7915\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7184 - accuracy: 0.7906 - val_loss: 0.8377 - val_accuracy: 0.7915\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7176 - accuracy: 0.7908 - val_loss: 0.8369 - val_accuracy: 0.7915\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7167 - accuracy: 0.7910 - val_loss: 0.8362 - val_accuracy: 0.7913\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7159 - accuracy: 0.7912 - val_loss: 0.8354 - val_accuracy: 0.7919\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7151 - accuracy: 0.7914 - val_loss: 0.8346 - val_accuracy: 0.7920\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7142 - accuracy: 0.7915 - val_loss: 0.8338 - val_accuracy: 0.7923\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7134 - accuracy: 0.7917 - val_loss: 0.8329 - val_accuracy: 0.7926\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7126 - accuracy: 0.7918 - val_loss: 0.8320 - val_accuracy: 0.7928\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7117 - accuracy: 0.7920 - val_loss: 0.8311 - val_accuracy: 0.7928\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7109 - accuracy: 0.7922 - val_loss: 0.8303 - val_accuracy: 0.7932\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7101 - accuracy: 0.7923 - val_loss: 0.8295 - val_accuracy: 0.7935\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7092 - accuracy: 0.7928 - val_loss: 0.8289 - val_accuracy: 0.7939\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7084 - accuracy: 0.7932 - val_loss: 0.8282 - val_accuracy: 0.7942\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7075 - accuracy: 0.7935 - val_loss: 0.8276 - val_accuracy: 0.7945\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7067 - accuracy: 0.7940 - val_loss: 0.8270 - val_accuracy: 0.7947\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7059 - accuracy: 0.7942 - val_loss: 0.8264 - val_accuracy: 0.7952\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7051 - accuracy: 0.7944 - val_loss: 0.8257 - val_accuracy: 0.7954\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7043 - accuracy: 0.7946 - val_loss: 0.8250 - val_accuracy: 0.7957\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7035 - accuracy: 0.7949 - val_loss: 0.8243 - val_accuracy: 0.7958\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7027 - accuracy: 0.7951 - val_loss: 0.8236 - val_accuracy: 0.7961\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7019 - accuracy: 0.7953 - val_loss: 0.8228 - val_accuracy: 0.7963\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7011 - accuracy: 0.7953 - val_loss: 0.8220 - val_accuracy: 0.7967\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7003 - accuracy: 0.7958 - val_loss: 0.8212 - val_accuracy: 0.7966\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6995 - accuracy: 0.7959 - val_loss: 0.8204 - val_accuracy: 0.7965\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6987 - accuracy: 0.7962 - val_loss: 0.8196 - val_accuracy: 0.7967\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6979 - accuracy: 0.7964 - val_loss: 0.8188 - val_accuracy: 0.7967\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6971 - accuracy: 0.7966 - val_loss: 0.8180 - val_accuracy: 0.7968\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6963 - accuracy: 0.7969 - val_loss: 0.8172 - val_accuracy: 0.7970\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6956 - accuracy: 0.7971 - val_loss: 0.8165 - val_accuracy: 0.7972\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6948 - accuracy: 0.7971 - val_loss: 0.8158 - val_accuracy: 0.7976\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6940 - accuracy: 0.7973 - val_loss: 0.8150 - val_accuracy: 0.7977\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6932 - accuracy: 0.7974 - val_loss: 0.8142 - val_accuracy: 0.7978\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6925 - accuracy: 0.7976 - val_loss: 0.8134 - val_accuracy: 0.7979\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6917 - accuracy: 0.7979 - val_loss: 0.8126 - val_accuracy: 0.7983\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6909 - accuracy: 0.7984 - val_loss: 0.8118 - val_accuracy: 0.7986\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6901 - accuracy: 0.7987 - val_loss: 0.8110 - val_accuracy: 0.7988\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6894 - accuracy: 0.7987 - val_loss: 0.8103 - val_accuracy: 0.7986\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6886 - accuracy: 0.7990 - val_loss: 0.8096 - val_accuracy: 0.7987\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6878 - accuracy: 0.7993 - val_loss: 0.8088 - val_accuracy: 0.7990\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6871 - accuracy: 0.7994 - val_loss: 0.8080 - val_accuracy: 0.7989\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6863 - accuracy: 0.7998 - val_loss: 0.8073 - val_accuracy: 0.7993\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6856 - accuracy: 0.8000 - val_loss: 0.8066 - val_accuracy: 0.7995\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6848 - accuracy: 0.8002 - val_loss: 0.8060 - val_accuracy: 0.7996\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6841 - accuracy: 0.8006 - val_loss: 0.8054 - val_accuracy: 0.7999\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6834 - accuracy: 0.8009 - val_loss: 0.8048 - val_accuracy: 0.8002\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6826 - accuracy: 0.8012 - val_loss: 0.8042 - val_accuracy: 0.8003\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6819 - accuracy: 0.8013 - val_loss: 0.8036 - val_accuracy: 0.8003\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6812 - accuracy: 0.8015 - val_loss: 0.8029 - val_accuracy: 0.8003\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6805 - accuracy: 0.8017 - val_loss: 0.8023 - val_accuracy: 0.8003\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6798 - accuracy: 0.8019 - val_loss: 0.8017 - val_accuracy: 0.8004\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6790 - accuracy: 0.8021 - val_loss: 0.8011 - val_accuracy: 0.8005\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6783 - accuracy: 0.8023 - val_loss: 0.8005 - val_accuracy: 0.8010\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6776 - accuracy: 0.8025 - val_loss: 0.7999 - val_accuracy: 0.8010\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6768 - accuracy: 0.8027 - val_loss: 0.7994 - val_accuracy: 0.8010\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6761 - accuracy: 0.8030 - val_loss: 0.7988 - val_accuracy: 0.8010\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6754 - accuracy: 0.8033 - val_loss: 0.7982 - val_accuracy: 0.8014\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6746 - accuracy: 0.8037 - val_loss: 0.7976 - val_accuracy: 0.8018\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6739 - accuracy: 0.8039 - val_loss: 0.7970 - val_accuracy: 0.8018\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6731 - accuracy: 0.8041 - val_loss: 0.7964 - val_accuracy: 0.8018\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6724 - accuracy: 0.8042 - val_loss: 0.7958 - val_accuracy: 0.8019\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6717 - accuracy: 0.8043 - val_loss: 0.7951 - val_accuracy: 0.8020\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6710 - accuracy: 0.8044 - val_loss: 0.7945 - val_accuracy: 0.8026\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6703 - accuracy: 0.8045 - val_loss: 0.7938 - val_accuracy: 0.8025\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6696 - accuracy: 0.8046 - val_loss: 0.7931 - val_accuracy: 0.8026\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6689 - accuracy: 0.8048 - val_loss: 0.7924 - val_accuracy: 0.8027\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6683 - accuracy: 0.8049 - val_loss: 0.7918 - val_accuracy: 0.8027\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6676 - accuracy: 0.8051 - val_loss: 0.7911 - val_accuracy: 0.8029\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6669 - accuracy: 0.8051 - val_loss: 0.7904 - val_accuracy: 0.8030\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6662 - accuracy: 0.8052 - val_loss: 0.7898 - val_accuracy: 0.8029\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6655 - accuracy: 0.8053 - val_loss: 0.7892 - val_accuracy: 0.8031\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6648 - accuracy: 0.8055 - val_loss: 0.7885 - val_accuracy: 0.8032\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6642 - accuracy: 0.8056 - val_loss: 0.7879 - val_accuracy: 0.8033\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6635 - accuracy: 0.8059 - val_loss: 0.7873 - val_accuracy: 0.8036\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6628 - accuracy: 0.8062 - val_loss: 0.7867 - val_accuracy: 0.8038\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6621 - accuracy: 0.8063 - val_loss: 0.7861 - val_accuracy: 0.8040\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6614 - accuracy: 0.8065 - val_loss: 0.7855 - val_accuracy: 0.8040\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6607 - accuracy: 0.8068 - val_loss: 0.7850 - val_accuracy: 0.8040\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6601 - accuracy: 0.8067 - val_loss: 0.7844 - val_accuracy: 0.8042\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6594 - accuracy: 0.8071 - val_loss: 0.7838 - val_accuracy: 0.8042\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6587 - accuracy: 0.8073 - val_loss: 0.7832 - val_accuracy: 0.8043\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6580 - accuracy: 0.8076 - val_loss: 0.7826 - val_accuracy: 0.8042\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6573 - accuracy: 0.8078 - val_loss: 0.7819 - val_accuracy: 0.8044\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6566 - accuracy: 0.8079 - val_loss: 0.7813 - val_accuracy: 0.8045\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6559 - accuracy: 0.8079 - val_loss: 0.7807 - val_accuracy: 0.8047\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6552 - accuracy: 0.8082 - val_loss: 0.7801 - val_accuracy: 0.8048\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6545 - accuracy: 0.8084 - val_loss: 0.7795 - val_accuracy: 0.8049\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6538 - accuracy: 0.8086 - val_loss: 0.7790 - val_accuracy: 0.8049\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6531 - accuracy: 0.8087 - val_loss: 0.7783 - val_accuracy: 0.8050\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6524 - accuracy: 0.8089 - val_loss: 0.7777 - val_accuracy: 0.8053\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6517 - accuracy: 0.8091 - val_loss: 0.7771 - val_accuracy: 0.8055\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6510 - accuracy: 0.8094 - val_loss: 0.7765 - val_accuracy: 0.8057\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6503 - accuracy: 0.8096 - val_loss: 0.7758 - val_accuracy: 0.8059\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6497 - accuracy: 0.8097 - val_loss: 0.7751 - val_accuracy: 0.8063\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6490 - accuracy: 0.8100 - val_loss: 0.7744 - val_accuracy: 0.8064\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6483 - accuracy: 0.8102 - val_loss: 0.7737 - val_accuracy: 0.8066\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6476 - accuracy: 0.8104 - val_loss: 0.7730 - val_accuracy: 0.8067\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6470 - accuracy: 0.8106 - val_loss: 0.7723 - val_accuracy: 0.8069\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6463 - accuracy: 0.8108 - val_loss: 0.7716 - val_accuracy: 0.8070\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6456 - accuracy: 0.8110 - val_loss: 0.7709 - val_accuracy: 0.8070\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6450 - accuracy: 0.8109 - val_loss: 0.7703 - val_accuracy: 0.8074\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6443 - accuracy: 0.8111 - val_loss: 0.7697 - val_accuracy: 0.8077\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6436 - accuracy: 0.8115 - val_loss: 0.7690 - val_accuracy: 0.8082\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6430 - accuracy: 0.8117 - val_loss: 0.7684 - val_accuracy: 0.8083\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6423 - accuracy: 0.8119 - val_loss: 0.7677 - val_accuracy: 0.8084\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6417 - accuracy: 0.8120 - val_loss: 0.7671 - val_accuracy: 0.8084\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6410 - accuracy: 0.8122 - val_loss: 0.7664 - val_accuracy: 0.8087\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6404 - accuracy: 0.8123 - val_loss: 0.7658 - val_accuracy: 0.8088\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6397 - accuracy: 0.8123 - val_loss: 0.7652 - val_accuracy: 0.8091\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6391 - accuracy: 0.8125 - val_loss: 0.7646 - val_accuracy: 0.8088\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6385 - accuracy: 0.8126 - val_loss: 0.7640 - val_accuracy: 0.8087\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6378 - accuracy: 0.8126 - val_loss: 0.7634 - val_accuracy: 0.8088\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6372 - accuracy: 0.8127 - val_loss: 0.7628 - val_accuracy: 0.8089\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6366 - accuracy: 0.8130 - val_loss: 0.7622 - val_accuracy: 0.8090\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6360 - accuracy: 0.8130 - val_loss: 0.7616 - val_accuracy: 0.8092\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6353 - accuracy: 0.8131 - val_loss: 0.7610 - val_accuracy: 0.8092\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6347 - accuracy: 0.8133 - val_loss: 0.7604 - val_accuracy: 0.8092\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6341 - accuracy: 0.8134 - val_loss: 0.7598 - val_accuracy: 0.8095\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6335 - accuracy: 0.8135 - val_loss: 0.7592 - val_accuracy: 0.8096\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6329 - accuracy: 0.8136 - val_loss: 0.7586 - val_accuracy: 0.8099\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6323 - accuracy: 0.8138 - val_loss: 0.7581 - val_accuracy: 0.8100\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6316 - accuracy: 0.8139 - val_loss: 0.7575 - val_accuracy: 0.8100\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6310 - accuracy: 0.8140 - val_loss: 0.7569 - val_accuracy: 0.8102\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6304 - accuracy: 0.8141 - val_loss: 0.7563 - val_accuracy: 0.8105\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6298 - accuracy: 0.8143 - val_loss: 0.7557 - val_accuracy: 0.8104\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6292 - accuracy: 0.8146 - val_loss: 0.7550 - val_accuracy: 0.8105\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6286 - accuracy: 0.8148 - val_loss: 0.7544 - val_accuracy: 0.8106\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6280 - accuracy: 0.8149 - val_loss: 0.7538 - val_accuracy: 0.8106\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6274 - accuracy: 0.8151 - val_loss: 0.7532 - val_accuracy: 0.8106\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6268 - accuracy: 0.8154 - val_loss: 0.7526 - val_accuracy: 0.8107\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6262 - accuracy: 0.8156 - val_loss: 0.7521 - val_accuracy: 0.8110\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6256 - accuracy: 0.8158 - val_loss: 0.7515 - val_accuracy: 0.8111\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6250 - accuracy: 0.8159 - val_loss: 0.7509 - val_accuracy: 0.8114\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6244 - accuracy: 0.8162 - val_loss: 0.7503 - val_accuracy: 0.8117\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6238 - accuracy: 0.8164 - val_loss: 0.7497 - val_accuracy: 0.8115\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6232 - accuracy: 0.8166 - val_loss: 0.7490 - val_accuracy: 0.8118\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6226 - accuracy: 0.8168 - val_loss: 0.7483 - val_accuracy: 0.8121\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6220 - accuracy: 0.8169 - val_loss: 0.7476 - val_accuracy: 0.8122\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6214 - accuracy: 0.8170 - val_loss: 0.7469 - val_accuracy: 0.8128\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6208 - accuracy: 0.8173 - val_loss: 0.7463 - val_accuracy: 0.8128\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6202 - accuracy: 0.8175 - val_loss: 0.7456 - val_accuracy: 0.8128\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6196 - accuracy: 0.8178 - val_loss: 0.7450 - val_accuracy: 0.8131\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6190 - accuracy: 0.8180 - val_loss: 0.7443 - val_accuracy: 0.8133\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6184 - accuracy: 0.8182 - val_loss: 0.7437 - val_accuracy: 0.8134\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6178 - accuracy: 0.8184 - val_loss: 0.7430 - val_accuracy: 0.8135\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6172 - accuracy: 0.8185 - val_loss: 0.7423 - val_accuracy: 0.8139\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6166 - accuracy: 0.8188 - val_loss: 0.7416 - val_accuracy: 0.8143\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6160 - accuracy: 0.8188 - val_loss: 0.7409 - val_accuracy: 0.8145\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6154 - accuracy: 0.8188 - val_loss: 0.7402 - val_accuracy: 0.8149\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6148 - accuracy: 0.8190 - val_loss: 0.7395 - val_accuracy: 0.8150\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6142 - accuracy: 0.8193 - val_loss: 0.7389 - val_accuracy: 0.8150\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6137 - accuracy: 0.8195 - val_loss: 0.7382 - val_accuracy: 0.8152\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6131 - accuracy: 0.8197 - val_loss: 0.7375 - val_accuracy: 0.8153\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6125 - accuracy: 0.8199 - val_loss: 0.7368 - val_accuracy: 0.8156\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6120 - accuracy: 0.8202 - val_loss: 0.7362 - val_accuracy: 0.8160\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6114 - accuracy: 0.8203 - val_loss: 0.7356 - val_accuracy: 0.8166\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6108 - accuracy: 0.8204 - val_loss: 0.7350 - val_accuracy: 0.8166\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6103 - accuracy: 0.8206 - val_loss: 0.7344 - val_accuracy: 0.8167\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6097 - accuracy: 0.8207 - val_loss: 0.7338 - val_accuracy: 0.8170\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6091 - accuracy: 0.8209 - val_loss: 0.7332 - val_accuracy: 0.8169\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6086 - accuracy: 0.8211 - val_loss: 0.7326 - val_accuracy: 0.8170\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6080 - accuracy: 0.8212 - val_loss: 0.7320 - val_accuracy: 0.8170\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6075 - accuracy: 0.8213 - val_loss: 0.7314 - val_accuracy: 0.8168\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6069 - accuracy: 0.8214 - val_loss: 0.7308 - val_accuracy: 0.8173\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6063 - accuracy: 0.8217 - val_loss: 0.7303 - val_accuracy: 0.8180\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6057 - accuracy: 0.8220 - val_loss: 0.7297 - val_accuracy: 0.8184\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6052 - accuracy: 0.8222 - val_loss: 0.7292 - val_accuracy: 0.8190\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6046 - accuracy: 0.8224 - val_loss: 0.7287 - val_accuracy: 0.8190\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6040 - accuracy: 0.8227 - val_loss: 0.7281 - val_accuracy: 0.8191\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6034 - accuracy: 0.8228 - val_loss: 0.7276 - val_accuracy: 0.8192\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6028 - accuracy: 0.8231 - val_loss: 0.7271 - val_accuracy: 0.8195\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6021 - accuracy: 0.8232 - val_loss: 0.7266 - val_accuracy: 0.8196\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6015 - accuracy: 0.8235 - val_loss: 0.7261 - val_accuracy: 0.8196\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6009 - accuracy: 0.8238 - val_loss: 0.7256 - val_accuracy: 0.8199\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6003 - accuracy: 0.8239 - val_loss: 0.7251 - val_accuracy: 0.8201\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5997 - accuracy: 0.8242 - val_loss: 0.7246 - val_accuracy: 0.8204\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5991 - accuracy: 0.8244 - val_loss: 0.7240 - val_accuracy: 0.8204\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5985 - accuracy: 0.8247 - val_loss: 0.7235 - val_accuracy: 0.8205\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5979 - accuracy: 0.8249 - val_loss: 0.7230 - val_accuracy: 0.8207\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5973 - accuracy: 0.8252 - val_loss: 0.7224 - val_accuracy: 0.8208\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5968 - accuracy: 0.8254 - val_loss: 0.7219 - val_accuracy: 0.8208\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5962 - accuracy: 0.8255 - val_loss: 0.7213 - val_accuracy: 0.8210\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5956 - accuracy: 0.8257 - val_loss: 0.7208 - val_accuracy: 0.8213\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5950 - accuracy: 0.8260 - val_loss: 0.7202 - val_accuracy: 0.8217\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5945 - accuracy: 0.8260 - val_loss: 0.7197 - val_accuracy: 0.8220\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5939 - accuracy: 0.8262 - val_loss: 0.7191 - val_accuracy: 0.8218\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5933 - accuracy: 0.8263 - val_loss: 0.7186 - val_accuracy: 0.8220\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5928 - accuracy: 0.8264 - val_loss: 0.7180 - val_accuracy: 0.8221\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5922 - accuracy: 0.8265 - val_loss: 0.7174 - val_accuracy: 0.8222\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5917 - accuracy: 0.8266 - val_loss: 0.7168 - val_accuracy: 0.8224\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5911 - accuracy: 0.8268 - val_loss: 0.7162 - val_accuracy: 0.8228\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5905 - accuracy: 0.8271 - val_loss: 0.7156 - val_accuracy: 0.8232\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5899 - accuracy: 0.8274 - val_loss: 0.7150 - val_accuracy: 0.8232\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5894 - accuracy: 0.8275 - val_loss: 0.7145 - val_accuracy: 0.8235\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5888 - accuracy: 0.8280 - val_loss: 0.7140 - val_accuracy: 0.8237\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5882 - accuracy: 0.8282 - val_loss: 0.7135 - val_accuracy: 0.8240\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5876 - accuracy: 0.8285 - val_loss: 0.7130 - val_accuracy: 0.8246\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5870 - accuracy: 0.8286 - val_loss: 0.7125 - val_accuracy: 0.8251\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5864 - accuracy: 0.8288 - val_loss: 0.7119 - val_accuracy: 0.8253\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5858 - accuracy: 0.8290 - val_loss: 0.7114 - val_accuracy: 0.8254\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5852 - accuracy: 0.8292 - val_loss: 0.7108 - val_accuracy: 0.8255\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5846 - accuracy: 0.8294 - val_loss: 0.7103 - val_accuracy: 0.8257\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5840 - accuracy: 0.8295 - val_loss: 0.7097 - val_accuracy: 0.8256\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5834 - accuracy: 0.8297 - val_loss: 0.7092 - val_accuracy: 0.8254\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5829 - accuracy: 0.8299 - val_loss: 0.7086 - val_accuracy: 0.8255\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5823 - accuracy: 0.8299 - val_loss: 0.7080 - val_accuracy: 0.8253\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5817 - accuracy: 0.8300 - val_loss: 0.7074 - val_accuracy: 0.8253\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5811 - accuracy: 0.8300 - val_loss: 0.7068 - val_accuracy: 0.8256\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5805 - accuracy: 0.8301 - val_loss: 0.7061 - val_accuracy: 0.8257\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5800 - accuracy: 0.8303 - val_loss: 0.7055 - val_accuracy: 0.8258\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5794 - accuracy: 0.8304 - val_loss: 0.7049 - val_accuracy: 0.8260\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5788 - accuracy: 0.8306 - val_loss: 0.7044 - val_accuracy: 0.8258\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5782 - accuracy: 0.8309 - val_loss: 0.7038 - val_accuracy: 0.8259\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5776 - accuracy: 0.8311 - val_loss: 0.7032 - val_accuracy: 0.8262\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5770 - accuracy: 0.8314 - val_loss: 0.7026 - val_accuracy: 0.8264\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5764 - accuracy: 0.8319 - val_loss: 0.7020 - val_accuracy: 0.8269\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5758 - accuracy: 0.8321 - val_loss: 0.7015 - val_accuracy: 0.8271\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5752 - accuracy: 0.8323 - val_loss: 0.7010 - val_accuracy: 0.8273\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5747 - accuracy: 0.8325 - val_loss: 0.7004 - val_accuracy: 0.8274\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5741 - accuracy: 0.8327 - val_loss: 0.6998 - val_accuracy: 0.8273\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5735 - accuracy: 0.8329 - val_loss: 0.6992 - val_accuracy: 0.8273\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5730 - accuracy: 0.8330 - val_loss: 0.6986 - val_accuracy: 0.8276\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5724 - accuracy: 0.8331 - val_loss: 0.6981 - val_accuracy: 0.8281\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5719 - accuracy: 0.8333 - val_loss: 0.6975 - val_accuracy: 0.8282\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5713 - accuracy: 0.8333 - val_loss: 0.6969 - val_accuracy: 0.8282\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5708 - accuracy: 0.8334 - val_loss: 0.6963 - val_accuracy: 0.8285\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5702 - accuracy: 0.8336 - val_loss: 0.6958 - val_accuracy: 0.8287\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5697 - accuracy: 0.8339 - val_loss: 0.6952 - val_accuracy: 0.8288\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5691 - accuracy: 0.8340 - val_loss: 0.6946 - val_accuracy: 0.8288\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5686 - accuracy: 0.8341 - val_loss: 0.6940 - val_accuracy: 0.8290\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5680 - accuracy: 0.8342 - val_loss: 0.6934 - val_accuracy: 0.8290\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5675 - accuracy: 0.8343 - val_loss: 0.6927 - val_accuracy: 0.8290\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5669 - accuracy: 0.8346 - val_loss: 0.6921 - val_accuracy: 0.8294\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5664 - accuracy: 0.8347 - val_loss: 0.6915 - val_accuracy: 0.8295\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5658 - accuracy: 0.8350 - val_loss: 0.6909 - val_accuracy: 0.8295\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5652 - accuracy: 0.8353 - val_loss: 0.6903 - val_accuracy: 0.8294\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5647 - accuracy: 0.8354 - val_loss: 0.6897 - val_accuracy: 0.8295\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5641 - accuracy: 0.8357 - val_loss: 0.6891 - val_accuracy: 0.8297\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5636 - accuracy: 0.8358 - val_loss: 0.6886 - val_accuracy: 0.8297\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5631 - accuracy: 0.8359 - val_loss: 0.6880 - val_accuracy: 0.8300\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5625 - accuracy: 0.8359 - val_loss: 0.6874 - val_accuracy: 0.8299\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5620 - accuracy: 0.8360 - val_loss: 0.6867 - val_accuracy: 0.8296\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5615 - accuracy: 0.8360 - val_loss: 0.6861 - val_accuracy: 0.8297\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5610 - accuracy: 0.8362 - val_loss: 0.6855 - val_accuracy: 0.8299\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5604 - accuracy: 0.8364 - val_loss: 0.6848 - val_accuracy: 0.8302\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5599 - accuracy: 0.8365 - val_loss: 0.6842 - val_accuracy: 0.8307\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5594 - accuracy: 0.8366 - val_loss: 0.6835 - val_accuracy: 0.8310\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5589 - accuracy: 0.8368 - val_loss: 0.6829 - val_accuracy: 0.8314\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5584 - accuracy: 0.8367 - val_loss: 0.6822 - val_accuracy: 0.8314\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5579 - accuracy: 0.8368 - val_loss: 0.6817 - val_accuracy: 0.8316\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5574 - accuracy: 0.8369 - val_loss: 0.6811 - val_accuracy: 0.8314\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5568 - accuracy: 0.8371 - val_loss: 0.6805 - val_accuracy: 0.8311\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5563 - accuracy: 0.8372 - val_loss: 0.6800 - val_accuracy: 0.8313\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5558 - accuracy: 0.8374 - val_loss: 0.6794 - val_accuracy: 0.8314\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5553 - accuracy: 0.8374 - val_loss: 0.6789 - val_accuracy: 0.8312\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5548 - accuracy: 0.8376 - val_loss: 0.6784 - val_accuracy: 0.8313\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5543 - accuracy: 0.8378 - val_loss: 0.6778 - val_accuracy: 0.8313\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5538 - accuracy: 0.8379 - val_loss: 0.6773 - val_accuracy: 0.8315\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5533 - accuracy: 0.8381 - val_loss: 0.6768 - val_accuracy: 0.8316\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5528 - accuracy: 0.8383 - val_loss: 0.6763 - val_accuracy: 0.8319\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5523 - accuracy: 0.8384 - val_loss: 0.6758 - val_accuracy: 0.8318\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5518 - accuracy: 0.8386 - val_loss: 0.6753 - val_accuracy: 0.8320\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5513 - accuracy: 0.8387 - val_loss: 0.6748 - val_accuracy: 0.8322\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5509 - accuracy: 0.8389 - val_loss: 0.6744 - val_accuracy: 0.8324\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5504 - accuracy: 0.8391 - val_loss: 0.6739 - val_accuracy: 0.8325\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5499 - accuracy: 0.8391 - val_loss: 0.6734 - val_accuracy: 0.8328\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5494 - accuracy: 0.8394 - val_loss: 0.6730 - val_accuracy: 0.8328\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5489 - accuracy: 0.8395 - val_loss: 0.6725 - val_accuracy: 0.8328\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5484 - accuracy: 0.8398 - val_loss: 0.6720 - val_accuracy: 0.8335\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5479 - accuracy: 0.8399 - val_loss: 0.6716 - val_accuracy: 0.8340\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5475 - accuracy: 0.8401 - val_loss: 0.6711 - val_accuracy: 0.8340\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5470 - accuracy: 0.8402 - val_loss: 0.6707 - val_accuracy: 0.8337\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5465 - accuracy: 0.8403 - val_loss: 0.6702 - val_accuracy: 0.8338\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5460 - accuracy: 0.8406 - val_loss: 0.6698 - val_accuracy: 0.8340\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5455 - accuracy: 0.8408 - val_loss: 0.6693 - val_accuracy: 0.8342\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5450 - accuracy: 0.8408 - val_loss: 0.6688 - val_accuracy: 0.8345\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5446 - accuracy: 0.8409 - val_loss: 0.6684 - val_accuracy: 0.8346\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5441 - accuracy: 0.8412 - val_loss: 0.6679 - val_accuracy: 0.8347\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5436 - accuracy: 0.8414 - val_loss: 0.6674 - val_accuracy: 0.8348\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5431 - accuracy: 0.8415 - val_loss: 0.6669 - val_accuracy: 0.8348\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5426 - accuracy: 0.8416 - val_loss: 0.6665 - val_accuracy: 0.8352\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5421 - accuracy: 0.8417 - val_loss: 0.6660 - val_accuracy: 0.8352\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5416 - accuracy: 0.8420 - val_loss: 0.6656 - val_accuracy: 0.8356\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5411 - accuracy: 0.8421 - val_loss: 0.6651 - val_accuracy: 0.8359\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5407 - accuracy: 0.8422 - val_loss: 0.6647 - val_accuracy: 0.8360\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5402 - accuracy: 0.8424 - val_loss: 0.6642 - val_accuracy: 0.8363\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5397 - accuracy: 0.8425 - val_loss: 0.6637 - val_accuracy: 0.8369\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5392 - accuracy: 0.8427 - val_loss: 0.6632 - val_accuracy: 0.8371\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5387 - accuracy: 0.8429 - val_loss: 0.6628 - val_accuracy: 0.8372\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5383 - accuracy: 0.8430 - val_loss: 0.6623 - val_accuracy: 0.8379\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5378 - accuracy: 0.8431 - val_loss: 0.6618 - val_accuracy: 0.8381\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5373 - accuracy: 0.8433 - val_loss: 0.6614 - val_accuracy: 0.8381\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5369 - accuracy: 0.8434 - val_loss: 0.6609 - val_accuracy: 0.8381\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5364 - accuracy: 0.8435 - val_loss: 0.6605 - val_accuracy: 0.8382\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5359 - accuracy: 0.8436 - val_loss: 0.6600 - val_accuracy: 0.8383\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5355 - accuracy: 0.8438 - val_loss: 0.6596 - val_accuracy: 0.8384\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5350 - accuracy: 0.8438 - val_loss: 0.6592 - val_accuracy: 0.8384\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5346 - accuracy: 0.8439 - val_loss: 0.6588 - val_accuracy: 0.8384\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.5341 - accuracy: 0.8440 - val_loss: 0.6584 - val_accuracy: 0.8388\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5336 - accuracy: 0.8443 - val_loss: 0.6579 - val_accuracy: 0.8388\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5332 - accuracy: 0.8445 - val_loss: 0.6575 - val_accuracy: 0.8385\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5327 - accuracy: 0.8445 - val_loss: 0.6570 - val_accuracy: 0.8388\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5322 - accuracy: 0.8446 - val_loss: 0.6566 - val_accuracy: 0.8390\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5318 - accuracy: 0.8447 - val_loss: 0.6562 - val_accuracy: 0.8390\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5313 - accuracy: 0.8449 - val_loss: 0.6557 - val_accuracy: 0.8390\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5308 - accuracy: 0.8450 - val_loss: 0.6553 - val_accuracy: 0.8391\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5304 - accuracy: 0.8450 - val_loss: 0.6548 - val_accuracy: 0.8390\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5299 - accuracy: 0.8452 - val_loss: 0.6544 - val_accuracy: 0.8392\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5295 - accuracy: 0.8452 - val_loss: 0.6539 - val_accuracy: 0.8393\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5290 - accuracy: 0.8454 - val_loss: 0.6535 - val_accuracy: 0.8394\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5285 - accuracy: 0.8456 - val_loss: 0.6530 - val_accuracy: 0.8395\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5281 - accuracy: 0.8457 - val_loss: 0.6525 - val_accuracy: 0.8397\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5276 - accuracy: 0.8459 - val_loss: 0.6520 - val_accuracy: 0.8398\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5272 - accuracy: 0.8459 - val_loss: 0.6515 - val_accuracy: 0.8400\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5267 - accuracy: 0.8459 - val_loss: 0.6510 - val_accuracy: 0.8405\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5262 - accuracy: 0.8461 - val_loss: 0.6505 - val_accuracy: 0.8407\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5258 - accuracy: 0.8463 - val_loss: 0.6500 - val_accuracy: 0.8409\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5253 - accuracy: 0.8465 - val_loss: 0.6495 - val_accuracy: 0.8411\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5248 - accuracy: 0.8466 - val_loss: 0.6490 - val_accuracy: 0.8413\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5244 - accuracy: 0.8466 - val_loss: 0.6485 - val_accuracy: 0.8414\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5239 - accuracy: 0.8468 - val_loss: 0.6480 - val_accuracy: 0.8417\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5235 - accuracy: 0.8470 - val_loss: 0.6476 - val_accuracy: 0.8419\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5230 - accuracy: 0.8472 - val_loss: 0.6471 - val_accuracy: 0.8421\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5225 - accuracy: 0.8474 - val_loss: 0.6465 - val_accuracy: 0.8427\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5221 - accuracy: 0.8475 - val_loss: 0.6460 - val_accuracy: 0.8428\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5216 - accuracy: 0.8475 - val_loss: 0.6455 - val_accuracy: 0.8427\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5212 - accuracy: 0.8477 - val_loss: 0.6449 - val_accuracy: 0.8428\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5207 - accuracy: 0.8478 - val_loss: 0.6444 - val_accuracy: 0.8428\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5202 - accuracy: 0.8479 - val_loss: 0.6438 - val_accuracy: 0.8430\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5198 - accuracy: 0.8479 - val_loss: 0.6433 - val_accuracy: 0.8432\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5193 - accuracy: 0.8480 - val_loss: 0.6428 - val_accuracy: 0.8432\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5189 - accuracy: 0.8482 - val_loss: 0.6423 - val_accuracy: 0.8431\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5184 - accuracy: 0.8484 - val_loss: 0.6418 - val_accuracy: 0.8432\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5179 - accuracy: 0.8486 - val_loss: 0.6413 - val_accuracy: 0.8436\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5175 - accuracy: 0.8488 - val_loss: 0.6408 - val_accuracy: 0.8438\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5170 - accuracy: 0.8488 - val_loss: 0.6404 - val_accuracy: 0.8437\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5166 - accuracy: 0.8489 - val_loss: 0.6400 - val_accuracy: 0.8437\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5161 - accuracy: 0.8490 - val_loss: 0.6395 - val_accuracy: 0.8436\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5157 - accuracy: 0.8490 - val_loss: 0.6391 - val_accuracy: 0.8436\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5153 - accuracy: 0.8491 - val_loss: 0.6386 - val_accuracy: 0.8438\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5148 - accuracy: 0.8492 - val_loss: 0.6382 - val_accuracy: 0.8438\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5144 - accuracy: 0.8493 - val_loss: 0.6378 - val_accuracy: 0.8439\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5139 - accuracy: 0.8494 - val_loss: 0.6373 - val_accuracy: 0.8441\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5135 - accuracy: 0.8495 - val_loss: 0.6369 - val_accuracy: 0.8441\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5131 - accuracy: 0.8495 - val_loss: 0.6365 - val_accuracy: 0.8441\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5127 - accuracy: 0.8496 - val_loss: 0.6361 - val_accuracy: 0.8442\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5122 - accuracy: 0.8497 - val_loss: 0.6357 - val_accuracy: 0.8442\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5118 - accuracy: 0.8497 - val_loss: 0.6353 - val_accuracy: 0.8444\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5114 - accuracy: 0.8498 - val_loss: 0.6349 - val_accuracy: 0.8445\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5110 - accuracy: 0.8499 - val_loss: 0.6345 - val_accuracy: 0.8448\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5105 - accuracy: 0.8500 - val_loss: 0.6342 - val_accuracy: 0.8449\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5101 - accuracy: 0.8502 - val_loss: 0.6338 - val_accuracy: 0.8449\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5097 - accuracy: 0.8503 - val_loss: 0.6334 - val_accuracy: 0.8451\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5093 - accuracy: 0.8504 - val_loss: 0.6330 - val_accuracy: 0.8456\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5089 - accuracy: 0.8505 - val_loss: 0.6327 - val_accuracy: 0.8458\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5085 - accuracy: 0.8506 - val_loss: 0.6323 - val_accuracy: 0.8455\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5081 - accuracy: 0.8507 - val_loss: 0.6319 - val_accuracy: 0.8457\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5076 - accuracy: 0.8508 - val_loss: 0.6315 - val_accuracy: 0.8459\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5072 - accuracy: 0.8509 - val_loss: 0.6311 - val_accuracy: 0.8460\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5068 - accuracy: 0.8509 - val_loss: 0.6307 - val_accuracy: 0.8460\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5064 - accuracy: 0.8510 - val_loss: 0.6303 - val_accuracy: 0.8461\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5060 - accuracy: 0.8511 - val_loss: 0.6299 - val_accuracy: 0.8458\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5056 - accuracy: 0.8514 - val_loss: 0.6294 - val_accuracy: 0.8460\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5052 - accuracy: 0.8514 - val_loss: 0.6290 - val_accuracy: 0.8462\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5047 - accuracy: 0.8515 - val_loss: 0.6286 - val_accuracy: 0.8464\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5043 - accuracy: 0.8516 - val_loss: 0.6282 - val_accuracy: 0.8468\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5039 - accuracy: 0.8517 - val_loss: 0.6277 - val_accuracy: 0.8470\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5035 - accuracy: 0.8519 - val_loss: 0.6273 - val_accuracy: 0.8471\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5031 - accuracy: 0.8520 - val_loss: 0.6269 - val_accuracy: 0.8472\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5027 - accuracy: 0.8522 - val_loss: 0.6265 - val_accuracy: 0.8474\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5023 - accuracy: 0.8524 - val_loss: 0.6262 - val_accuracy: 0.8476\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5019 - accuracy: 0.8527 - val_loss: 0.6258 - val_accuracy: 0.8478\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5014 - accuracy: 0.8528 - val_loss: 0.6254 - val_accuracy: 0.8479\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5010 - accuracy: 0.8529 - val_loss: 0.6251 - val_accuracy: 0.8480\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5006 - accuracy: 0.8529 - val_loss: 0.6247 - val_accuracy: 0.8484\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5002 - accuracy: 0.8530 - val_loss: 0.6244 - val_accuracy: 0.8486\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4998 - accuracy: 0.8531 - val_loss: 0.6240 - val_accuracy: 0.8489\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4994 - accuracy: 0.8532 - val_loss: 0.6237 - val_accuracy: 0.8492\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4989 - accuracy: 0.8534 - val_loss: 0.6234 - val_accuracy: 0.8492\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4985 - accuracy: 0.8536 - val_loss: 0.6231 - val_accuracy: 0.8493\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4981 - accuracy: 0.8536 - val_loss: 0.6228 - val_accuracy: 0.8494\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4977 - accuracy: 0.8537 - val_loss: 0.6224 - val_accuracy: 0.8494\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4973 - accuracy: 0.8538 - val_loss: 0.6221 - val_accuracy: 0.8497\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4969 - accuracy: 0.8540 - val_loss: 0.6217 - val_accuracy: 0.8502\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4964 - accuracy: 0.8541 - val_loss: 0.6213 - val_accuracy: 0.8504\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4960 - accuracy: 0.8542 - val_loss: 0.6209 - val_accuracy: 0.8504\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4956 - accuracy: 0.8543 - val_loss: 0.6205 - val_accuracy: 0.8506\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4951 - accuracy: 0.8543 - val_loss: 0.6201 - val_accuracy: 0.8505\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4947 - accuracy: 0.8545 - val_loss: 0.6196 - val_accuracy: 0.8505\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4943 - accuracy: 0.8545 - val_loss: 0.6192 - val_accuracy: 0.8504\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4939 - accuracy: 0.8547 - val_loss: 0.6188 - val_accuracy: 0.8505\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4934 - accuracy: 0.8547 - val_loss: 0.6184 - val_accuracy: 0.8506\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4930 - accuracy: 0.8549 - val_loss: 0.6180 - val_accuracy: 0.8506\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4926 - accuracy: 0.8550 - val_loss: 0.6176 - val_accuracy: 0.8506\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4922 - accuracy: 0.8551 - val_loss: 0.6173 - val_accuracy: 0.8506\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4917 - accuracy: 0.8552 - val_loss: 0.6169 - val_accuracy: 0.8506\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4913 - accuracy: 0.8553 - val_loss: 0.6166 - val_accuracy: 0.8507\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4909 - accuracy: 0.8554 - val_loss: 0.6162 - val_accuracy: 0.8509\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4905 - accuracy: 0.8556 - val_loss: 0.6158 - val_accuracy: 0.8510\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4900 - accuracy: 0.8557 - val_loss: 0.6155 - val_accuracy: 0.8515\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4896 - accuracy: 0.8558 - val_loss: 0.6151 - val_accuracy: 0.8515\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4892 - accuracy: 0.8558 - val_loss: 0.6146 - val_accuracy: 0.8518\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4887 - accuracy: 0.8559 - val_loss: 0.6143 - val_accuracy: 0.8516\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4883 - accuracy: 0.8561 - val_loss: 0.6138 - val_accuracy: 0.8518\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4879 - accuracy: 0.8563 - val_loss: 0.6134 - val_accuracy: 0.8517\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4874 - accuracy: 0.8565 - val_loss: 0.6129 - val_accuracy: 0.8519\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4870 - accuracy: 0.8565 - val_loss: 0.6125 - val_accuracy: 0.8518\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4865 - accuracy: 0.8566 - val_loss: 0.6120 - val_accuracy: 0.8521\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4861 - accuracy: 0.8569 - val_loss: 0.6116 - val_accuracy: 0.8522\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4857 - accuracy: 0.8571 - val_loss: 0.6111 - val_accuracy: 0.8525\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4852 - accuracy: 0.8571 - val_loss: 0.6107 - val_accuracy: 0.8527\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4848 - accuracy: 0.8572 - val_loss: 0.6102 - val_accuracy: 0.8529\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4844 - accuracy: 0.8572 - val_loss: 0.6097 - val_accuracy: 0.8530\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4840 - accuracy: 0.8575 - val_loss: 0.6092 - val_accuracy: 0.8531\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4835 - accuracy: 0.8576 - val_loss: 0.6087 - val_accuracy: 0.8532\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4831 - accuracy: 0.8577 - val_loss: 0.6083 - val_accuracy: 0.8533\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4827 - accuracy: 0.8578 - val_loss: 0.6079 - val_accuracy: 0.8532\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4823 - accuracy: 0.8580 - val_loss: 0.6075 - val_accuracy: 0.8531\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4818 - accuracy: 0.8582 - val_loss: 0.6071 - val_accuracy: 0.8532\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4814 - accuracy: 0.8582 - val_loss: 0.6066 - val_accuracy: 0.8533\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4810 - accuracy: 0.8584 - val_loss: 0.6062 - val_accuracy: 0.8536\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4805 - accuracy: 0.8586 - val_loss: 0.6058 - val_accuracy: 0.8538\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4801 - accuracy: 0.8587 - val_loss: 0.6054 - val_accuracy: 0.8538\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4797 - accuracy: 0.8588 - val_loss: 0.6050 - val_accuracy: 0.8539\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4792 - accuracy: 0.8590 - val_loss: 0.6045 - val_accuracy: 0.8541\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4788 - accuracy: 0.8591 - val_loss: 0.6040 - val_accuracy: 0.8540\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4783 - accuracy: 0.8591 - val_loss: 0.6037 - val_accuracy: 0.8544\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4779 - accuracy: 0.8593 - val_loss: 0.6033 - val_accuracy: 0.8545\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4775 - accuracy: 0.8594 - val_loss: 0.6029 - val_accuracy: 0.8548\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4770 - accuracy: 0.8596 - val_loss: 0.6025 - val_accuracy: 0.8548\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4766 - accuracy: 0.8597 - val_loss: 0.6020 - val_accuracy: 0.8549\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4762 - accuracy: 0.8597 - val_loss: 0.6016 - val_accuracy: 0.8549\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4757 - accuracy: 0.8598 - val_loss: 0.6012 - val_accuracy: 0.8551\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4753 - accuracy: 0.8598 - val_loss: 0.6009 - val_accuracy: 0.8552\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4749 - accuracy: 0.8600 - val_loss: 0.6004 - val_accuracy: 0.8555\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4744 - accuracy: 0.8600 - val_loss: 0.5999 - val_accuracy: 0.8558\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4740 - accuracy: 0.8602 - val_loss: 0.5994 - val_accuracy: 0.8557\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4736 - accuracy: 0.8605 - val_loss: 0.5990 - val_accuracy: 0.8559\n"
     ]
    }
   ],
   "source": [
    "# first train\n",
    "keras_model_cce1 = keras_dense_model()\n",
    "\n",
    "keras_model_cce1.summary()\n",
    "\n",
    "keras_model_cce1.compile(\n",
    "    optimizer = optimizers.Adam(0.001),\n",
    "    loss = 'sparse_categorical_crossentropy', \n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "history_train_cce1 = keras_model_cce1.fit(\n",
    "    Xtrain, Ytrain, \n",
    "    validation_data=(Xtest, Ytest),\n",
    "    epochs = 1000, batch_size = Xtrain.shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uL9lPDi1gnNE",
    "outputId": "25523fd1-2a15-4452-a0f4-5c590d7be761"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 165.5854 - accuracy: 0.1140 - val_loss: 117.8787 - val_accuracy: 0.1436\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 118.9026 - accuracy: 0.1492 - val_loss: 90.1319 - val_accuracy: 0.1879\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 90.9970 - accuracy: 0.1957 - val_loss: 75.0533 - val_accuracy: 0.2280\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 75.7590 - accuracy: 0.2366 - val_loss: 66.2447 - val_accuracy: 0.2633\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 66.9592 - accuracy: 0.2733 - val_loss: 59.3060 - val_accuracy: 0.2962\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 60.1071 - accuracy: 0.3047 - val_loss: 52.6376 - val_accuracy: 0.3297\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 53.5589 - accuracy: 0.3374 - val_loss: 46.1500 - val_accuracy: 0.3642\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 47.1851 - accuracy: 0.3704 - val_loss: 40.2818 - val_accuracy: 0.4016\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 41.3832 - accuracy: 0.4018 - val_loss: 35.3186 - val_accuracy: 0.4356\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 36.3977 - accuracy: 0.4329 - val_loss: 31.2058 - val_accuracy: 0.4647\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 32.2990 - accuracy: 0.4604 - val_loss: 27.8844 - val_accuracy: 0.4904\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 28.9651 - accuracy: 0.4864 - val_loss: 25.2405 - val_accuracy: 0.5108\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 26.2233 - accuracy: 0.5059 - val_loss: 23.0620 - val_accuracy: 0.5261\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 23.9153 - accuracy: 0.5238 - val_loss: 21.1756 - val_accuracy: 0.5409\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 21.9547 - accuracy: 0.5386 - val_loss: 19.5475 - val_accuracy: 0.5509\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 20.2999 - accuracy: 0.5500 - val_loss: 18.1468 - val_accuracy: 0.5638\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 18.8949 - accuracy: 0.5607 - val_loss: 16.9327 - val_accuracy: 0.5759\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 17.6762 - accuracy: 0.5710 - val_loss: 15.8452 - val_accuracy: 0.5855\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 16.5851 - accuracy: 0.5808 - val_loss: 14.8161 - val_accuracy: 0.5937\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 15.5678 - accuracy: 0.5913 - val_loss: 13.8469 - val_accuracy: 0.6054\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 14.6016 - accuracy: 0.6023 - val_loss: 12.9503 - val_accuracy: 0.6157\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 13.6968 - accuracy: 0.6124 - val_loss: 12.1555 - val_accuracy: 0.6263\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 12.8700 - accuracy: 0.6229 - val_loss: 11.4437 - val_accuracy: 0.6365\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 12.1256 - accuracy: 0.6323 - val_loss: 10.8058 - val_accuracy: 0.6454\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 11.4559 - accuracy: 0.6397 - val_loss: 10.2307 - val_accuracy: 0.6489\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 10.8440 - accuracy: 0.6457 - val_loss: 9.7024 - val_accuracy: 0.6540\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 10.2914 - accuracy: 0.6497 - val_loss: 9.2288 - val_accuracy: 0.6582\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 9.7853 - accuracy: 0.6529 - val_loss: 8.8015 - val_accuracy: 0.6607\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 9.3253 - accuracy: 0.6556 - val_loss: 8.4240 - val_accuracy: 0.6619\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 8.9157 - accuracy: 0.6571 - val_loss: 8.0923 - val_accuracy: 0.6640\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 8.5479 - accuracy: 0.6587 - val_loss: 7.7941 - val_accuracy: 0.6656\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 8.2061 - accuracy: 0.6582 - val_loss: 7.5068 - val_accuracy: 0.6636\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 7.8764 - accuracy: 0.6584 - val_loss: 7.2215 - val_accuracy: 0.6647\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 7.5549 - accuracy: 0.6579 - val_loss: 6.9381 - val_accuracy: 0.6638\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 7.2383 - accuracy: 0.6582 - val_loss: 6.6561 - val_accuracy: 0.6617\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.9310 - accuracy: 0.6568 - val_loss: 6.3835 - val_accuracy: 0.6604\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 6.6349 - accuracy: 0.6558 - val_loss: 6.1225 - val_accuracy: 0.6576\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 6.3523 - accuracy: 0.6545 - val_loss: 5.8761 - val_accuracy: 0.6558\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.0872 - accuracy: 0.6530 - val_loss: 5.6384 - val_accuracy: 0.6508\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.8395 - accuracy: 0.6501 - val_loss: 5.4105 - val_accuracy: 0.6478\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 5.6063 - accuracy: 0.6477 - val_loss: 5.1877 - val_accuracy: 0.6577\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 5.3835 - accuracy: 0.6561 - val_loss: 4.9739 - val_accuracy: 0.6565\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 5.1701 - accuracy: 0.6535 - val_loss: 4.7673 - val_accuracy: 0.6540\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.9646 - accuracy: 0.6510 - val_loss: 4.5688 - val_accuracy: 0.6523\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 4.7684 - accuracy: 0.6473 - val_loss: 4.3822 - val_accuracy: 0.6475\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.5811 - accuracy: 0.6432 - val_loss: 4.2053 - val_accuracy: 0.6460\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 4.4017 - accuracy: 0.6392 - val_loss: 4.0401 - val_accuracy: 0.6408\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 4.2317 - accuracy: 0.6360 - val_loss: 3.8873 - val_accuracy: 0.6362\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 4.0707 - accuracy: 0.6317 - val_loss: 3.7460 - val_accuracy: 0.6327\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.9191 - accuracy: 0.6279 - val_loss: 3.6162 - val_accuracy: 0.6290\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7783 - accuracy: 0.6241 - val_loss: 3.4976 - val_accuracy: 0.6244\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.6482 - accuracy: 0.6197 - val_loss: 3.3888 - val_accuracy: 0.6218\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.5261 - accuracy: 0.6154 - val_loss: 3.2886 - val_accuracy: 0.6159\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.4106 - accuracy: 0.6116 - val_loss: 3.1964 - val_accuracy: 0.6111\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.3030 - accuracy: 0.6066 - val_loss: 3.1102 - val_accuracy: 0.6053\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 3.2031 - accuracy: 0.6015 - val_loss: 3.0277 - val_accuracy: 0.6007\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.1091 - accuracy: 0.5973 - val_loss: 2.9474 - val_accuracy: 0.5933\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.0206 - accuracy: 0.5930 - val_loss: 2.8714 - val_accuracy: 0.5859\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.9377 - accuracy: 0.5890 - val_loss: 2.8004 - val_accuracy: 0.5809\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.8596 - accuracy: 0.5845 - val_loss: 2.7343 - val_accuracy: 0.5780\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.7864 - accuracy: 0.5814 - val_loss: 2.6723 - val_accuracy: 0.5743\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.7183 - accuracy: 0.5783 - val_loss: 2.6161 - val_accuracy: 0.5721\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6550 - accuracy: 0.5747 - val_loss: 2.5634 - val_accuracy: 0.5677\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5962 - accuracy: 0.5713 - val_loss: 2.5132 - val_accuracy: 0.5643\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.5408 - accuracy: 0.5685 - val_loss: 2.4670 - val_accuracy: 0.5588\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.4891 - accuracy: 0.5657 - val_loss: 2.4224 - val_accuracy: 0.5573\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.4407 - accuracy: 0.5631 - val_loss: 2.3802 - val_accuracy: 0.5543\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 2.3950 - accuracy: 0.5601 - val_loss: 2.3402 - val_accuracy: 0.5642\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.3518 - accuracy: 0.5687 - val_loss: 2.3031 - val_accuracy: 0.5627\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.3111 - accuracy: 0.5682 - val_loss: 2.2676 - val_accuracy: 0.5610\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.2727 - accuracy: 0.5674 - val_loss: 2.2338 - val_accuracy: 0.5584\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.2367 - accuracy: 0.5653 - val_loss: 2.2017 - val_accuracy: 0.5553\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.2028 - accuracy: 0.5633 - val_loss: 2.1717 - val_accuracy: 0.5549\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.1709 - accuracy: 0.5613 - val_loss: 2.1437 - val_accuracy: 0.5530\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.1409 - accuracy: 0.5601 - val_loss: 2.1171 - val_accuracy: 0.5517\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.1127 - accuracy: 0.5582 - val_loss: 2.0920 - val_accuracy: 0.5499\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 2.0862 - accuracy: 0.5572 - val_loss: 2.0686 - val_accuracy: 0.5476\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.0613 - accuracy: 0.5564 - val_loss: 2.0463 - val_accuracy: 0.5479\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 2.0378 - accuracy: 0.5552 - val_loss: 2.0247 - val_accuracy: 0.5481\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0156 - accuracy: 0.5544 - val_loss: 2.0040 - val_accuracy: 0.5474\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.9946 - accuracy: 0.5542 - val_loss: 1.9847 - val_accuracy: 0.5493\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9748 - accuracy: 0.5538 - val_loss: 1.9664 - val_accuracy: 0.5481\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9560 - accuracy: 0.5530 - val_loss: 1.9490 - val_accuracy: 0.5480\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.9379 - accuracy: 0.5524 - val_loss: 1.9328 - val_accuracy: 0.5475\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.9208 - accuracy: 0.5517 - val_loss: 1.9172 - val_accuracy: 0.5474\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.9042 - accuracy: 0.5518 - val_loss: 1.9024 - val_accuracy: 0.5463\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8883 - accuracy: 0.5523 - val_loss: 1.8882 - val_accuracy: 0.5471\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.8731 - accuracy: 0.5533 - val_loss: 1.8744 - val_accuracy: 0.5479\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.8586 - accuracy: 0.5540 - val_loss: 1.8612 - val_accuracy: 0.5494\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.8449 - accuracy: 0.5549 - val_loss: 1.8484 - val_accuracy: 0.5509\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.8317 - accuracy: 0.5570 - val_loss: 1.8361 - val_accuracy: 0.5519\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.8190 - accuracy: 0.5580 - val_loss: 1.8245 - val_accuracy: 0.5528\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.8070 - accuracy: 0.5590 - val_loss: 1.8134 - val_accuracy: 0.5540\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.7953 - accuracy: 0.5596 - val_loss: 1.8027 - val_accuracy: 0.5549\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.7841 - accuracy: 0.5597 - val_loss: 1.7927 - val_accuracy: 0.5566\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7734 - accuracy: 0.5604 - val_loss: 1.7830 - val_accuracy: 0.5570\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.7631 - accuracy: 0.5612 - val_loss: 1.7738 - val_accuracy: 0.5571\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7531 - accuracy: 0.5618 - val_loss: 1.7650 - val_accuracy: 0.5576\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.7435 - accuracy: 0.5627 - val_loss: 1.7564 - val_accuracy: 0.5587\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.7341 - accuracy: 0.5634 - val_loss: 1.7481 - val_accuracy: 0.5597\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7250 - accuracy: 0.5644 - val_loss: 1.7401 - val_accuracy: 0.5609\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.7162 - accuracy: 0.5657 - val_loss: 1.7323 - val_accuracy: 0.5622\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.7076 - accuracy: 0.5667 - val_loss: 1.7247 - val_accuracy: 0.5638\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.6991 - accuracy: 0.5677 - val_loss: 1.7174 - val_accuracy: 0.5650\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.6908 - accuracy: 0.5689 - val_loss: 1.7102 - val_accuracy: 0.5651\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6827 - accuracy: 0.5699 - val_loss: 1.7032 - val_accuracy: 0.5661\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.6748 - accuracy: 0.5710 - val_loss: 1.6963 - val_accuracy: 0.5666\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.6671 - accuracy: 0.5720 - val_loss: 1.6894 - val_accuracy: 0.5678\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6596 - accuracy: 0.5729 - val_loss: 1.6828 - val_accuracy: 0.5693\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6523 - accuracy: 0.5741 - val_loss: 1.6763 - val_accuracy: 0.5702\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6453 - accuracy: 0.5754 - val_loss: 1.6700 - val_accuracy: 0.5711\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.6384 - accuracy: 0.5761 - val_loss: 1.6639 - val_accuracy: 0.5717\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.6315 - accuracy: 0.5766 - val_loss: 1.6579 - val_accuracy: 0.5729\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.6248 - accuracy: 0.5777 - val_loss: 1.6520 - val_accuracy: 0.5729\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.6180 - accuracy: 0.5787 - val_loss: 1.6461 - val_accuracy: 0.5738\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.6114 - accuracy: 0.5797 - val_loss: 1.6403 - val_accuracy: 0.5745\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.6050 - accuracy: 0.5809 - val_loss: 1.6346 - val_accuracy: 0.5764\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.5986 - accuracy: 0.5823 - val_loss: 1.6287 - val_accuracy: 0.5782\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5923 - accuracy: 0.5835 - val_loss: 1.6232 - val_accuracy: 0.5790\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5861 - accuracy: 0.5848 - val_loss: 1.6180 - val_accuracy: 0.5797\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.5800 - accuracy: 0.5863 - val_loss: 1.6129 - val_accuracy: 0.5810\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5741 - accuracy: 0.5877 - val_loss: 1.6079 - val_accuracy: 0.5836\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5684 - accuracy: 0.5890 - val_loss: 1.6028 - val_accuracy: 0.5852\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.5629 - accuracy: 0.5902 - val_loss: 1.5978 - val_accuracy: 0.5859\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.5575 - accuracy: 0.5915 - val_loss: 1.5929 - val_accuracy: 0.5868\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5522 - accuracy: 0.5927 - val_loss: 1.5880 - val_accuracy: 0.5872\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5470 - accuracy: 0.5938 - val_loss: 1.5832 - val_accuracy: 0.5884\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5419 - accuracy: 0.5949 - val_loss: 1.5785 - val_accuracy: 0.5900\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.5369 - accuracy: 0.5960 - val_loss: 1.5739 - val_accuracy: 0.5915\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5319 - accuracy: 0.5971 - val_loss: 1.5693 - val_accuracy: 0.5924\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5270 - accuracy: 0.5984 - val_loss: 1.5649 - val_accuracy: 0.5936\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5221 - accuracy: 0.5993 - val_loss: 1.5607 - val_accuracy: 0.5940\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5173 - accuracy: 0.6005 - val_loss: 1.5565 - val_accuracy: 0.5948\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5126 - accuracy: 0.6013 - val_loss: 1.5525 - val_accuracy: 0.5954\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5079 - accuracy: 0.6024 - val_loss: 1.5486 - val_accuracy: 0.5961\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5032 - accuracy: 0.6034 - val_loss: 1.5447 - val_accuracy: 0.5973\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4986 - accuracy: 0.6044 - val_loss: 1.5409 - val_accuracy: 0.5985\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4941 - accuracy: 0.6054 - val_loss: 1.5371 - val_accuracy: 0.5995\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4897 - accuracy: 0.6065 - val_loss: 1.5333 - val_accuracy: 0.6008\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4852 - accuracy: 0.6072 - val_loss: 1.5297 - val_accuracy: 0.6013\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.4806 - accuracy: 0.6082 - val_loss: 1.5261 - val_accuracy: 0.6023\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4761 - accuracy: 0.6093 - val_loss: 1.5225 - val_accuracy: 0.6030\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4717 - accuracy: 0.6106 - val_loss: 1.5191 - val_accuracy: 0.6037\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4673 - accuracy: 0.6118 - val_loss: 1.5155 - val_accuracy: 0.6049\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4630 - accuracy: 0.6128 - val_loss: 1.5120 - val_accuracy: 0.6055\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4588 - accuracy: 0.6137 - val_loss: 1.5085 - val_accuracy: 0.6065\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4545 - accuracy: 0.6146 - val_loss: 1.5049 - val_accuracy: 0.6079\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4503 - accuracy: 0.6156 - val_loss: 1.5015 - val_accuracy: 0.6089\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4462 - accuracy: 0.6167 - val_loss: 1.4979 - val_accuracy: 0.6098\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4421 - accuracy: 0.6176 - val_loss: 1.4945 - val_accuracy: 0.6106\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4380 - accuracy: 0.6186 - val_loss: 1.4911 - val_accuracy: 0.6115\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4340 - accuracy: 0.6198 - val_loss: 1.4877 - val_accuracy: 0.6127\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4301 - accuracy: 0.6208 - val_loss: 1.4844 - val_accuracy: 0.6135\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4262 - accuracy: 0.6220 - val_loss: 1.4811 - val_accuracy: 0.6138\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.4224 - accuracy: 0.6229 - val_loss: 1.4779 - val_accuracy: 0.6144\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4185 - accuracy: 0.6237 - val_loss: 1.4747 - val_accuracy: 0.6151\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.4148 - accuracy: 0.6245 - val_loss: 1.4715 - val_accuracy: 0.6155\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4110 - accuracy: 0.6257 - val_loss: 1.4683 - val_accuracy: 0.6167\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4072 - accuracy: 0.6268 - val_loss: 1.4651 - val_accuracy: 0.6173\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4035 - accuracy: 0.6276 - val_loss: 1.4620 - val_accuracy: 0.6180\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.3997 - accuracy: 0.6284 - val_loss: 1.4591 - val_accuracy: 0.6185\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3961 - accuracy: 0.6291 - val_loss: 1.4561 - val_accuracy: 0.6193\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3925 - accuracy: 0.6302 - val_loss: 1.4531 - val_accuracy: 0.6202\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3889 - accuracy: 0.6310 - val_loss: 1.4501 - val_accuracy: 0.6214\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3854 - accuracy: 0.6320 - val_loss: 1.4470 - val_accuracy: 0.6225\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3820 - accuracy: 0.6327 - val_loss: 1.4440 - val_accuracy: 0.6235\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3786 - accuracy: 0.6334 - val_loss: 1.4409 - val_accuracy: 0.6237\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3752 - accuracy: 0.6345 - val_loss: 1.4379 - val_accuracy: 0.6248\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.3718 - accuracy: 0.6350 - val_loss: 1.4348 - val_accuracy: 0.6259\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3685 - accuracy: 0.6358 - val_loss: 1.4319 - val_accuracy: 0.6261\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3652 - accuracy: 0.6365 - val_loss: 1.4290 - val_accuracy: 0.6271\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3620 - accuracy: 0.6373 - val_loss: 1.4261 - val_accuracy: 0.6280\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3588 - accuracy: 0.6378 - val_loss: 1.4232 - val_accuracy: 0.6285\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3556 - accuracy: 0.6386 - val_loss: 1.4203 - val_accuracy: 0.6286\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3525 - accuracy: 0.6392 - val_loss: 1.4174 - val_accuracy: 0.6295\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3493 - accuracy: 0.6398 - val_loss: 1.4146 - val_accuracy: 0.6299\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3462 - accuracy: 0.6403 - val_loss: 1.4118 - val_accuracy: 0.6305\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3432 - accuracy: 0.6411 - val_loss: 1.4091 - val_accuracy: 0.6316\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.3402 - accuracy: 0.6420 - val_loss: 1.4064 - val_accuracy: 0.6324\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3372 - accuracy: 0.6428 - val_loss: 1.4036 - val_accuracy: 0.6328\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3342 - accuracy: 0.6437 - val_loss: 1.4009 - val_accuracy: 0.6336\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3312 - accuracy: 0.6444 - val_loss: 1.3982 - val_accuracy: 0.6344\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3282 - accuracy: 0.6449 - val_loss: 1.3956 - val_accuracy: 0.6351\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.3252 - accuracy: 0.6460 - val_loss: 1.3930 - val_accuracy: 0.6358\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3223 - accuracy: 0.6468 - val_loss: 1.3904 - val_accuracy: 0.6365\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3194 - accuracy: 0.6475 - val_loss: 1.3877 - val_accuracy: 0.6372\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3164 - accuracy: 0.6483 - val_loss: 1.3850 - val_accuracy: 0.6384\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3135 - accuracy: 0.6493 - val_loss: 1.3823 - val_accuracy: 0.6397\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3107 - accuracy: 0.6501 - val_loss: 1.3797 - val_accuracy: 0.6405\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3078 - accuracy: 0.6508 - val_loss: 1.3769 - val_accuracy: 0.6412\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.3050 - accuracy: 0.6515 - val_loss: 1.3743 - val_accuracy: 0.6416\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3022 - accuracy: 0.6523 - val_loss: 1.3717 - val_accuracy: 0.6422\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2994 - accuracy: 0.6532 - val_loss: 1.3691 - val_accuracy: 0.6431\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2966 - accuracy: 0.6539 - val_loss: 1.3665 - val_accuracy: 0.6440\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2939 - accuracy: 0.6548 - val_loss: 1.3640 - val_accuracy: 0.6445\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2911 - accuracy: 0.6553 - val_loss: 1.3615 - val_accuracy: 0.6452\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2885 - accuracy: 0.6561 - val_loss: 1.3591 - val_accuracy: 0.6459\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2858 - accuracy: 0.6571 - val_loss: 1.3566 - val_accuracy: 0.6468\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2832 - accuracy: 0.6579 - val_loss: 1.3542 - val_accuracy: 0.6476\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2805 - accuracy: 0.6585 - val_loss: 1.3517 - val_accuracy: 0.6481\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2780 - accuracy: 0.6593 - val_loss: 1.3492 - val_accuracy: 0.6485\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2754 - accuracy: 0.6598 - val_loss: 1.3467 - val_accuracy: 0.6494\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2728 - accuracy: 0.6604 - val_loss: 1.3443 - val_accuracy: 0.6500\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2703 - accuracy: 0.6609 - val_loss: 1.3419 - val_accuracy: 0.6500\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2677 - accuracy: 0.6612 - val_loss: 1.3394 - val_accuracy: 0.6517\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2652 - accuracy: 0.6618 - val_loss: 1.3370 - val_accuracy: 0.6523\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2627 - accuracy: 0.6625 - val_loss: 1.3346 - val_accuracy: 0.6522\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2603 - accuracy: 0.6630 - val_loss: 1.3322 - val_accuracy: 0.6528\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2578 - accuracy: 0.6636 - val_loss: 1.3298 - val_accuracy: 0.6541\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2553 - accuracy: 0.6642 - val_loss: 1.3274 - val_accuracy: 0.6548\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2529 - accuracy: 0.6647 - val_loss: 1.3251 - val_accuracy: 0.6557\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2505 - accuracy: 0.6654 - val_loss: 1.3227 - val_accuracy: 0.6561\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2481 - accuracy: 0.6661 - val_loss: 1.3203 - val_accuracy: 0.6568\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2457 - accuracy: 0.6666 - val_loss: 1.3179 - val_accuracy: 0.6574\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2432 - accuracy: 0.6674 - val_loss: 1.3155 - val_accuracy: 0.6585\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2408 - accuracy: 0.6682 - val_loss: 1.3131 - val_accuracy: 0.6591\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2384 - accuracy: 0.6691 - val_loss: 1.3107 - val_accuracy: 0.6599\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2360 - accuracy: 0.6700 - val_loss: 1.3083 - val_accuracy: 0.6605\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2335 - accuracy: 0.6707 - val_loss: 1.3059 - val_accuracy: 0.6614\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2312 - accuracy: 0.6715 - val_loss: 1.3036 - val_accuracy: 0.6626\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2288 - accuracy: 0.6722 - val_loss: 1.3013 - val_accuracy: 0.6630\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2264 - accuracy: 0.6728 - val_loss: 1.2989 - val_accuracy: 0.6643\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2240 - accuracy: 0.6736 - val_loss: 1.2966 - val_accuracy: 0.6652\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2216 - accuracy: 0.6743 - val_loss: 1.2944 - val_accuracy: 0.6660\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2193 - accuracy: 0.6747 - val_loss: 1.2923 - val_accuracy: 0.6668\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2169 - accuracy: 0.6753 - val_loss: 1.2902 - val_accuracy: 0.6673\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2146 - accuracy: 0.6760 - val_loss: 1.2881 - val_accuracy: 0.6677\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.2123 - accuracy: 0.6765 - val_loss: 1.2861 - val_accuracy: 0.6683\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2100 - accuracy: 0.6772 - val_loss: 1.2840 - val_accuracy: 0.6693\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2077 - accuracy: 0.6780 - val_loss: 1.2820 - val_accuracy: 0.6700\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2054 - accuracy: 0.6788 - val_loss: 1.2800 - val_accuracy: 0.6708\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2031 - accuracy: 0.6793 - val_loss: 1.2781 - val_accuracy: 0.6714\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2008 - accuracy: 0.6803 - val_loss: 1.2761 - val_accuracy: 0.6716\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1985 - accuracy: 0.6811 - val_loss: 1.2742 - val_accuracy: 0.6724\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1963 - accuracy: 0.6818 - val_loss: 1.2722 - val_accuracy: 0.6736\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1940 - accuracy: 0.6827 - val_loss: 1.2704 - val_accuracy: 0.6742\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1917 - accuracy: 0.6836 - val_loss: 1.2686 - val_accuracy: 0.6752\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1894 - accuracy: 0.6846 - val_loss: 1.2668 - val_accuracy: 0.6753\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1871 - accuracy: 0.6855 - val_loss: 1.2649 - val_accuracy: 0.6758\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1848 - accuracy: 0.6862 - val_loss: 1.2630 - val_accuracy: 0.6764\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1825 - accuracy: 0.6869 - val_loss: 1.2611 - val_accuracy: 0.6773\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1802 - accuracy: 0.6878 - val_loss: 1.2592 - val_accuracy: 0.6786\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1779 - accuracy: 0.6884 - val_loss: 1.2573 - val_accuracy: 0.6803\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1756 - accuracy: 0.6893 - val_loss: 1.2553 - val_accuracy: 0.6813\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1734 - accuracy: 0.6899 - val_loss: 1.2534 - val_accuracy: 0.6827\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1711 - accuracy: 0.6906 - val_loss: 1.2514 - val_accuracy: 0.6838\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1689 - accuracy: 0.6914 - val_loss: 1.2495 - val_accuracy: 0.6843\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1667 - accuracy: 0.6920 - val_loss: 1.2476 - val_accuracy: 0.6847\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1645 - accuracy: 0.6927 - val_loss: 1.2457 - val_accuracy: 0.6847\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1623 - accuracy: 0.6932 - val_loss: 1.2438 - val_accuracy: 0.6856\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1602 - accuracy: 0.6939 - val_loss: 1.2418 - val_accuracy: 0.6865\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1581 - accuracy: 0.6946 - val_loss: 1.2399 - val_accuracy: 0.6873\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1561 - accuracy: 0.6951 - val_loss: 1.2379 - val_accuracy: 0.6878\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1540 - accuracy: 0.6957 - val_loss: 1.2359 - val_accuracy: 0.6885\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1520 - accuracy: 0.6960 - val_loss: 1.2339 - val_accuracy: 0.6895\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1500 - accuracy: 0.6964 - val_loss: 1.2320 - val_accuracy: 0.6900\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1480 - accuracy: 0.6972 - val_loss: 1.2302 - val_accuracy: 0.6906\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1459 - accuracy: 0.6977 - val_loss: 1.2284 - val_accuracy: 0.6909\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1439 - accuracy: 0.6981 - val_loss: 1.2266 - val_accuracy: 0.6916\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1419 - accuracy: 0.6986 - val_loss: 1.2249 - val_accuracy: 0.6917\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.1399 - accuracy: 0.6991 - val_loss: 1.2231 - val_accuracy: 0.6922\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1379 - accuracy: 0.6996 - val_loss: 1.2214 - val_accuracy: 0.6921\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1359 - accuracy: 0.7001 - val_loss: 1.2198 - val_accuracy: 0.6925\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1339 - accuracy: 0.7005 - val_loss: 1.2181 - val_accuracy: 0.6931\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1320 - accuracy: 0.7009 - val_loss: 1.2165 - val_accuracy: 0.6933\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1300 - accuracy: 0.7015 - val_loss: 1.2148 - val_accuracy: 0.6933\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1281 - accuracy: 0.7019 - val_loss: 1.2131 - val_accuracy: 0.6939\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1261 - accuracy: 0.7024 - val_loss: 1.2115 - val_accuracy: 0.6941\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.1242 - accuracy: 0.7028 - val_loss: 1.2099 - val_accuracy: 0.6947\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1222 - accuracy: 0.7032 - val_loss: 1.2083 - val_accuracy: 0.6951\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1203 - accuracy: 0.7038 - val_loss: 1.2067 - val_accuracy: 0.6958\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1183 - accuracy: 0.7043 - val_loss: 1.2052 - val_accuracy: 0.6960\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1163 - accuracy: 0.7047 - val_loss: 1.2036 - val_accuracy: 0.6960\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1144 - accuracy: 0.7051 - val_loss: 1.2019 - val_accuracy: 0.6965\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1125 - accuracy: 0.7054 - val_loss: 1.2002 - val_accuracy: 0.6971\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1106 - accuracy: 0.7058 - val_loss: 1.1985 - val_accuracy: 0.6976\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1087 - accuracy: 0.7065 - val_loss: 1.1968 - val_accuracy: 0.6983\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1068 - accuracy: 0.7068 - val_loss: 1.1951 - val_accuracy: 0.6985\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1050 - accuracy: 0.7072 - val_loss: 1.1934 - val_accuracy: 0.6990\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1031 - accuracy: 0.7078 - val_loss: 1.1917 - val_accuracy: 0.7000\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1012 - accuracy: 0.7082 - val_loss: 1.1901 - val_accuracy: 0.7009\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0993 - accuracy: 0.7086 - val_loss: 1.1886 - val_accuracy: 0.7016\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0975 - accuracy: 0.7092 - val_loss: 1.1872 - val_accuracy: 0.7026\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0956 - accuracy: 0.7098 - val_loss: 1.1858 - val_accuracy: 0.7031\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0937 - accuracy: 0.7105 - val_loss: 1.1842 - val_accuracy: 0.7035\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0919 - accuracy: 0.7110 - val_loss: 1.1824 - val_accuracy: 0.7040\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0900 - accuracy: 0.7116 - val_loss: 1.1806 - val_accuracy: 0.7045\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0882 - accuracy: 0.7120 - val_loss: 1.1788 - val_accuracy: 0.7049\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0863 - accuracy: 0.7127 - val_loss: 1.1770 - val_accuracy: 0.7057\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0844 - accuracy: 0.7131 - val_loss: 1.1752 - val_accuracy: 0.7064\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0826 - accuracy: 0.7139 - val_loss: 1.1735 - val_accuracy: 0.7071\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0807 - accuracy: 0.7143 - val_loss: 1.1716 - val_accuracy: 0.7080\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0789 - accuracy: 0.7146 - val_loss: 1.1697 - val_accuracy: 0.7085\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0771 - accuracy: 0.7153 - val_loss: 1.1678 - val_accuracy: 0.7090\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0753 - accuracy: 0.7159 - val_loss: 1.1661 - val_accuracy: 0.7092\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0735 - accuracy: 0.7164 - val_loss: 1.1645 - val_accuracy: 0.7097\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0718 - accuracy: 0.7170 - val_loss: 1.1630 - val_accuracy: 0.7101\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0700 - accuracy: 0.7175 - val_loss: 1.1615 - val_accuracy: 0.7101\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0682 - accuracy: 0.7180 - val_loss: 1.1601 - val_accuracy: 0.7105\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0665 - accuracy: 0.7184 - val_loss: 1.1587 - val_accuracy: 0.7107\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0647 - accuracy: 0.7189 - val_loss: 1.1574 - val_accuracy: 0.7112\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0629 - accuracy: 0.7193 - val_loss: 1.1560 - val_accuracy: 0.7118\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0611 - accuracy: 0.7197 - val_loss: 1.1546 - val_accuracy: 0.7119\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0594 - accuracy: 0.7201 - val_loss: 1.1532 - val_accuracy: 0.7127\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0576 - accuracy: 0.7206 - val_loss: 1.1518 - val_accuracy: 0.7134\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0558 - accuracy: 0.7211 - val_loss: 1.1503 - val_accuracy: 0.7138\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0540 - accuracy: 0.7215 - val_loss: 1.1488 - val_accuracy: 0.7141\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0522 - accuracy: 0.7219 - val_loss: 1.1472 - val_accuracy: 0.7144\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0505 - accuracy: 0.7225 - val_loss: 1.1456 - val_accuracy: 0.7149\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0488 - accuracy: 0.7229 - val_loss: 1.1441 - val_accuracy: 0.7155\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0470 - accuracy: 0.7235 - val_loss: 1.1428 - val_accuracy: 0.7159\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0452 - accuracy: 0.7242 - val_loss: 1.1414 - val_accuracy: 0.7161\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0434 - accuracy: 0.7247 - val_loss: 1.1400 - val_accuracy: 0.7165\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0416 - accuracy: 0.7252 - val_loss: 1.1385 - val_accuracy: 0.7172\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0398 - accuracy: 0.7258 - val_loss: 1.1367 - val_accuracy: 0.7180\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0379 - accuracy: 0.7265 - val_loss: 1.1350 - val_accuracy: 0.7185\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0360 - accuracy: 0.7273 - val_loss: 1.1333 - val_accuracy: 0.7191\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0340 - accuracy: 0.7280 - val_loss: 1.1317 - val_accuracy: 0.7204\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0319 - accuracy: 0.7287 - val_loss: 1.1301 - val_accuracy: 0.7211\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0300 - accuracy: 0.7295 - val_loss: 1.1282 - val_accuracy: 0.7218\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0280 - accuracy: 0.7301 - val_loss: 1.1262 - val_accuracy: 0.7222\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0259 - accuracy: 0.7309 - val_loss: 1.1244 - val_accuracy: 0.7229\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0239 - accuracy: 0.7315 - val_loss: 1.1228 - val_accuracy: 0.7231\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0220 - accuracy: 0.7321 - val_loss: 1.1213 - val_accuracy: 0.7235\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.0201 - accuracy: 0.7328 - val_loss: 1.1197 - val_accuracy: 0.7241\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0182 - accuracy: 0.7333 - val_loss: 1.1180 - val_accuracy: 0.7242\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0164 - accuracy: 0.7339 - val_loss: 1.1166 - val_accuracy: 0.7251\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0145 - accuracy: 0.7345 - val_loss: 1.1153 - val_accuracy: 0.7260\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0126 - accuracy: 0.7354 - val_loss: 1.1139 - val_accuracy: 0.7265\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0106 - accuracy: 0.7361 - val_loss: 1.1126 - val_accuracy: 0.7270\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0087 - accuracy: 0.7369 - val_loss: 1.1114 - val_accuracy: 0.7280\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0069 - accuracy: 0.7376 - val_loss: 1.1103 - val_accuracy: 0.7286\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0049 - accuracy: 0.7386 - val_loss: 1.1091 - val_accuracy: 0.7297\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0030 - accuracy: 0.7393 - val_loss: 1.1077 - val_accuracy: 0.7298\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0010 - accuracy: 0.7400 - val_loss: 1.1061 - val_accuracy: 0.7301\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9991 - accuracy: 0.7408 - val_loss: 1.1042 - val_accuracy: 0.7306\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9972 - accuracy: 0.7416 - val_loss: 1.1024 - val_accuracy: 0.7316\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9952 - accuracy: 0.7422 - val_loss: 1.1008 - val_accuracy: 0.7328\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9932 - accuracy: 0.7430 - val_loss: 1.0992 - val_accuracy: 0.7341\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9913 - accuracy: 0.7437 - val_loss: 1.0973 - val_accuracy: 0.7344\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9893 - accuracy: 0.7443 - val_loss: 1.0954 - val_accuracy: 0.7358\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9874 - accuracy: 0.7450 - val_loss: 1.0933 - val_accuracy: 0.7361\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9855 - accuracy: 0.7454 - val_loss: 1.0912 - val_accuracy: 0.7368\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9837 - accuracy: 0.7459 - val_loss: 1.0893 - val_accuracy: 0.7371\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9818 - accuracy: 0.7464 - val_loss: 1.0874 - val_accuracy: 0.7374\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9799 - accuracy: 0.7467 - val_loss: 1.0858 - val_accuracy: 0.7381\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9780 - accuracy: 0.7472 - val_loss: 1.0841 - val_accuracy: 0.7388\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9762 - accuracy: 0.7477 - val_loss: 1.0824 - val_accuracy: 0.7395\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9744 - accuracy: 0.7483 - val_loss: 1.0806 - val_accuracy: 0.7402\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.9726 - accuracy: 0.7488 - val_loss: 1.0788 - val_accuracy: 0.7402\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9708 - accuracy: 0.7492 - val_loss: 1.0769 - val_accuracy: 0.7408\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9689 - accuracy: 0.7495 - val_loss: 1.0752 - val_accuracy: 0.7416\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9671 - accuracy: 0.7500 - val_loss: 1.0735 - val_accuracy: 0.7423\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9652 - accuracy: 0.7505 - val_loss: 1.0717 - val_accuracy: 0.7429\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9634 - accuracy: 0.7511 - val_loss: 1.0700 - val_accuracy: 0.7434\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9616 - accuracy: 0.7518 - val_loss: 1.0683 - val_accuracy: 0.7438\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9598 - accuracy: 0.7523 - val_loss: 1.0666 - val_accuracy: 0.7442\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9580 - accuracy: 0.7527 - val_loss: 1.0650 - val_accuracy: 0.7449\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9563 - accuracy: 0.7532 - val_loss: 1.0634 - val_accuracy: 0.7457\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9545 - accuracy: 0.7537 - val_loss: 1.0619 - val_accuracy: 0.7461\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9527 - accuracy: 0.7545 - val_loss: 1.0604 - val_accuracy: 0.7468\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9509 - accuracy: 0.7551 - val_loss: 1.0589 - val_accuracy: 0.7476\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9491 - accuracy: 0.7557 - val_loss: 1.0573 - val_accuracy: 0.7481\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9473 - accuracy: 0.7565 - val_loss: 1.0556 - val_accuracy: 0.7480\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9454 - accuracy: 0.7571 - val_loss: 1.0538 - val_accuracy: 0.7487\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9435 - accuracy: 0.7577 - val_loss: 1.0518 - val_accuracy: 0.7492\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9415 - accuracy: 0.7582 - val_loss: 1.0498 - val_accuracy: 0.7497\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9397 - accuracy: 0.7588 - val_loss: 1.0478 - val_accuracy: 0.7504\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9378 - accuracy: 0.7592 - val_loss: 1.0458 - val_accuracy: 0.7505\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9359 - accuracy: 0.7600 - val_loss: 1.0439 - val_accuracy: 0.7510\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9341 - accuracy: 0.7606 - val_loss: 1.0421 - val_accuracy: 0.7516\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9322 - accuracy: 0.7613 - val_loss: 1.0400 - val_accuracy: 0.7520\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9303 - accuracy: 0.7618 - val_loss: 1.0379 - val_accuracy: 0.7519\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9284 - accuracy: 0.7623 - val_loss: 1.0358 - val_accuracy: 0.7524\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9266 - accuracy: 0.7625 - val_loss: 1.0338 - val_accuracy: 0.7528\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9249 - accuracy: 0.7628 - val_loss: 1.0320 - val_accuracy: 0.7531\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9231 - accuracy: 0.7631 - val_loss: 1.0304 - val_accuracy: 0.7540\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9213 - accuracy: 0.7639 - val_loss: 1.0289 - val_accuracy: 0.7543\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9196 - accuracy: 0.7645 - val_loss: 1.0273 - val_accuracy: 0.7554\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9179 - accuracy: 0.7651 - val_loss: 1.0256 - val_accuracy: 0.7561\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9160 - accuracy: 0.7657 - val_loss: 1.0240 - val_accuracy: 0.7564\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9142 - accuracy: 0.7663 - val_loss: 1.0226 - val_accuracy: 0.7578\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9124 - accuracy: 0.7668 - val_loss: 1.0209 - val_accuracy: 0.7581\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9106 - accuracy: 0.7672 - val_loss: 1.0190 - val_accuracy: 0.7586\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9088 - accuracy: 0.7676 - val_loss: 1.0172 - val_accuracy: 0.7589\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9070 - accuracy: 0.7682 - val_loss: 1.0155 - val_accuracy: 0.7591\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9053 - accuracy: 0.7686 - val_loss: 1.0139 - val_accuracy: 0.7601\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9036 - accuracy: 0.7692 - val_loss: 1.0123 - val_accuracy: 0.7607\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9020 - accuracy: 0.7699 - val_loss: 1.0107 - val_accuracy: 0.7608\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9004 - accuracy: 0.7706 - val_loss: 1.0093 - val_accuracy: 0.7611\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8987 - accuracy: 0.7713 - val_loss: 1.0079 - val_accuracy: 0.7612\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8971 - accuracy: 0.7716 - val_loss: 1.0063 - val_accuracy: 0.7617\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8955 - accuracy: 0.7718 - val_loss: 1.0047 - val_accuracy: 0.7621\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8939 - accuracy: 0.7724 - val_loss: 1.0032 - val_accuracy: 0.7626\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8923 - accuracy: 0.7729 - val_loss: 1.0017 - val_accuracy: 0.7630\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8906 - accuracy: 0.7737 - val_loss: 1.0001 - val_accuracy: 0.7636\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8890 - accuracy: 0.7741 - val_loss: 0.9984 - val_accuracy: 0.7638\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8874 - accuracy: 0.7746 - val_loss: 0.9967 - val_accuracy: 0.7637\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8858 - accuracy: 0.7749 - val_loss: 0.9949 - val_accuracy: 0.7638\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8842 - accuracy: 0.7751 - val_loss: 0.9930 - val_accuracy: 0.7639\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8827 - accuracy: 0.7753 - val_loss: 0.9914 - val_accuracy: 0.7644\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8812 - accuracy: 0.7757 - val_loss: 0.9898 - val_accuracy: 0.7646\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8797 - accuracy: 0.7758 - val_loss: 0.9882 - val_accuracy: 0.7653\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8782 - accuracy: 0.7762 - val_loss: 0.9866 - val_accuracy: 0.7656\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8767 - accuracy: 0.7766 - val_loss: 0.9849 - val_accuracy: 0.7661\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8753 - accuracy: 0.7771 - val_loss: 0.9832 - val_accuracy: 0.7663\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8738 - accuracy: 0.7775 - val_loss: 0.9817 - val_accuracy: 0.7665\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8724 - accuracy: 0.7779 - val_loss: 0.9803 - val_accuracy: 0.7667\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8710 - accuracy: 0.7781 - val_loss: 0.9791 - val_accuracy: 0.7669\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8696 - accuracy: 0.7784 - val_loss: 0.9778 - val_accuracy: 0.7675\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8681 - accuracy: 0.7791 - val_loss: 0.9766 - val_accuracy: 0.7675\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8667 - accuracy: 0.7794 - val_loss: 0.9753 - val_accuracy: 0.7680\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8653 - accuracy: 0.7798 - val_loss: 0.9737 - val_accuracy: 0.7691\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8639 - accuracy: 0.7801 - val_loss: 0.9721 - val_accuracy: 0.7698\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8625 - accuracy: 0.7803 - val_loss: 0.9707 - val_accuracy: 0.7700\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8612 - accuracy: 0.7804 - val_loss: 0.9692 - val_accuracy: 0.7704\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8598 - accuracy: 0.7807 - val_loss: 0.9677 - val_accuracy: 0.7707\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8585 - accuracy: 0.7808 - val_loss: 0.9661 - val_accuracy: 0.7710\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8571 - accuracy: 0.7811 - val_loss: 0.9645 - val_accuracy: 0.7714\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8557 - accuracy: 0.7812 - val_loss: 0.9629 - val_accuracy: 0.7721\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8544 - accuracy: 0.7816 - val_loss: 0.9615 - val_accuracy: 0.7728\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8530 - accuracy: 0.7821 - val_loss: 0.9600 - val_accuracy: 0.7730\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8517 - accuracy: 0.7823 - val_loss: 0.9587 - val_accuracy: 0.7733\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8504 - accuracy: 0.7827 - val_loss: 0.9573 - val_accuracy: 0.7735\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8490 - accuracy: 0.7830 - val_loss: 0.9559 - val_accuracy: 0.7738\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8478 - accuracy: 0.7832 - val_loss: 0.9546 - val_accuracy: 0.7746\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8465 - accuracy: 0.7837 - val_loss: 0.9533 - val_accuracy: 0.7752\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8452 - accuracy: 0.7841 - val_loss: 0.9519 - val_accuracy: 0.7759\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8440 - accuracy: 0.7844 - val_loss: 0.9505 - val_accuracy: 0.7765\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8426 - accuracy: 0.7849 - val_loss: 0.9494 - val_accuracy: 0.7772\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8414 - accuracy: 0.7853 - val_loss: 0.9482 - val_accuracy: 0.7773\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8401 - accuracy: 0.7855 - val_loss: 0.9471 - val_accuracy: 0.7775\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8388 - accuracy: 0.7858 - val_loss: 0.9460 - val_accuracy: 0.7776\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8375 - accuracy: 0.7862 - val_loss: 0.9450 - val_accuracy: 0.7782\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8362 - accuracy: 0.7868 - val_loss: 0.9440 - val_accuracy: 0.7791\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8348 - accuracy: 0.7874 - val_loss: 0.9429 - val_accuracy: 0.7794\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8336 - accuracy: 0.7879 - val_loss: 0.9417 - val_accuracy: 0.7799\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8323 - accuracy: 0.7883 - val_loss: 0.9404 - val_accuracy: 0.7801\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8310 - accuracy: 0.7889 - val_loss: 0.9392 - val_accuracy: 0.7803\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8297 - accuracy: 0.7893 - val_loss: 0.9379 - val_accuracy: 0.7808\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8283 - accuracy: 0.7897 - val_loss: 0.9367 - val_accuracy: 0.7812\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8270 - accuracy: 0.7901 - val_loss: 0.9355 - val_accuracy: 0.7818\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8257 - accuracy: 0.7904 - val_loss: 0.9343 - val_accuracy: 0.7821\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8244 - accuracy: 0.7908 - val_loss: 0.9332 - val_accuracy: 0.7825\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8231 - accuracy: 0.7911 - val_loss: 0.9320 - val_accuracy: 0.7832\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8217 - accuracy: 0.7917 - val_loss: 0.9308 - val_accuracy: 0.7831\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8204 - accuracy: 0.7919 - val_loss: 0.9297 - val_accuracy: 0.7829\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8191 - accuracy: 0.7924 - val_loss: 0.9286 - val_accuracy: 0.7831\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.8179 - accuracy: 0.7929 - val_loss: 0.9276 - val_accuracy: 0.7831\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8166 - accuracy: 0.7932 - val_loss: 0.9266 - val_accuracy: 0.7834\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8154 - accuracy: 0.7936 - val_loss: 0.9254 - val_accuracy: 0.7842\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8141 - accuracy: 0.7940 - val_loss: 0.9243 - val_accuracy: 0.7838\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8128 - accuracy: 0.7945 - val_loss: 0.9231 - val_accuracy: 0.7843\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8115 - accuracy: 0.7947 - val_loss: 0.9218 - val_accuracy: 0.7842\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8103 - accuracy: 0.7951 - val_loss: 0.9204 - val_accuracy: 0.7853\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8091 - accuracy: 0.7955 - val_loss: 0.9192 - val_accuracy: 0.7852\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8079 - accuracy: 0.7960 - val_loss: 0.9181 - val_accuracy: 0.7855\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8067 - accuracy: 0.7965 - val_loss: 0.9169 - val_accuracy: 0.7860\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8055 - accuracy: 0.7969 - val_loss: 0.9157 - val_accuracy: 0.7868\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8043 - accuracy: 0.7973 - val_loss: 0.9145 - val_accuracy: 0.7873\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8031 - accuracy: 0.7978 - val_loss: 0.9133 - val_accuracy: 0.7872\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8019 - accuracy: 0.7982 - val_loss: 0.9122 - val_accuracy: 0.7878\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8007 - accuracy: 0.7986 - val_loss: 0.9112 - val_accuracy: 0.7883\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7996 - accuracy: 0.7990 - val_loss: 0.9102 - val_accuracy: 0.7881\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7984 - accuracy: 0.7994 - val_loss: 0.9091 - val_accuracy: 0.7885\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7973 - accuracy: 0.7995 - val_loss: 0.9080 - val_accuracy: 0.7890\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7962 - accuracy: 0.7998 - val_loss: 0.9070 - val_accuracy: 0.7893\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7950 - accuracy: 0.8000 - val_loss: 0.9060 - val_accuracy: 0.7892\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7939 - accuracy: 0.8004 - val_loss: 0.9049 - val_accuracy: 0.7896\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7928 - accuracy: 0.8005 - val_loss: 0.9037 - val_accuracy: 0.7898\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7917 - accuracy: 0.8007 - val_loss: 0.9025 - val_accuracy: 0.7900\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7906 - accuracy: 0.8009 - val_loss: 0.9015 - val_accuracy: 0.7901\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7896 - accuracy: 0.8013 - val_loss: 0.9004 - val_accuracy: 0.7904\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7885 - accuracy: 0.8015 - val_loss: 0.8993 - val_accuracy: 0.7903\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7874 - accuracy: 0.8018 - val_loss: 0.8983 - val_accuracy: 0.7908\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7863 - accuracy: 0.8021 - val_loss: 0.8972 - val_accuracy: 0.7911\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7853 - accuracy: 0.8023 - val_loss: 0.8961 - val_accuracy: 0.7916\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7842 - accuracy: 0.8023 - val_loss: 0.8949 - val_accuracy: 0.7921\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7832 - accuracy: 0.8027 - val_loss: 0.8940 - val_accuracy: 0.7921\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7822 - accuracy: 0.8030 - val_loss: 0.8931 - val_accuracy: 0.7926\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7812 - accuracy: 0.8033 - val_loss: 0.8922 - val_accuracy: 0.7929\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7801 - accuracy: 0.8037 - val_loss: 0.8912 - val_accuracy: 0.7929\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7791 - accuracy: 0.8040 - val_loss: 0.8903 - val_accuracy: 0.7933\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7781 - accuracy: 0.8041 - val_loss: 0.8894 - val_accuracy: 0.7932\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7771 - accuracy: 0.8044 - val_loss: 0.8886 - val_accuracy: 0.7939\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7760 - accuracy: 0.8048 - val_loss: 0.8877 - val_accuracy: 0.7943\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7750 - accuracy: 0.8051 - val_loss: 0.8868 - val_accuracy: 0.7948\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7740 - accuracy: 0.8055 - val_loss: 0.8861 - val_accuracy: 0.7952\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7730 - accuracy: 0.8058 - val_loss: 0.8853 - val_accuracy: 0.7956\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7719 - accuracy: 0.8061 - val_loss: 0.8844 - val_accuracy: 0.7961\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7709 - accuracy: 0.8064 - val_loss: 0.8835 - val_accuracy: 0.7967\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7698 - accuracy: 0.8068 - val_loss: 0.8824 - val_accuracy: 0.7970\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7687 - accuracy: 0.8070 - val_loss: 0.8814 - val_accuracy: 0.7975\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7676 - accuracy: 0.8073 - val_loss: 0.8804 - val_accuracy: 0.7979\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7666 - accuracy: 0.8077 - val_loss: 0.8795 - val_accuracy: 0.7979\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7655 - accuracy: 0.8079 - val_loss: 0.8787 - val_accuracy: 0.7983\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7644 - accuracy: 0.8081 - val_loss: 0.8782 - val_accuracy: 0.7987\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7633 - accuracy: 0.8086 - val_loss: 0.8775 - val_accuracy: 0.7990\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7622 - accuracy: 0.8088 - val_loss: 0.8765 - val_accuracy: 0.7990\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7611 - accuracy: 0.8090 - val_loss: 0.8756 - val_accuracy: 0.7994\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7600 - accuracy: 0.8092 - val_loss: 0.8752 - val_accuracy: 0.8001\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7589 - accuracy: 0.8099 - val_loss: 0.8747 - val_accuracy: 0.8008\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7578 - accuracy: 0.8104 - val_loss: 0.8738 - val_accuracy: 0.8010\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7567 - accuracy: 0.8105 - val_loss: 0.8728 - val_accuracy: 0.8011\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7556 - accuracy: 0.8107 - val_loss: 0.8719 - val_accuracy: 0.8011\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7546 - accuracy: 0.8108 - val_loss: 0.8714 - val_accuracy: 0.8016\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7535 - accuracy: 0.8113 - val_loss: 0.8710 - val_accuracy: 0.8016\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7525 - accuracy: 0.8117 - val_loss: 0.8701 - val_accuracy: 0.8016\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7514 - accuracy: 0.8118 - val_loss: 0.8690 - val_accuracy: 0.8016\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7504 - accuracy: 0.8119 - val_loss: 0.8681 - val_accuracy: 0.8022\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7494 - accuracy: 0.8122 - val_loss: 0.8674 - val_accuracy: 0.8029\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7484 - accuracy: 0.8126 - val_loss: 0.8665 - val_accuracy: 0.8029\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7473 - accuracy: 0.8128 - val_loss: 0.8653 - val_accuracy: 0.8032\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7463 - accuracy: 0.8130 - val_loss: 0.8644 - val_accuracy: 0.8040\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7453 - accuracy: 0.8134 - val_loss: 0.8636 - val_accuracy: 0.8043\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7443 - accuracy: 0.8138 - val_loss: 0.8628 - val_accuracy: 0.8053\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7433 - accuracy: 0.8142 - val_loss: 0.8618 - val_accuracy: 0.8055\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7423 - accuracy: 0.8146 - val_loss: 0.8609 - val_accuracy: 0.8058\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7413 - accuracy: 0.8148 - val_loss: 0.8599 - val_accuracy: 0.8060\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7404 - accuracy: 0.8153 - val_loss: 0.8591 - val_accuracy: 0.8065\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7394 - accuracy: 0.8154 - val_loss: 0.8584 - val_accuracy: 0.8067\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7385 - accuracy: 0.8157 - val_loss: 0.8575 - val_accuracy: 0.8070\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7375 - accuracy: 0.8159 - val_loss: 0.8567 - val_accuracy: 0.8071\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7366 - accuracy: 0.8160 - val_loss: 0.8561 - val_accuracy: 0.8072\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7356 - accuracy: 0.8163 - val_loss: 0.8556 - val_accuracy: 0.8076\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7346 - accuracy: 0.8165 - val_loss: 0.8547 - val_accuracy: 0.8077\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7337 - accuracy: 0.8166 - val_loss: 0.8538 - val_accuracy: 0.8077\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7327 - accuracy: 0.8168 - val_loss: 0.8532 - val_accuracy: 0.8082\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7318 - accuracy: 0.8171 - val_loss: 0.8527 - val_accuracy: 0.8082\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7309 - accuracy: 0.8175 - val_loss: 0.8521 - val_accuracy: 0.8089\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7299 - accuracy: 0.8179 - val_loss: 0.8514 - val_accuracy: 0.8087\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7290 - accuracy: 0.8181 - val_loss: 0.8505 - val_accuracy: 0.8093\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7281 - accuracy: 0.8182 - val_loss: 0.8499 - val_accuracy: 0.8095\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7272 - accuracy: 0.8185 - val_loss: 0.8494 - val_accuracy: 0.8096\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7264 - accuracy: 0.8188 - val_loss: 0.8485 - val_accuracy: 0.8098\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7255 - accuracy: 0.8189 - val_loss: 0.8479 - val_accuracy: 0.8101\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7246 - accuracy: 0.8194 - val_loss: 0.8473 - val_accuracy: 0.8106\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7237 - accuracy: 0.8197 - val_loss: 0.8464 - val_accuracy: 0.8108\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7228 - accuracy: 0.8199 - val_loss: 0.8458 - val_accuracy: 0.8108\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7220 - accuracy: 0.8200 - val_loss: 0.8452 - val_accuracy: 0.8110\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7211 - accuracy: 0.8202 - val_loss: 0.8445 - val_accuracy: 0.8115\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7203 - accuracy: 0.8203 - val_loss: 0.8439 - val_accuracy: 0.8116\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7194 - accuracy: 0.8205 - val_loss: 0.8434 - val_accuracy: 0.8117\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7186 - accuracy: 0.8206 - val_loss: 0.8427 - val_accuracy: 0.8119\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7177 - accuracy: 0.8207 - val_loss: 0.8421 - val_accuracy: 0.8120\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7169 - accuracy: 0.8209 - val_loss: 0.8416 - val_accuracy: 0.8122\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7161 - accuracy: 0.8212 - val_loss: 0.8410 - val_accuracy: 0.8121\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7152 - accuracy: 0.8214 - val_loss: 0.8403 - val_accuracy: 0.8119\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7144 - accuracy: 0.8215 - val_loss: 0.8398 - val_accuracy: 0.8124\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7136 - accuracy: 0.8216 - val_loss: 0.8392 - val_accuracy: 0.8124\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7129 - accuracy: 0.8218 - val_loss: 0.8385 - val_accuracy: 0.8127\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7121 - accuracy: 0.8219 - val_loss: 0.8380 - val_accuracy: 0.8130\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7113 - accuracy: 0.8221 - val_loss: 0.8374 - val_accuracy: 0.8135\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7105 - accuracy: 0.8223 - val_loss: 0.8366 - val_accuracy: 0.8136\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7097 - accuracy: 0.8224 - val_loss: 0.8361 - val_accuracy: 0.8140\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7089 - accuracy: 0.8227 - val_loss: 0.8353 - val_accuracy: 0.8143\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7081 - accuracy: 0.8230 - val_loss: 0.8345 - val_accuracy: 0.8144\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7073 - accuracy: 0.8231 - val_loss: 0.8340 - val_accuracy: 0.8145\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7065 - accuracy: 0.8235 - val_loss: 0.8333 - val_accuracy: 0.8144\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7057 - accuracy: 0.8238 - val_loss: 0.8327 - val_accuracy: 0.8146\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7049 - accuracy: 0.8240 - val_loss: 0.8320 - val_accuracy: 0.8147\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7042 - accuracy: 0.8241 - val_loss: 0.8314 - val_accuracy: 0.8148\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7034 - accuracy: 0.8243 - val_loss: 0.8309 - val_accuracy: 0.8150\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7026 - accuracy: 0.8246 - val_loss: 0.8302 - val_accuracy: 0.8147\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7019 - accuracy: 0.8248 - val_loss: 0.8297 - val_accuracy: 0.8156\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7011 - accuracy: 0.8250 - val_loss: 0.8293 - val_accuracy: 0.8158\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7004 - accuracy: 0.8252 - val_loss: 0.8285 - val_accuracy: 0.8155\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6996 - accuracy: 0.8253 - val_loss: 0.8280 - val_accuracy: 0.8156\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6988 - accuracy: 0.8256 - val_loss: 0.8276 - val_accuracy: 0.8160\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6981 - accuracy: 0.8256 - val_loss: 0.8270 - val_accuracy: 0.8166\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6973 - accuracy: 0.8258 - val_loss: 0.8263 - val_accuracy: 0.8170\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6965 - accuracy: 0.8261 - val_loss: 0.8256 - val_accuracy: 0.8176\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6958 - accuracy: 0.8262 - val_loss: 0.8248 - val_accuracy: 0.8177\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6950 - accuracy: 0.8264 - val_loss: 0.8244 - val_accuracy: 0.8184\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6943 - accuracy: 0.8267 - val_loss: 0.8235 - val_accuracy: 0.8181\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6935 - accuracy: 0.8270 - val_loss: 0.8228 - val_accuracy: 0.8182\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6928 - accuracy: 0.8274 - val_loss: 0.8222 - val_accuracy: 0.8184\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6920 - accuracy: 0.8275 - val_loss: 0.8216 - val_accuracy: 0.8188\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6913 - accuracy: 0.8276 - val_loss: 0.8210 - val_accuracy: 0.8191\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6905 - accuracy: 0.8278 - val_loss: 0.8204 - val_accuracy: 0.8194\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6898 - accuracy: 0.8281 - val_loss: 0.8197 - val_accuracy: 0.8200\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6890 - accuracy: 0.8283 - val_loss: 0.8192 - val_accuracy: 0.8204\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6883 - accuracy: 0.8283 - val_loss: 0.8185 - val_accuracy: 0.8203\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6876 - accuracy: 0.8284 - val_loss: 0.8180 - val_accuracy: 0.8206\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6868 - accuracy: 0.8287 - val_loss: 0.8174 - val_accuracy: 0.8207\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6861 - accuracy: 0.8288 - val_loss: 0.8168 - val_accuracy: 0.8210\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6854 - accuracy: 0.8290 - val_loss: 0.8164 - val_accuracy: 0.8213\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6847 - accuracy: 0.8292 - val_loss: 0.8159 - val_accuracy: 0.8212\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6840 - accuracy: 0.8293 - val_loss: 0.8153 - val_accuracy: 0.8213\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6832 - accuracy: 0.8295 - val_loss: 0.8148 - val_accuracy: 0.8217\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6825 - accuracy: 0.8297 - val_loss: 0.8142 - val_accuracy: 0.8218\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6818 - accuracy: 0.8298 - val_loss: 0.8136 - val_accuracy: 0.8219\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6811 - accuracy: 0.8300 - val_loss: 0.8131 - val_accuracy: 0.8219\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6804 - accuracy: 0.8302 - val_loss: 0.8124 - val_accuracy: 0.8221\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6797 - accuracy: 0.8304 - val_loss: 0.8117 - val_accuracy: 0.8222\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6790 - accuracy: 0.8306 - val_loss: 0.8112 - val_accuracy: 0.8226\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6782 - accuracy: 0.8308 - val_loss: 0.8106 - val_accuracy: 0.8226\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6775 - accuracy: 0.8309 - val_loss: 0.8100 - val_accuracy: 0.8229\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6768 - accuracy: 0.8311 - val_loss: 0.8095 - val_accuracy: 0.8237\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6761 - accuracy: 0.8312 - val_loss: 0.8089 - val_accuracy: 0.8236\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6754 - accuracy: 0.8316 - val_loss: 0.8084 - val_accuracy: 0.8237\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6747 - accuracy: 0.8317 - val_loss: 0.8079 - val_accuracy: 0.8240\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6740 - accuracy: 0.8318 - val_loss: 0.8073 - val_accuracy: 0.8243\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6733 - accuracy: 0.8319 - val_loss: 0.8068 - val_accuracy: 0.8246\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6726 - accuracy: 0.8321 - val_loss: 0.8064 - val_accuracy: 0.8247\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6718 - accuracy: 0.8322 - val_loss: 0.8059 - val_accuracy: 0.8248\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6712 - accuracy: 0.8325 - val_loss: 0.8056 - val_accuracy: 0.8252\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6705 - accuracy: 0.8326 - val_loss: 0.8050 - val_accuracy: 0.8253\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6698 - accuracy: 0.8327 - val_loss: 0.8045 - val_accuracy: 0.8255\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6691 - accuracy: 0.8328 - val_loss: 0.8039 - val_accuracy: 0.8256\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6684 - accuracy: 0.8329 - val_loss: 0.8033 - val_accuracy: 0.8256\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6677 - accuracy: 0.8331 - val_loss: 0.8029 - val_accuracy: 0.8258\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6671 - accuracy: 0.8333 - val_loss: 0.8021 - val_accuracy: 0.8259\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6664 - accuracy: 0.8334 - val_loss: 0.8017 - val_accuracy: 0.8260\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6657 - accuracy: 0.8336 - val_loss: 0.8013 - val_accuracy: 0.8260\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6651 - accuracy: 0.8337 - val_loss: 0.8004 - val_accuracy: 0.8262\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6644 - accuracy: 0.8339 - val_loss: 0.8002 - val_accuracy: 0.8263\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6637 - accuracy: 0.8341 - val_loss: 0.7998 - val_accuracy: 0.8264\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6630 - accuracy: 0.8342 - val_loss: 0.7990 - val_accuracy: 0.8265\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6624 - accuracy: 0.8344 - val_loss: 0.7988 - val_accuracy: 0.8269\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6617 - accuracy: 0.8345 - val_loss: 0.7983 - val_accuracy: 0.8269\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6611 - accuracy: 0.8347 - val_loss: 0.7976 - val_accuracy: 0.8274\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6604 - accuracy: 0.8347 - val_loss: 0.7972 - val_accuracy: 0.8275\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6598 - accuracy: 0.8349 - val_loss: 0.7968 - val_accuracy: 0.8275\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6591 - accuracy: 0.8349 - val_loss: 0.7962 - val_accuracy: 0.8277\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6585 - accuracy: 0.8352 - val_loss: 0.7958 - val_accuracy: 0.8279\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6578 - accuracy: 0.8354 - val_loss: 0.7953 - val_accuracy: 0.8280\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6572 - accuracy: 0.8356 - val_loss: 0.7949 - val_accuracy: 0.8284\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6565 - accuracy: 0.8357 - val_loss: 0.7944 - val_accuracy: 0.8288\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6559 - accuracy: 0.8359 - val_loss: 0.7941 - val_accuracy: 0.8291\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6552 - accuracy: 0.8360 - val_loss: 0.7936 - val_accuracy: 0.8293\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6546 - accuracy: 0.8362 - val_loss: 0.7931 - val_accuracy: 0.8293\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6540 - accuracy: 0.8364 - val_loss: 0.7928 - val_accuracy: 0.8295\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6534 - accuracy: 0.8366 - val_loss: 0.7919 - val_accuracy: 0.8294\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6528 - accuracy: 0.8367 - val_loss: 0.7917 - val_accuracy: 0.8297\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6521 - accuracy: 0.8369 - val_loss: 0.7913 - val_accuracy: 0.8301\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6515 - accuracy: 0.8369 - val_loss: 0.7908 - val_accuracy: 0.8304\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6508 - accuracy: 0.8370 - val_loss: 0.7904 - val_accuracy: 0.8304\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6502 - accuracy: 0.8371 - val_loss: 0.7901 - val_accuracy: 0.8304\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6496 - accuracy: 0.8371 - val_loss: 0.7897 - val_accuracy: 0.8306\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6489 - accuracy: 0.8375 - val_loss: 0.7892 - val_accuracy: 0.8307\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6483 - accuracy: 0.8377 - val_loss: 0.7889 - val_accuracy: 0.8308\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6477 - accuracy: 0.8378 - val_loss: 0.7884 - val_accuracy: 0.8309\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6471 - accuracy: 0.8380 - val_loss: 0.7880 - val_accuracy: 0.8308\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6465 - accuracy: 0.8382 - val_loss: 0.7876 - val_accuracy: 0.8309\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6458 - accuracy: 0.8384 - val_loss: 0.7870 - val_accuracy: 0.8313\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6452 - accuracy: 0.8385 - val_loss: 0.7865 - val_accuracy: 0.8314\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6446 - accuracy: 0.8387 - val_loss: 0.7860 - val_accuracy: 0.8315\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6440 - accuracy: 0.8390 - val_loss: 0.7855 - val_accuracy: 0.8319\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6433 - accuracy: 0.8392 - val_loss: 0.7852 - val_accuracy: 0.8318\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6427 - accuracy: 0.8393 - val_loss: 0.7846 - val_accuracy: 0.8322\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6421 - accuracy: 0.8394 - val_loss: 0.7842 - val_accuracy: 0.8326\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6414 - accuracy: 0.8396 - val_loss: 0.7837 - val_accuracy: 0.8328\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6408 - accuracy: 0.8398 - val_loss: 0.7831 - val_accuracy: 0.8327\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6402 - accuracy: 0.8400 - val_loss: 0.7828 - val_accuracy: 0.8327\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6395 - accuracy: 0.8401 - val_loss: 0.7821 - val_accuracy: 0.8329\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6389 - accuracy: 0.8404 - val_loss: 0.7816 - val_accuracy: 0.8332\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6382 - accuracy: 0.8407 - val_loss: 0.7809 - val_accuracy: 0.8335\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6376 - accuracy: 0.8407 - val_loss: 0.7807 - val_accuracy: 0.8342\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6370 - accuracy: 0.8409 - val_loss: 0.7798 - val_accuracy: 0.8342\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6364 - accuracy: 0.8409 - val_loss: 0.7793 - val_accuracy: 0.8346\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6357 - accuracy: 0.8411 - val_loss: 0.7790 - val_accuracy: 0.8350\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6351 - accuracy: 0.8414 - val_loss: 0.7782 - val_accuracy: 0.8348\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6344 - accuracy: 0.8415 - val_loss: 0.7777 - val_accuracy: 0.8349\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6338 - accuracy: 0.8418 - val_loss: 0.7774 - val_accuracy: 0.8353\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6332 - accuracy: 0.8418 - val_loss: 0.7768 - val_accuracy: 0.8352\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6326 - accuracy: 0.8418 - val_loss: 0.7763 - val_accuracy: 0.8353\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6319 - accuracy: 0.8419 - val_loss: 0.7761 - val_accuracy: 0.8357\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6313 - accuracy: 0.8420 - val_loss: 0.7755 - val_accuracy: 0.8359\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6307 - accuracy: 0.8421 - val_loss: 0.7749 - val_accuracy: 0.8363\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6301 - accuracy: 0.8422 - val_loss: 0.7745 - val_accuracy: 0.8365\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6294 - accuracy: 0.8425 - val_loss: 0.7741 - val_accuracy: 0.8362\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6288 - accuracy: 0.8426 - val_loss: 0.7735 - val_accuracy: 0.8363\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6282 - accuracy: 0.8428 - val_loss: 0.7731 - val_accuracy: 0.8364\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6276 - accuracy: 0.8428 - val_loss: 0.7726 - val_accuracy: 0.8365\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6270 - accuracy: 0.8430 - val_loss: 0.7722 - val_accuracy: 0.8366\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6264 - accuracy: 0.8431 - val_loss: 0.7715 - val_accuracy: 0.8369\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6258 - accuracy: 0.8432 - val_loss: 0.7712 - val_accuracy: 0.8370\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6252 - accuracy: 0.8433 - val_loss: 0.7709 - val_accuracy: 0.8373\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6246 - accuracy: 0.8434 - val_loss: 0.7702 - val_accuracy: 0.8374\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6241 - accuracy: 0.8435 - val_loss: 0.7698 - val_accuracy: 0.8374\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6235 - accuracy: 0.8437 - val_loss: 0.7697 - val_accuracy: 0.8378\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6231 - accuracy: 0.8439 - val_loss: 0.7688 - val_accuracy: 0.8376\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6224 - accuracy: 0.8439 - val_loss: 0.7683 - val_accuracy: 0.8379\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6218 - accuracy: 0.8440 - val_loss: 0.7683 - val_accuracy: 0.8380\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6213 - accuracy: 0.8441 - val_loss: 0.7676 - val_accuracy: 0.8382\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6206 - accuracy: 0.8442 - val_loss: 0.7668 - val_accuracy: 0.8381\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6202 - accuracy: 0.8443 - val_loss: 0.7665 - val_accuracy: 0.8377\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6196 - accuracy: 0.8443 - val_loss: 0.7666 - val_accuracy: 0.8379\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6191 - accuracy: 0.8443 - val_loss: 0.7656 - val_accuracy: 0.8385\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6184 - accuracy: 0.8446 - val_loss: 0.7649 - val_accuracy: 0.8386\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6179 - accuracy: 0.8447 - val_loss: 0.7647 - val_accuracy: 0.8385\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6173 - accuracy: 0.8449 - val_loss: 0.7645 - val_accuracy: 0.8388\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6168 - accuracy: 0.8450 - val_loss: 0.7639 - val_accuracy: 0.8387\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6162 - accuracy: 0.8451 - val_loss: 0.7637 - val_accuracy: 0.8389\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6156 - accuracy: 0.8452 - val_loss: 0.7634 - val_accuracy: 0.8386\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6151 - accuracy: 0.8454 - val_loss: 0.7628 - val_accuracy: 0.8388\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6144 - accuracy: 0.8457 - val_loss: 0.7623 - val_accuracy: 0.8391\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6139 - accuracy: 0.8458 - val_loss: 0.7620 - val_accuracy: 0.8391\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6133 - accuracy: 0.8459 - val_loss: 0.7616 - val_accuracy: 0.8394\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6127 - accuracy: 0.8461 - val_loss: 0.7614 - val_accuracy: 0.8400\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6122 - accuracy: 0.8462 - val_loss: 0.7613 - val_accuracy: 0.8402\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6117 - accuracy: 0.8463 - val_loss: 0.7606 - val_accuracy: 0.8399\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6111 - accuracy: 0.8464 - val_loss: 0.7604 - val_accuracy: 0.8401\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6104 - accuracy: 0.8465 - val_loss: 0.7604 - val_accuracy: 0.8403\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6100 - accuracy: 0.8468 - val_loss: 0.7594 - val_accuracy: 0.8402\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6095 - accuracy: 0.8468 - val_loss: 0.7595 - val_accuracy: 0.8405\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6087 - accuracy: 0.8471 - val_loss: 0.7597 - val_accuracy: 0.8408\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6083 - accuracy: 0.8473 - val_loss: 0.7585 - val_accuracy: 0.8404\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6078 - accuracy: 0.8472 - val_loss: 0.7584 - val_accuracy: 0.8406\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6071 - accuracy: 0.8474 - val_loss: 0.7592 - val_accuracy: 0.8409\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6067 - accuracy: 0.8476 - val_loss: 0.7583 - val_accuracy: 0.8408\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6059 - accuracy: 0.8478 - val_loss: 0.7574 - val_accuracy: 0.8405\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6055 - accuracy: 0.8477 - val_loss: 0.7575 - val_accuracy: 0.8409\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6048 - accuracy: 0.8479 - val_loss: 0.7579 - val_accuracy: 0.8413\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6044 - accuracy: 0.8480 - val_loss: 0.7570 - val_accuracy: 0.8409\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6037 - accuracy: 0.8482 - val_loss: 0.7565 - val_accuracy: 0.8410\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6032 - accuracy: 0.8482 - val_loss: 0.7570 - val_accuracy: 0.8413\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6026 - accuracy: 0.8484 - val_loss: 0.7568 - val_accuracy: 0.8414\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6020 - accuracy: 0.8486 - val_loss: 0.7556 - val_accuracy: 0.8412\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6015 - accuracy: 0.8486 - val_loss: 0.7554 - val_accuracy: 0.8412\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6009 - accuracy: 0.8488 - val_loss: 0.7558 - val_accuracy: 0.8412\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6005 - accuracy: 0.8490 - val_loss: 0.7552 - val_accuracy: 0.8412\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5998 - accuracy: 0.8492 - val_loss: 0.7543 - val_accuracy: 0.8412\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5994 - accuracy: 0.8493 - val_loss: 0.7543 - val_accuracy: 0.8412\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5987 - accuracy: 0.8493 - val_loss: 0.7547 - val_accuracy: 0.8416\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5984 - accuracy: 0.8496 - val_loss: 0.7535 - val_accuracy: 0.8415\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5977 - accuracy: 0.8497 - val_loss: 0.7530 - val_accuracy: 0.8417\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5971 - accuracy: 0.8499 - val_loss: 0.7534 - val_accuracy: 0.8419\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5966 - accuracy: 0.8501 - val_loss: 0.7530 - val_accuracy: 0.8418\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5960 - accuracy: 0.8503 - val_loss: 0.7521 - val_accuracy: 0.8416\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5955 - accuracy: 0.8504 - val_loss: 0.7521 - val_accuracy: 0.8418\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5949 - accuracy: 0.8505 - val_loss: 0.7525 - val_accuracy: 0.8421\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5945 - accuracy: 0.8505 - val_loss: 0.7516 - val_accuracy: 0.8422\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5938 - accuracy: 0.8508 - val_loss: 0.7510 - val_accuracy: 0.8421\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5933 - accuracy: 0.8509 - val_loss: 0.7512 - val_accuracy: 0.8426\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5927 - accuracy: 0.8510 - val_loss: 0.7509 - val_accuracy: 0.8427\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5922 - accuracy: 0.8512 - val_loss: 0.7500 - val_accuracy: 0.8424\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5917 - accuracy: 0.8514 - val_loss: 0.7498 - val_accuracy: 0.8425\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5911 - accuracy: 0.8515 - val_loss: 0.7500 - val_accuracy: 0.8428\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5907 - accuracy: 0.8515 - val_loss: 0.7492 - val_accuracy: 0.8427\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5900 - accuracy: 0.8516 - val_loss: 0.7485 - val_accuracy: 0.8425\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5896 - accuracy: 0.8518 - val_loss: 0.7486 - val_accuracy: 0.8426\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5889 - accuracy: 0.8520 - val_loss: 0.7483 - val_accuracy: 0.8430\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5884 - accuracy: 0.8522 - val_loss: 0.7477 - val_accuracy: 0.8431\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5879 - accuracy: 0.8523 - val_loss: 0.7476 - val_accuracy: 0.8433\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5873 - accuracy: 0.8524 - val_loss: 0.7475 - val_accuracy: 0.8435\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5868 - accuracy: 0.8524 - val_loss: 0.7466 - val_accuracy: 0.8434\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5863 - accuracy: 0.8526 - val_loss: 0.7465 - val_accuracy: 0.8435\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5857 - accuracy: 0.8528 - val_loss: 0.7463 - val_accuracy: 0.8436\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5852 - accuracy: 0.8529 - val_loss: 0.7455 - val_accuracy: 0.8436\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5847 - accuracy: 0.8530 - val_loss: 0.7454 - val_accuracy: 0.8440\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5841 - accuracy: 0.8530 - val_loss: 0.7457 - val_accuracy: 0.8442\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5837 - accuracy: 0.8532 - val_loss: 0.7448 - val_accuracy: 0.8442\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5830 - accuracy: 0.8533 - val_loss: 0.7447 - val_accuracy: 0.8442\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5824 - accuracy: 0.8535 - val_loss: 0.7450 - val_accuracy: 0.8447\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5819 - accuracy: 0.8535 - val_loss: 0.7444 - val_accuracy: 0.8445\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5813 - accuracy: 0.8537 - val_loss: 0.7441 - val_accuracy: 0.8445\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5807 - accuracy: 0.8538 - val_loss: 0.7442 - val_accuracy: 0.8449\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5802 - accuracy: 0.8539 - val_loss: 0.7440 - val_accuracy: 0.8450\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5796 - accuracy: 0.8540 - val_loss: 0.7433 - val_accuracy: 0.8448\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5790 - accuracy: 0.8542 - val_loss: 0.7430 - val_accuracy: 0.8450\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5784 - accuracy: 0.8543 - val_loss: 0.7429 - val_accuracy: 0.8448\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5779 - accuracy: 0.8544 - val_loss: 0.7423 - val_accuracy: 0.8450\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5773 - accuracy: 0.8545 - val_loss: 0.7419 - val_accuracy: 0.8449\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5768 - accuracy: 0.8546 - val_loss: 0.7419 - val_accuracy: 0.8452\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5763 - accuracy: 0.8547 - val_loss: 0.7412 - val_accuracy: 0.8450\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5757 - accuracy: 0.8550 - val_loss: 0.7411 - val_accuracy: 0.8454\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5751 - accuracy: 0.8551 - val_loss: 0.7411 - val_accuracy: 0.8457\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5746 - accuracy: 0.8551 - val_loss: 0.7404 - val_accuracy: 0.8457\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5740 - accuracy: 0.8553 - val_loss: 0.7400 - val_accuracy: 0.8457\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5735 - accuracy: 0.8553 - val_loss: 0.7399 - val_accuracy: 0.8459\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5729 - accuracy: 0.8555 - val_loss: 0.7393 - val_accuracy: 0.8456\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5724 - accuracy: 0.8556 - val_loss: 0.7391 - val_accuracy: 0.8457\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5718 - accuracy: 0.8557 - val_loss: 0.7390 - val_accuracy: 0.8458\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5713 - accuracy: 0.8560 - val_loss: 0.7384 - val_accuracy: 0.8457\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5707 - accuracy: 0.8562 - val_loss: 0.7380 - val_accuracy: 0.8456\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5702 - accuracy: 0.8564 - val_loss: 0.7378 - val_accuracy: 0.8457\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5696 - accuracy: 0.8565 - val_loss: 0.7374 - val_accuracy: 0.8456\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5690 - accuracy: 0.8567 - val_loss: 0.7371 - val_accuracy: 0.8456\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5685 - accuracy: 0.8569 - val_loss: 0.7368 - val_accuracy: 0.8455\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5680 - accuracy: 0.8570 - val_loss: 0.7364 - val_accuracy: 0.8454\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5674 - accuracy: 0.8571 - val_loss: 0.7359 - val_accuracy: 0.8458\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5669 - accuracy: 0.8573 - val_loss: 0.7355 - val_accuracy: 0.8459\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5663 - accuracy: 0.8574 - val_loss: 0.7353 - val_accuracy: 0.8466\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5658 - accuracy: 0.8575 - val_loss: 0.7348 - val_accuracy: 0.8466\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5653 - accuracy: 0.8577 - val_loss: 0.7345 - val_accuracy: 0.8466\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5647 - accuracy: 0.8577 - val_loss: 0.7342 - val_accuracy: 0.8468\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5642 - accuracy: 0.8579 - val_loss: 0.7336 - val_accuracy: 0.8466\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5637 - accuracy: 0.8580 - val_loss: 0.7332 - val_accuracy: 0.8470\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5632 - accuracy: 0.8582 - val_loss: 0.7328 - val_accuracy: 0.8469\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5626 - accuracy: 0.8583 - val_loss: 0.7324 - val_accuracy: 0.8471\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5621 - accuracy: 0.8585 - val_loss: 0.7322 - val_accuracy: 0.8473\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5616 - accuracy: 0.8586 - val_loss: 0.7317 - val_accuracy: 0.8474\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5610 - accuracy: 0.8589 - val_loss: 0.7314 - val_accuracy: 0.8477\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5605 - accuracy: 0.8589 - val_loss: 0.7313 - val_accuracy: 0.8479\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5601 - accuracy: 0.8590 - val_loss: 0.7307 - val_accuracy: 0.8479\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5595 - accuracy: 0.8591 - val_loss: 0.7305 - val_accuracy: 0.8481\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5589 - accuracy: 0.8593 - val_loss: 0.7305 - val_accuracy: 0.8485\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5585 - accuracy: 0.8593 - val_loss: 0.7299 - val_accuracy: 0.8482\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5579 - accuracy: 0.8594 - val_loss: 0.7297 - val_accuracy: 0.8482\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5574 - accuracy: 0.8595 - val_loss: 0.7297 - val_accuracy: 0.8485\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5569 - accuracy: 0.8595 - val_loss: 0.7292 - val_accuracy: 0.8484\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5564 - accuracy: 0.8598 - val_loss: 0.7289 - val_accuracy: 0.8487\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5559 - accuracy: 0.8600 - val_loss: 0.7288 - val_accuracy: 0.8490\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5554 - accuracy: 0.8600 - val_loss: 0.7286 - val_accuracy: 0.8491\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5548 - accuracy: 0.8600 - val_loss: 0.7284 - val_accuracy: 0.8491\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5543 - accuracy: 0.8601 - val_loss: 0.7283 - val_accuracy: 0.8490\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5538 - accuracy: 0.8602 - val_loss: 0.7280 - val_accuracy: 0.8489\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5533 - accuracy: 0.8603 - val_loss: 0.7277 - val_accuracy: 0.8489\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5527 - accuracy: 0.8604 - val_loss: 0.7274 - val_accuracy: 0.8491\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5522 - accuracy: 0.8603 - val_loss: 0.7272 - val_accuracy: 0.8493\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5517 - accuracy: 0.8604 - val_loss: 0.7271 - val_accuracy: 0.8494\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5512 - accuracy: 0.8605 - val_loss: 0.7270 - val_accuracy: 0.8494\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5507 - accuracy: 0.8606 - val_loss: 0.7267 - val_accuracy: 0.8496\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5502 - accuracy: 0.8608 - val_loss: 0.7265 - val_accuracy: 0.8497\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5498 - accuracy: 0.8609 - val_loss: 0.7261 - val_accuracy: 0.8497\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5493 - accuracy: 0.8610 - val_loss: 0.7259 - val_accuracy: 0.8498\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5488 - accuracy: 0.8611 - val_loss: 0.7253 - val_accuracy: 0.8497\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5483 - accuracy: 0.8613 - val_loss: 0.7251 - val_accuracy: 0.8499\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5478 - accuracy: 0.8612 - val_loss: 0.7248 - val_accuracy: 0.8500\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5473 - accuracy: 0.8613 - val_loss: 0.7243 - val_accuracy: 0.8505\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5469 - accuracy: 0.8615 - val_loss: 0.7240 - val_accuracy: 0.8505\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5464 - accuracy: 0.8615 - val_loss: 0.7236 - val_accuracy: 0.8506\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5459 - accuracy: 0.8615 - val_loss: 0.7233 - val_accuracy: 0.8505\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5454 - accuracy: 0.8616 - val_loss: 0.7231 - val_accuracy: 0.8508\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5450 - accuracy: 0.8617 - val_loss: 0.7226 - val_accuracy: 0.8507\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5445 - accuracy: 0.8617 - val_loss: 0.7223 - val_accuracy: 0.8510\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5440 - accuracy: 0.8618 - val_loss: 0.7220 - val_accuracy: 0.8510\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5436 - accuracy: 0.8619 - val_loss: 0.7216 - val_accuracy: 0.8510\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5432 - accuracy: 0.8620 - val_loss: 0.7216 - val_accuracy: 0.8511\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5427 - accuracy: 0.8622 - val_loss: 0.7212 - val_accuracy: 0.8511\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5422 - accuracy: 0.8622 - val_loss: 0.7208 - val_accuracy: 0.8511\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5417 - accuracy: 0.8623 - val_loss: 0.7207 - val_accuracy: 0.8513\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5413 - accuracy: 0.8625 - val_loss: 0.7203 - val_accuracy: 0.8513\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5408 - accuracy: 0.8626 - val_loss: 0.7199 - val_accuracy: 0.8515\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5404 - accuracy: 0.8627 - val_loss: 0.7198 - val_accuracy: 0.8518\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5400 - accuracy: 0.8627 - val_loss: 0.7192 - val_accuracy: 0.8518\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5396 - accuracy: 0.8629 - val_loss: 0.7190 - val_accuracy: 0.8521\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5390 - accuracy: 0.8630 - val_loss: 0.7189 - val_accuracy: 0.8520\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5387 - accuracy: 0.8630 - val_loss: 0.7183 - val_accuracy: 0.8521\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5382 - accuracy: 0.8631 - val_loss: 0.7181 - val_accuracy: 0.8521\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5378 - accuracy: 0.8632 - val_loss: 0.7181 - val_accuracy: 0.8524\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5374 - accuracy: 0.8631 - val_loss: 0.7176 - val_accuracy: 0.8527\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5369 - accuracy: 0.8634 - val_loss: 0.7172 - val_accuracy: 0.8523\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5365 - accuracy: 0.8635 - val_loss: 0.7172 - val_accuracy: 0.8526\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5361 - accuracy: 0.8636 - val_loss: 0.7167 - val_accuracy: 0.8524\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5356 - accuracy: 0.8636 - val_loss: 0.7164 - val_accuracy: 0.8524\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5352 - accuracy: 0.8637 - val_loss: 0.7163 - val_accuracy: 0.8525\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5348 - accuracy: 0.8637 - val_loss: 0.7159 - val_accuracy: 0.8523\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5344 - accuracy: 0.8638 - val_loss: 0.7158 - val_accuracy: 0.8524\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5339 - accuracy: 0.8638 - val_loss: 0.7156 - val_accuracy: 0.8527\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5335 - accuracy: 0.8639 - val_loss: 0.7152 - val_accuracy: 0.8526\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5331 - accuracy: 0.8641 - val_loss: 0.7151 - val_accuracy: 0.8527\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5327 - accuracy: 0.8642 - val_loss: 0.7147 - val_accuracy: 0.8529\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5323 - accuracy: 0.8643 - val_loss: 0.7145 - val_accuracy: 0.8527\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5319 - accuracy: 0.8643 - val_loss: 0.7142 - val_accuracy: 0.8528\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5314 - accuracy: 0.8645 - val_loss: 0.7139 - val_accuracy: 0.8530\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5310 - accuracy: 0.8645 - val_loss: 0.7135 - val_accuracy: 0.8531\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5306 - accuracy: 0.8646 - val_loss: 0.7131 - val_accuracy: 0.8532\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5302 - accuracy: 0.8647 - val_loss: 0.7130 - val_accuracy: 0.8532\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5299 - accuracy: 0.8647 - val_loss: 0.7125 - val_accuracy: 0.8532\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5295 - accuracy: 0.8648 - val_loss: 0.7125 - val_accuracy: 0.8535\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5290 - accuracy: 0.8649 - val_loss: 0.7123 - val_accuracy: 0.8536\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5286 - accuracy: 0.8651 - val_loss: 0.7117 - val_accuracy: 0.8536\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5283 - accuracy: 0.8653 - val_loss: 0.7116 - val_accuracy: 0.8539\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5278 - accuracy: 0.8655 - val_loss: 0.7112 - val_accuracy: 0.8541\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5274 - accuracy: 0.8655 - val_loss: 0.7107 - val_accuracy: 0.8541\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5270 - accuracy: 0.8656 - val_loss: 0.7104 - val_accuracy: 0.8542\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5266 - accuracy: 0.8658 - val_loss: 0.7100 - val_accuracy: 0.8543\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5262 - accuracy: 0.8659 - val_loss: 0.7095 - val_accuracy: 0.8546\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5258 - accuracy: 0.8660 - val_loss: 0.7094 - val_accuracy: 0.8546\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5254 - accuracy: 0.8661 - val_loss: 0.7089 - val_accuracy: 0.8549\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5250 - accuracy: 0.8663 - val_loss: 0.7088 - val_accuracy: 0.8550\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5246 - accuracy: 0.8664 - val_loss: 0.7085 - val_accuracy: 0.8549\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5242 - accuracy: 0.8665 - val_loss: 0.7082 - val_accuracy: 0.8549\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5238 - accuracy: 0.8666 - val_loss: 0.7079 - val_accuracy: 0.8549\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5234 - accuracy: 0.8666 - val_loss: 0.7076 - val_accuracy: 0.8549\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5229 - accuracy: 0.8668 - val_loss: 0.7075 - val_accuracy: 0.8552\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5225 - accuracy: 0.8670 - val_loss: 0.7072 - val_accuracy: 0.8551\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5221 - accuracy: 0.8671 - val_loss: 0.7071 - val_accuracy: 0.8553\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5217 - accuracy: 0.8671 - val_loss: 0.7069 - val_accuracy: 0.8556\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5213 - accuracy: 0.8672 - val_loss: 0.7063 - val_accuracy: 0.8556\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5209 - accuracy: 0.8673 - val_loss: 0.7062 - val_accuracy: 0.8556\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5205 - accuracy: 0.8674 - val_loss: 0.7058 - val_accuracy: 0.8558\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5200 - accuracy: 0.8674 - val_loss: 0.7055 - val_accuracy: 0.8559\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5197 - accuracy: 0.8676 - val_loss: 0.7052 - val_accuracy: 0.8560\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5193 - accuracy: 0.8677 - val_loss: 0.7049 - val_accuracy: 0.8561\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5189 - accuracy: 0.8678 - val_loss: 0.7044 - val_accuracy: 0.8561\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5185 - accuracy: 0.8679 - val_loss: 0.7042 - val_accuracy: 0.8561\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5181 - accuracy: 0.8679 - val_loss: 0.7039 - val_accuracy: 0.8560\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5177 - accuracy: 0.8679 - val_loss: 0.7036 - val_accuracy: 0.8561\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5172 - accuracy: 0.8680 - val_loss: 0.7035 - val_accuracy: 0.8563\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5169 - accuracy: 0.8682 - val_loss: 0.7029 - val_accuracy: 0.8565\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5165 - accuracy: 0.8682 - val_loss: 0.7027 - val_accuracy: 0.8566\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5160 - accuracy: 0.8684 - val_loss: 0.7024 - val_accuracy: 0.8569\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5156 - accuracy: 0.8685 - val_loss: 0.7018 - val_accuracy: 0.8569\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5153 - accuracy: 0.8686 - val_loss: 0.7017 - val_accuracy: 0.8573\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5149 - accuracy: 0.8687 - val_loss: 0.7015 - val_accuracy: 0.8576\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5145 - accuracy: 0.8687 - val_loss: 0.7009 - val_accuracy: 0.8571\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5142 - accuracy: 0.8688 - val_loss: 0.7008 - val_accuracy: 0.8574\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5137 - accuracy: 0.8690 - val_loss: 0.7008 - val_accuracy: 0.8579\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5134 - accuracy: 0.8691 - val_loss: 0.7001 - val_accuracy: 0.8577\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5130 - accuracy: 0.8692 - val_loss: 0.6998 - val_accuracy: 0.8578\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5126 - accuracy: 0.8694 - val_loss: 0.7002 - val_accuracy: 0.8582\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5123 - accuracy: 0.8694 - val_loss: 0.6994 - val_accuracy: 0.8581\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5117 - accuracy: 0.8695 - val_loss: 0.6991 - val_accuracy: 0.8579\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5114 - accuracy: 0.8696 - val_loss: 0.6991 - val_accuracy: 0.8585\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5109 - accuracy: 0.8697 - val_loss: 0.6989 - val_accuracy: 0.8584\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5105 - accuracy: 0.8698 - val_loss: 0.6986 - val_accuracy: 0.8583\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5101 - accuracy: 0.8699 - val_loss: 0.6984 - val_accuracy: 0.8582\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5097 - accuracy: 0.8701 - val_loss: 0.6981 - val_accuracy: 0.8581\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5093 - accuracy: 0.8701 - val_loss: 0.6979 - val_accuracy: 0.8584\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5088 - accuracy: 0.8702 - val_loss: 0.6976 - val_accuracy: 0.8584\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5084 - accuracy: 0.8702 - val_loss: 0.6972 - val_accuracy: 0.8585\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5080 - accuracy: 0.8704 - val_loss: 0.6970 - val_accuracy: 0.8586\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5076 - accuracy: 0.8704 - val_loss: 0.6966 - val_accuracy: 0.8586\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5072 - accuracy: 0.8704 - val_loss: 0.6963 - val_accuracy: 0.8586\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5068 - accuracy: 0.8705 - val_loss: 0.6961 - val_accuracy: 0.8588\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5064 - accuracy: 0.8706 - val_loss: 0.6956 - val_accuracy: 0.8585\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5061 - accuracy: 0.8706 - val_loss: 0.6955 - val_accuracy: 0.8587\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5056 - accuracy: 0.8708 - val_loss: 0.6955 - val_accuracy: 0.8592\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5053 - accuracy: 0.8709 - val_loss: 0.6947 - val_accuracy: 0.8586\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5050 - accuracy: 0.8709 - val_loss: 0.6945 - val_accuracy: 0.8589\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5045 - accuracy: 0.8711 - val_loss: 0.6948 - val_accuracy: 0.8594\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5043 - accuracy: 0.8711 - val_loss: 0.6939 - val_accuracy: 0.8591\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5037 - accuracy: 0.8713 - val_loss: 0.6935 - val_accuracy: 0.8593\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5033 - accuracy: 0.8714 - val_loss: 0.6934 - val_accuracy: 0.8595\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5029 - accuracy: 0.8716 - val_loss: 0.6930 - val_accuracy: 0.8595\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5024 - accuracy: 0.8717 - val_loss: 0.6925 - val_accuracy: 0.8595\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5021 - accuracy: 0.8717 - val_loss: 0.6923 - val_accuracy: 0.8596\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5016 - accuracy: 0.8719 - val_loss: 0.6921 - val_accuracy: 0.8599\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5013 - accuracy: 0.8720 - val_loss: 0.6916 - val_accuracy: 0.8599\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5009 - accuracy: 0.8722 - val_loss: 0.6914 - val_accuracy: 0.8601\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5004 - accuracy: 0.8722 - val_loss: 0.6915 - val_accuracy: 0.8606\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5002 - accuracy: 0.8723 - val_loss: 0.6907 - val_accuracy: 0.8602\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4998 - accuracy: 0.8723 - val_loss: 0.6903 - val_accuracy: 0.8604\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4994 - accuracy: 0.8724 - val_loss: 0.6904 - val_accuracy: 0.8608\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4990 - accuracy: 0.8724 - val_loss: 0.6901 - val_accuracy: 0.8608\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4986 - accuracy: 0.8724 - val_loss: 0.6894 - val_accuracy: 0.8604\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4983 - accuracy: 0.8726 - val_loss: 0.6891 - val_accuracy: 0.8604\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4979 - accuracy: 0.8727 - val_loss: 0.6892 - val_accuracy: 0.8610\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4975 - accuracy: 0.8728 - val_loss: 0.6886 - val_accuracy: 0.8609\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4970 - accuracy: 0.8730 - val_loss: 0.6882 - val_accuracy: 0.8608\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4967 - accuracy: 0.8730 - val_loss: 0.6880 - val_accuracy: 0.8610\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4963 - accuracy: 0.8731 - val_loss: 0.6877 - val_accuracy: 0.8612\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4959 - accuracy: 0.8732 - val_loss: 0.6872 - val_accuracy: 0.8612\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4955 - accuracy: 0.8732 - val_loss: 0.6869 - val_accuracy: 0.8615\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4951 - accuracy: 0.8733 - val_loss: 0.6866 - val_accuracy: 0.8617\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4947 - accuracy: 0.8734 - val_loss: 0.6863 - val_accuracy: 0.8617\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4943 - accuracy: 0.8734 - val_loss: 0.6861 - val_accuracy: 0.8618\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4940 - accuracy: 0.8735 - val_loss: 0.6856 - val_accuracy: 0.8621\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4936 - accuracy: 0.8736 - val_loss: 0.6853 - val_accuracy: 0.8624\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4932 - accuracy: 0.8736 - val_loss: 0.6850 - val_accuracy: 0.8624\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4928 - accuracy: 0.8737 - val_loss: 0.6847 - val_accuracy: 0.8625\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4925 - accuracy: 0.8738 - val_loss: 0.6844 - val_accuracy: 0.8625\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4921 - accuracy: 0.8739 - val_loss: 0.6842 - val_accuracy: 0.8625\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4918 - accuracy: 0.8740 - val_loss: 0.6835 - val_accuracy: 0.8625\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4915 - accuracy: 0.8740 - val_loss: 0.6834 - val_accuracy: 0.8626\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4911 - accuracy: 0.8741 - val_loss: 0.6834 - val_accuracy: 0.8628\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4909 - accuracy: 0.8742 - val_loss: 0.6826 - val_accuracy: 0.8625\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4905 - accuracy: 0.8742 - val_loss: 0.6823 - val_accuracy: 0.8625\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4901 - accuracy: 0.8743 - val_loss: 0.6824 - val_accuracy: 0.8631\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4897 - accuracy: 0.8744 - val_loss: 0.6818 - val_accuracy: 0.8631\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4893 - accuracy: 0.8745 - val_loss: 0.6811 - val_accuracy: 0.8627\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4890 - accuracy: 0.8746 - val_loss: 0.6808 - val_accuracy: 0.8628\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4886 - accuracy: 0.8746 - val_loss: 0.6809 - val_accuracy: 0.8631\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4883 - accuracy: 0.8747 - val_loss: 0.6805 - val_accuracy: 0.8631\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4878 - accuracy: 0.8748 - val_loss: 0.6800 - val_accuracy: 0.8628\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4876 - accuracy: 0.8749 - val_loss: 0.6799 - val_accuracy: 0.8631\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4872 - accuracy: 0.8751 - val_loss: 0.6799 - val_accuracy: 0.8636\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4870 - accuracy: 0.8750 - val_loss: 0.6792 - val_accuracy: 0.8632\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4864 - accuracy: 0.8752 - val_loss: 0.6786 - val_accuracy: 0.8632\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4861 - accuracy: 0.8753 - val_loss: 0.6784 - val_accuracy: 0.8637\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4857 - accuracy: 0.8755 - val_loss: 0.6782 - val_accuracy: 0.8641\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4854 - accuracy: 0.8756 - val_loss: 0.6777 - val_accuracy: 0.8640\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4850 - accuracy: 0.8757 - val_loss: 0.6776 - val_accuracy: 0.8642\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4846 - accuracy: 0.8759 - val_loss: 0.6775 - val_accuracy: 0.8643\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4843 - accuracy: 0.8759 - val_loss: 0.6770 - val_accuracy: 0.8641\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4839 - accuracy: 0.8760 - val_loss: 0.6767 - val_accuracy: 0.8643\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4835 - accuracy: 0.8761 - val_loss: 0.6766 - val_accuracy: 0.8644\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4831 - accuracy: 0.8762 - val_loss: 0.6761 - val_accuracy: 0.8648\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4827 - accuracy: 0.8764 - val_loss: 0.6759 - val_accuracy: 0.8648\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4823 - accuracy: 0.8766 - val_loss: 0.6760 - val_accuracy: 0.8648\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4820 - accuracy: 0.8765 - val_loss: 0.6757 - val_accuracy: 0.8652\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4816 - accuracy: 0.8766 - val_loss: 0.6753 - val_accuracy: 0.8651\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4812 - accuracy: 0.8767 - val_loss: 0.6751 - val_accuracy: 0.8651\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4808 - accuracy: 0.8769 - val_loss: 0.6748 - val_accuracy: 0.8652\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4805 - accuracy: 0.8771 - val_loss: 0.6743 - val_accuracy: 0.8653\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4801 - accuracy: 0.8772 - val_loss: 0.6741 - val_accuracy: 0.8655\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4797 - accuracy: 0.8772 - val_loss: 0.6735 - val_accuracy: 0.8656\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4794 - accuracy: 0.8773 - val_loss: 0.6733 - val_accuracy: 0.8657\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4790 - accuracy: 0.8774 - val_loss: 0.6734 - val_accuracy: 0.8659\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4788 - accuracy: 0.8773 - val_loss: 0.6725 - val_accuracy: 0.8658\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4783 - accuracy: 0.8776 - val_loss: 0.6722 - val_accuracy: 0.8659\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4780 - accuracy: 0.8777 - val_loss: 0.6724 - val_accuracy: 0.8661\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4776 - accuracy: 0.8777 - val_loss: 0.6719 - val_accuracy: 0.8662\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4771 - accuracy: 0.8778 - val_loss: 0.6713 - val_accuracy: 0.8663\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4768 - accuracy: 0.8779 - val_loss: 0.6713 - val_accuracy: 0.8664\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4764 - accuracy: 0.8780 - val_loss: 0.6713 - val_accuracy: 0.8665\n"
     ]
    }
   ],
   "source": [
    "# second train\n",
    "keras_model_cce2 = keras_dense_model()\n",
    "\n",
    "keras_model_cce2.summary()\n",
    "\n",
    "keras_model_cce2.compile(\n",
    "    optimizer = optimizers.Adam(0.001),\n",
    "    loss = 'sparse_categorical_crossentropy', \n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "history_train_cce2 = keras_model_cce2.fit(\n",
    "    Xtrain, Ytrain, \n",
    "    validation_data=(Xtest, Ytest),\n",
    "    epochs = 1000, batch_size = Xtrain.shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yw2OFZu4gpCJ",
    "outputId": "787ca700-5a1c-4f86-ad6c-252c7d498d96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 154.1603 - accuracy: 0.0692 - val_loss: 117.7598 - val_accuracy: 0.0890\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 116.3793 - accuracy: 0.0954 - val_loss: 88.0750 - val_accuracy: 0.1233\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 87.7091 - accuracy: 0.1283 - val_loss: 67.3380 - val_accuracy: 0.1629\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 67.6449 - accuracy: 0.1623 - val_loss: 53.1672 - val_accuracy: 0.1925\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 53.9600 - accuracy: 0.1918 - val_loss: 42.9910 - val_accuracy: 0.2252\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 44.0775 - accuracy: 0.2207 - val_loss: 35.1821 - val_accuracy: 0.2553\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 36.3775 - accuracy: 0.2489 - val_loss: 28.8646 - val_accuracy: 0.2898\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 30.0348 - accuracy: 0.2797 - val_loss: 23.7270 - val_accuracy: 0.3164\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 24.8378 - accuracy: 0.3091 - val_loss: 19.6778 - val_accuracy: 0.3475\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 20.6817 - accuracy: 0.3376 - val_loss: 16.5891 - val_accuracy: 0.3681\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 17.4514 - accuracy: 0.3606 - val_loss: 14.2158 - val_accuracy: 0.3830\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 14.9088 - accuracy: 0.3796 - val_loss: 12.2674 - val_accuracy: 0.4118\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 12.8323 - accuracy: 0.4054 - val_loss: 10.6186 - val_accuracy: 0.4286\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 11.1047 - accuracy: 0.4260 - val_loss: 9.2261 - val_accuracy: 0.4392\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 9.6807 - accuracy: 0.4380 - val_loss: 8.0383 - val_accuracy: 0.4447\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 8.4755 - accuracy: 0.4455 - val_loss: 6.9775 - val_accuracy: 0.4489\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 7.4034 - accuracy: 0.4473 - val_loss: 6.0268 - val_accuracy: 0.4469\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.4424 - accuracy: 0.4451 - val_loss: 5.1994 - val_accuracy: 0.4404\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.6014 - accuracy: 0.4394 - val_loss: 4.5125 - val_accuracy: 0.4292\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.8859 - accuracy: 0.4300 - val_loss: 3.9604 - val_accuracy: 0.4250\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 4.3010 - accuracy: 0.4313 - val_loss: 3.5245 - val_accuracy: 0.4089\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8381 - accuracy: 0.4175 - val_loss: 3.1946 - val_accuracy: 0.3927\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 3.4706 - accuracy: 0.4022 - val_loss: 2.9407 - val_accuracy: 0.3837\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.1832 - accuracy: 0.3892 - val_loss: 2.7465 - val_accuracy: 0.3682\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.9604 - accuracy: 0.3738 - val_loss: 2.6014 - val_accuracy: 0.3537\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.7856 - accuracy: 0.3589 - val_loss: 2.4886 - val_accuracy: 0.3396\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.6486 - accuracy: 0.3456 - val_loss: 2.4038 - val_accuracy: 0.3260\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.5423 - accuracy: 0.3329 - val_loss: 2.3376 - val_accuracy: 0.3136\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.4595 - accuracy: 0.3219 - val_loss: 2.2866 - val_accuracy: 0.3040\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.3931 - accuracy: 0.3119 - val_loss: 2.2473 - val_accuracy: 0.2959\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.3384 - accuracy: 0.3031 - val_loss: 2.2154 - val_accuracy: 0.2860\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.2941 - accuracy: 0.2960 - val_loss: 2.1895 - val_accuracy: 0.2813\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.2584 - accuracy: 0.2894 - val_loss: 2.1694 - val_accuracy: 0.2759\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 2.2287 - accuracy: 0.2840 - val_loss: 2.1524 - val_accuracy: 0.2717\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.2040 - accuracy: 0.2797 - val_loss: 2.1385 - val_accuracy: 0.2672\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1831 - accuracy: 0.2765 - val_loss: 2.1272 - val_accuracy: 0.2640\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.1649 - accuracy: 0.2733 - val_loss: 2.1167 - val_accuracy: 0.2620\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.1489 - accuracy: 0.2716 - val_loss: 2.1074 - val_accuracy: 0.2642\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.1346 - accuracy: 0.2741 - val_loss: 2.0991 - val_accuracy: 0.2757\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 2.1219 - accuracy: 0.2857 - val_loss: 2.0911 - val_accuracy: 0.2749\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.1106 - accuracy: 0.2843 - val_loss: 2.0834 - val_accuracy: 0.2750\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.1002 - accuracy: 0.2836 - val_loss: 2.0765 - val_accuracy: 0.2741\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 2.0909 - accuracy: 0.2830 - val_loss: 2.0700 - val_accuracy: 0.2742\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.0820 - accuracy: 0.2832 - val_loss: 2.0640 - val_accuracy: 0.2744\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0736 - accuracy: 0.2830 - val_loss: 2.0583 - val_accuracy: 0.2745\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0655 - accuracy: 0.2831 - val_loss: 2.0526 - val_accuracy: 0.2752\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 2.0577 - accuracy: 0.2839 - val_loss: 2.0470 - val_accuracy: 0.2762\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0502 - accuracy: 0.2849 - val_loss: 2.0416 - val_accuracy: 0.2768\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 2.0426 - accuracy: 0.2860 - val_loss: 2.0364 - val_accuracy: 0.2774\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0353 - accuracy: 0.2876 - val_loss: 2.0314 - val_accuracy: 0.2797\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0281 - accuracy: 0.2892 - val_loss: 2.0265 - val_accuracy: 0.2813\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0210 - accuracy: 0.2912 - val_loss: 2.0217 - val_accuracy: 0.2832\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 2.0141 - accuracy: 0.2932 - val_loss: 2.0168 - val_accuracy: 0.2855\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.0072 - accuracy: 0.2955 - val_loss: 2.0116 - val_accuracy: 0.2880\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.0004 - accuracy: 0.2977 - val_loss: 2.0064 - val_accuracy: 0.2900\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9939 - accuracy: 0.2999 - val_loss: 2.0012 - val_accuracy: 0.2924\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9876 - accuracy: 0.3020 - val_loss: 1.9964 - val_accuracy: 0.2940\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.9815 - accuracy: 0.3041 - val_loss: 1.9919 - val_accuracy: 0.2959\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.9754 - accuracy: 0.3066 - val_loss: 1.9873 - val_accuracy: 0.2985\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.9692 - accuracy: 0.3092 - val_loss: 1.9824 - val_accuracy: 0.3002\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9629 - accuracy: 0.3115 - val_loss: 1.9776 - val_accuracy: 0.3023\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.9568 - accuracy: 0.3137 - val_loss: 1.9727 - val_accuracy: 0.3054\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.9507 - accuracy: 0.3158 - val_loss: 1.9677 - val_accuracy: 0.3083\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.9449 - accuracy: 0.3181 - val_loss: 1.9625 - val_accuracy: 0.3110\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.9391 - accuracy: 0.3205 - val_loss: 1.9578 - val_accuracy: 0.3123\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9334 - accuracy: 0.3227 - val_loss: 1.9534 - val_accuracy: 0.3133\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9279 - accuracy: 0.3246 - val_loss: 1.9489 - val_accuracy: 0.3153\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.9225 - accuracy: 0.3270 - val_loss: 1.9444 - val_accuracy: 0.3175\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.9173 - accuracy: 0.3289 - val_loss: 1.9402 - val_accuracy: 0.3194\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.9123 - accuracy: 0.3305 - val_loss: 1.9361 - val_accuracy: 0.3218\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.9072 - accuracy: 0.3325 - val_loss: 1.9322 - val_accuracy: 0.3233\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.9020 - accuracy: 0.3348 - val_loss: 1.9280 - val_accuracy: 0.3303\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8970 - accuracy: 0.3390 - val_loss: 1.9239 - val_accuracy: 0.3367\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.8920 - accuracy: 0.3438 - val_loss: 1.9199 - val_accuracy: 0.3415\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.8870 - accuracy: 0.3477 - val_loss: 1.9157 - val_accuracy: 0.3456\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8823 - accuracy: 0.3507 - val_loss: 1.9114 - val_accuracy: 0.3486\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.8777 - accuracy: 0.3531 - val_loss: 1.9076 - val_accuracy: 0.3512\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.8731 - accuracy: 0.3560 - val_loss: 1.9040 - val_accuracy: 0.3539\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.8685 - accuracy: 0.3583 - val_loss: 1.9006 - val_accuracy: 0.3562\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.8641 - accuracy: 0.3604 - val_loss: 1.8972 - val_accuracy: 0.3589\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.8597 - accuracy: 0.3625 - val_loss: 1.8939 - val_accuracy: 0.3618\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.8551 - accuracy: 0.3647 - val_loss: 1.8908 - val_accuracy: 0.3644\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.8506 - accuracy: 0.3670 - val_loss: 1.8875 - val_accuracy: 0.3671\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8462 - accuracy: 0.3690 - val_loss: 1.8840 - val_accuracy: 0.3690\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.8417 - accuracy: 0.3713 - val_loss: 1.8807 - val_accuracy: 0.3705\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.8372 - accuracy: 0.3733 - val_loss: 1.8775 - val_accuracy: 0.3730\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8328 - accuracy: 0.3753 - val_loss: 1.8745 - val_accuracy: 0.3743\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.8284 - accuracy: 0.3769 - val_loss: 1.8715 - val_accuracy: 0.3751\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.8240 - accuracy: 0.3786 - val_loss: 1.8682 - val_accuracy: 0.3761\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8197 - accuracy: 0.3798 - val_loss: 1.8647 - val_accuracy: 0.3776\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.8152 - accuracy: 0.3810 - val_loss: 1.8610 - val_accuracy: 0.3787\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.8108 - accuracy: 0.3821 - val_loss: 1.8574 - val_accuracy: 0.3793\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.8065 - accuracy: 0.3830 - val_loss: 1.8540 - val_accuracy: 0.3805\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.8023 - accuracy: 0.3843 - val_loss: 1.8509 - val_accuracy: 0.3819\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.7982 - accuracy: 0.3852 - val_loss: 1.8478 - val_accuracy: 0.3822\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7941 - accuracy: 0.3863 - val_loss: 1.8448 - val_accuracy: 0.3827\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.7901 - accuracy: 0.3874 - val_loss: 1.8418 - val_accuracy: 0.3840\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.7861 - accuracy: 0.3887 - val_loss: 1.8387 - val_accuracy: 0.3847\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.7821 - accuracy: 0.3902 - val_loss: 1.8359 - val_accuracy: 0.3857\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.7781 - accuracy: 0.3916 - val_loss: 1.8329 - val_accuracy: 0.3873\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7743 - accuracy: 0.3927 - val_loss: 1.8298 - val_accuracy: 0.3884\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.7706 - accuracy: 0.3937 - val_loss: 1.8267 - val_accuracy: 0.3897\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7670 - accuracy: 0.3950 - val_loss: 1.8237 - val_accuracy: 0.3911\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7634 - accuracy: 0.3963 - val_loss: 1.8207 - val_accuracy: 0.3919\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.7598 - accuracy: 0.3977 - val_loss: 1.8177 - val_accuracy: 0.3938\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7563 - accuracy: 0.3986 - val_loss: 1.8145 - val_accuracy: 0.3948\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7529 - accuracy: 0.3996 - val_loss: 1.8112 - val_accuracy: 0.3959\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.7495 - accuracy: 0.4007 - val_loss: 1.8082 - val_accuracy: 0.3957\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.7461 - accuracy: 0.4015 - val_loss: 1.8052 - val_accuracy: 0.3974\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7428 - accuracy: 0.4025 - val_loss: 1.8022 - val_accuracy: 0.3978\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.7395 - accuracy: 0.4035 - val_loss: 1.7992 - val_accuracy: 0.3993\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7362 - accuracy: 0.4043 - val_loss: 1.7962 - val_accuracy: 0.4004\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.7331 - accuracy: 0.4053 - val_loss: 1.7932 - val_accuracy: 0.4013\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7299 - accuracy: 0.4063 - val_loss: 1.7901 - val_accuracy: 0.4027\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.7267 - accuracy: 0.4073 - val_loss: 1.7871 - val_accuracy: 0.4037\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.7234 - accuracy: 0.4082 - val_loss: 1.7840 - val_accuracy: 0.4058\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.7202 - accuracy: 0.4095 - val_loss: 1.7808 - val_accuracy: 0.4071\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.7171 - accuracy: 0.4104 - val_loss: 1.7778 - val_accuracy: 0.4078\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.7141 - accuracy: 0.4118 - val_loss: 1.7749 - val_accuracy: 0.4088\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.7109 - accuracy: 0.4130 - val_loss: 1.7720 - val_accuracy: 0.4100\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.7077 - accuracy: 0.4143 - val_loss: 1.7693 - val_accuracy: 0.4058\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.7045 - accuracy: 0.4131 - val_loss: 1.7666 - val_accuracy: 0.4067\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.7014 - accuracy: 0.4142 - val_loss: 1.7640 - val_accuracy: 0.4076\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.6983 - accuracy: 0.4150 - val_loss: 1.7610 - val_accuracy: 0.4089\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6952 - accuracy: 0.4163 - val_loss: 1.7581 - val_accuracy: 0.4103\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.6921 - accuracy: 0.4176 - val_loss: 1.7552 - val_accuracy: 0.4121\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.6890 - accuracy: 0.4188 - val_loss: 1.7523 - val_accuracy: 0.4130\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.6859 - accuracy: 0.4198 - val_loss: 1.7494 - val_accuracy: 0.4144\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6828 - accuracy: 0.4212 - val_loss: 1.7467 - val_accuracy: 0.4154\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.6797 - accuracy: 0.4222 - val_loss: 1.7442 - val_accuracy: 0.4162\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6766 - accuracy: 0.4232 - val_loss: 1.7416 - val_accuracy: 0.4174\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.6733 - accuracy: 0.4241 - val_loss: 1.7391 - val_accuracy: 0.4184\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6702 - accuracy: 0.4247 - val_loss: 1.7362 - val_accuracy: 0.4196\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.6670 - accuracy: 0.4258 - val_loss: 1.7334 - val_accuracy: 0.4201\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6638 - accuracy: 0.4267 - val_loss: 1.7307 - val_accuracy: 0.4216\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6607 - accuracy: 0.4275 - val_loss: 1.7283 - val_accuracy: 0.4220\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.6576 - accuracy: 0.4286 - val_loss: 1.7260 - val_accuracy: 0.4230\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.6544 - accuracy: 0.4300 - val_loss: 1.7234 - val_accuracy: 0.4249\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.6512 - accuracy: 0.4313 - val_loss: 1.7206 - val_accuracy: 0.4268\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.6480 - accuracy: 0.4327 - val_loss: 1.7175 - val_accuracy: 0.4291\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.6448 - accuracy: 0.4342 - val_loss: 1.7147 - val_accuracy: 0.4312\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.6416 - accuracy: 0.4360 - val_loss: 1.7120 - val_accuracy: 0.4334\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.6383 - accuracy: 0.4378 - val_loss: 1.7091 - val_accuracy: 0.4354\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.6349 - accuracy: 0.4393 - val_loss: 1.7061 - val_accuracy: 0.4364\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.6315 - accuracy: 0.4405 - val_loss: 1.7029 - val_accuracy: 0.4379\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.6280 - accuracy: 0.4421 - val_loss: 1.6989 - val_accuracy: 0.4403\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.6243 - accuracy: 0.4437 - val_loss: 1.6952 - val_accuracy: 0.4422\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.6207 - accuracy: 0.4451 - val_loss: 1.6920 - val_accuracy: 0.4435\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.6171 - accuracy: 0.4466 - val_loss: 1.6889 - val_accuracy: 0.4456\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.6134 - accuracy: 0.4484 - val_loss: 1.6847 - val_accuracy: 0.4475\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.6095 - accuracy: 0.4501 - val_loss: 1.6812 - val_accuracy: 0.4488\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.6056 - accuracy: 0.4519 - val_loss: 1.6774 - val_accuracy: 0.4512\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.6013 - accuracy: 0.4538 - val_loss: 1.6728 - val_accuracy: 0.4534\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.5967 - accuracy: 0.4563 - val_loss: 1.6690 - val_accuracy: 0.4556\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5922 - accuracy: 0.4588 - val_loss: 1.6650 - val_accuracy: 0.4590\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5872 - accuracy: 0.4621 - val_loss: 1.6611 - val_accuracy: 0.4627\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.5816 - accuracy: 0.4655 - val_loss: 1.6570 - val_accuracy: 0.4657\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5758 - accuracy: 0.4692 - val_loss: 1.6531 - val_accuracy: 0.4685\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.5702 - accuracy: 0.4728 - val_loss: 1.6486 - val_accuracy: 0.4717\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.5643 - accuracy: 0.4767 - val_loss: 1.6428 - val_accuracy: 0.4755\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5581 - accuracy: 0.4798 - val_loss: 1.6353 - val_accuracy: 0.4788\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.5513 - accuracy: 0.4830 - val_loss: 1.6282 - val_accuracy: 0.4802\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.5440 - accuracy: 0.4854 - val_loss: 1.6210 - val_accuracy: 0.4827\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.5364 - accuracy: 0.4881 - val_loss: 1.6135 - val_accuracy: 0.4848\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5290 - accuracy: 0.4906 - val_loss: 1.6061 - val_accuracy: 0.4876\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5217 - accuracy: 0.4931 - val_loss: 1.5993 - val_accuracy: 0.4905\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.5143 - accuracy: 0.4965 - val_loss: 1.5930 - val_accuracy: 0.4941\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.5071 - accuracy: 0.4995 - val_loss: 1.5861 - val_accuracy: 0.4975\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.5001 - accuracy: 0.5026 - val_loss: 1.5799 - val_accuracy: 0.5004\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.4933 - accuracy: 0.5061 - val_loss: 1.5740 - val_accuracy: 0.5028\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4862 - accuracy: 0.5090 - val_loss: 1.5675 - val_accuracy: 0.5058\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4793 - accuracy: 0.5113 - val_loss: 1.5598 - val_accuracy: 0.5083\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4729 - accuracy: 0.5134 - val_loss: 1.5529 - val_accuracy: 0.5097\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4667 - accuracy: 0.5148 - val_loss: 1.5465 - val_accuracy: 0.5115\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4608 - accuracy: 0.5164 - val_loss: 1.5407 - val_accuracy: 0.5127\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4550 - accuracy: 0.5181 - val_loss: 1.5350 - val_accuracy: 0.5143\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4491 - accuracy: 0.5198 - val_loss: 1.5301 - val_accuracy: 0.5162\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4434 - accuracy: 0.5218 - val_loss: 1.5251 - val_accuracy: 0.5174\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4380 - accuracy: 0.5235 - val_loss: 1.5203 - val_accuracy: 0.5185\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4331 - accuracy: 0.5251 - val_loss: 1.5156 - val_accuracy: 0.5198\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.4281 - accuracy: 0.5268 - val_loss: 1.5106 - val_accuracy: 0.5204\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4232 - accuracy: 0.5286 - val_loss: 1.5063 - val_accuracy: 0.5216\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.4183 - accuracy: 0.5302 - val_loss: 1.5020 - val_accuracy: 0.5229\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.4137 - accuracy: 0.5317 - val_loss: 1.4977 - val_accuracy: 0.5246\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4092 - accuracy: 0.5329 - val_loss: 1.4932 - val_accuracy: 0.5262\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.4049 - accuracy: 0.5343 - val_loss: 1.4893 - val_accuracy: 0.5279\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4008 - accuracy: 0.5355 - val_loss: 1.4856 - val_accuracy: 0.5291\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3968 - accuracy: 0.5372 - val_loss: 1.4817 - val_accuracy: 0.5303\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3928 - accuracy: 0.5390 - val_loss: 1.4780 - val_accuracy: 0.5319\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3888 - accuracy: 0.5406 - val_loss: 1.4749 - val_accuracy: 0.5334\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.3849 - accuracy: 0.5422 - val_loss: 1.4717 - val_accuracy: 0.5348\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3813 - accuracy: 0.5433 - val_loss: 1.4684 - val_accuracy: 0.5360\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3775 - accuracy: 0.5446 - val_loss: 1.4651 - val_accuracy: 0.5379\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3736 - accuracy: 0.5458 - val_loss: 1.4623 - val_accuracy: 0.5398\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3696 - accuracy: 0.5471 - val_loss: 1.4591 - val_accuracy: 0.5411\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3656 - accuracy: 0.5481 - val_loss: 1.4557 - val_accuracy: 0.5427\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3617 - accuracy: 0.5490 - val_loss: 1.4520 - val_accuracy: 0.5436\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3578 - accuracy: 0.5495 - val_loss: 1.4482 - val_accuracy: 0.5434\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.3539 - accuracy: 0.5502 - val_loss: 1.4443 - val_accuracy: 0.5430\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3498 - accuracy: 0.5512 - val_loss: 1.4406 - val_accuracy: 0.5426\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.3457 - accuracy: 0.5519 - val_loss: 1.4371 - val_accuracy: 0.5426\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.3418 - accuracy: 0.5528 - val_loss: 1.4337 - val_accuracy: 0.5429\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3378 - accuracy: 0.5539 - val_loss: 1.4301 - val_accuracy: 0.5438\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3338 - accuracy: 0.5553 - val_loss: 1.4257 - val_accuracy: 0.5447\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3299 - accuracy: 0.5575 - val_loss: 1.4210 - val_accuracy: 0.5467\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3259 - accuracy: 0.5600 - val_loss: 1.4165 - val_accuracy: 0.5490\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.3219 - accuracy: 0.5628 - val_loss: 1.4121 - val_accuracy: 0.5510\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.3179 - accuracy: 0.5645 - val_loss: 1.4078 - val_accuracy: 0.5540\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3140 - accuracy: 0.5659 - val_loss: 1.4030 - val_accuracy: 0.5554\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.3102 - accuracy: 0.5676 - val_loss: 1.3984 - val_accuracy: 0.5565\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3063 - accuracy: 0.5692 - val_loss: 1.3942 - val_accuracy: 0.5561\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.3024 - accuracy: 0.5707 - val_loss: 1.3903 - val_accuracy: 0.5587\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2985 - accuracy: 0.5720 - val_loss: 1.3863 - val_accuracy: 0.5588\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2946 - accuracy: 0.5738 - val_loss: 1.3824 - val_accuracy: 0.5623\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2907 - accuracy: 0.5752 - val_loss: 1.3782 - val_accuracy: 0.5625\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2868 - accuracy: 0.5768 - val_loss: 1.3745 - val_accuracy: 0.5639\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2830 - accuracy: 0.5780 - val_loss: 1.3712 - val_accuracy: 0.5657\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2791 - accuracy: 0.5799 - val_loss: 1.3681 - val_accuracy: 0.5668\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.2753 - accuracy: 0.5815 - val_loss: 1.3653 - val_accuracy: 0.5678\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2716 - accuracy: 0.5826 - val_loss: 1.3624 - val_accuracy: 0.5687\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2680 - accuracy: 0.5839 - val_loss: 1.3597 - val_accuracy: 0.5708\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.2644 - accuracy: 0.5853 - val_loss: 1.3571 - val_accuracy: 0.5721\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2609 - accuracy: 0.5867 - val_loss: 1.3547 - val_accuracy: 0.5730\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2576 - accuracy: 0.5883 - val_loss: 1.3522 - val_accuracy: 0.5754\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2542 - accuracy: 0.5900 - val_loss: 1.3497 - val_accuracy: 0.5774\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2509 - accuracy: 0.5914 - val_loss: 1.3474 - val_accuracy: 0.5790\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.2477 - accuracy: 0.5931 - val_loss: 1.3449 - val_accuracy: 0.5803\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.2446 - accuracy: 0.5944 - val_loss: 1.3423 - val_accuracy: 0.5814\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2415 - accuracy: 0.5959 - val_loss: 1.3399 - val_accuracy: 0.5833\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2385 - accuracy: 0.5972 - val_loss: 1.3378 - val_accuracy: 0.5840\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2356 - accuracy: 0.5985 - val_loss: 1.3358 - val_accuracy: 0.5851\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2327 - accuracy: 0.5994 - val_loss: 1.3338 - val_accuracy: 0.5865\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.2300 - accuracy: 0.6003 - val_loss: 1.3315 - val_accuracy: 0.5873\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.2271 - accuracy: 0.6016 - val_loss: 1.3291 - val_accuracy: 0.5889\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.2242 - accuracy: 0.6025 - val_loss: 1.3271 - val_accuracy: 0.5906\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2214 - accuracy: 0.6037 - val_loss: 1.3254 - val_accuracy: 0.5920\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2186 - accuracy: 0.6050 - val_loss: 1.3237 - val_accuracy: 0.5928\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.2158 - accuracy: 0.6065 - val_loss: 1.3218 - val_accuracy: 0.5936\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2129 - accuracy: 0.6079 - val_loss: 1.3200 - val_accuracy: 0.5947\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.2099 - accuracy: 0.6092 - val_loss: 1.3184 - val_accuracy: 0.5954\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.2071 - accuracy: 0.6100 - val_loss: 1.3169 - val_accuracy: 0.5958\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2044 - accuracy: 0.6112 - val_loss: 1.3149 - val_accuracy: 0.5980\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.2017 - accuracy: 0.6125 - val_loss: 1.3131 - val_accuracy: 0.5993\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1991 - accuracy: 0.6135 - val_loss: 1.3115 - val_accuracy: 0.6002\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1966 - accuracy: 0.6143 - val_loss: 1.3100 - val_accuracy: 0.6015\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1940 - accuracy: 0.6151 - val_loss: 1.3082 - val_accuracy: 0.6016\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1914 - accuracy: 0.6161 - val_loss: 1.3062 - val_accuracy: 0.6027\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1889 - accuracy: 0.6171 - val_loss: 1.3043 - val_accuracy: 0.6038\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1864 - accuracy: 0.6183 - val_loss: 1.3025 - val_accuracy: 0.6055\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1840 - accuracy: 0.6195 - val_loss: 1.3006 - val_accuracy: 0.6066\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1816 - accuracy: 0.6207 - val_loss: 1.2986 - val_accuracy: 0.6075\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.1792 - accuracy: 0.6220 - val_loss: 1.2967 - val_accuracy: 0.6080\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1768 - accuracy: 0.6230 - val_loss: 1.2948 - val_accuracy: 0.6091\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1744 - accuracy: 0.6241 - val_loss: 1.2928 - val_accuracy: 0.6099\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1721 - accuracy: 0.6247 - val_loss: 1.2906 - val_accuracy: 0.6112\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1697 - accuracy: 0.6256 - val_loss: 1.2884 - val_accuracy: 0.6118\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1673 - accuracy: 0.6263 - val_loss: 1.2863 - val_accuracy: 0.6129\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1650 - accuracy: 0.6269 - val_loss: 1.2842 - val_accuracy: 0.6143\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1626 - accuracy: 0.6278 - val_loss: 1.2822 - val_accuracy: 0.6152\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1603 - accuracy: 0.6286 - val_loss: 1.2799 - val_accuracy: 0.6164\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1580 - accuracy: 0.6292 - val_loss: 1.2777 - val_accuracy: 0.6168\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1558 - accuracy: 0.6300 - val_loss: 1.2759 - val_accuracy: 0.6176\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1536 - accuracy: 0.6306 - val_loss: 1.2740 - val_accuracy: 0.6182\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1514 - accuracy: 0.6313 - val_loss: 1.2719 - val_accuracy: 0.6192\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1493 - accuracy: 0.6320 - val_loss: 1.2698 - val_accuracy: 0.6202\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.1471 - accuracy: 0.6330 - val_loss: 1.2679 - val_accuracy: 0.6211\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1450 - accuracy: 0.6339 - val_loss: 1.2662 - val_accuracy: 0.6220\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.1428 - accuracy: 0.6348 - val_loss: 1.2644 - val_accuracy: 0.6228\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1407 - accuracy: 0.6358 - val_loss: 1.2626 - val_accuracy: 0.6233\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1385 - accuracy: 0.6367 - val_loss: 1.2608 - val_accuracy: 0.6241\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1364 - accuracy: 0.6374 - val_loss: 1.2591 - val_accuracy: 0.6248\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1344 - accuracy: 0.6381 - val_loss: 1.2574 - val_accuracy: 0.6256\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1323 - accuracy: 0.6387 - val_loss: 1.2554 - val_accuracy: 0.6264\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1302 - accuracy: 0.6395 - val_loss: 1.2535 - val_accuracy: 0.6276\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1281 - accuracy: 0.6401 - val_loss: 1.2517 - val_accuracy: 0.6283\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1260 - accuracy: 0.6411 - val_loss: 1.2500 - val_accuracy: 0.6294\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1239 - accuracy: 0.6421 - val_loss: 1.2482 - val_accuracy: 0.6305\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1219 - accuracy: 0.6427 - val_loss: 1.2464 - val_accuracy: 0.6310\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1198 - accuracy: 0.6437 - val_loss: 1.2447 - val_accuracy: 0.6321\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1178 - accuracy: 0.6447 - val_loss: 1.2431 - val_accuracy: 0.6329\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.1158 - accuracy: 0.6457 - val_loss: 1.2414 - val_accuracy: 0.6339\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1138 - accuracy: 0.6466 - val_loss: 1.2397 - val_accuracy: 0.6353\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.1117 - accuracy: 0.6477 - val_loss: 1.2380 - val_accuracy: 0.6363\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.1097 - accuracy: 0.6486 - val_loss: 1.2363 - val_accuracy: 0.6372\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1076 - accuracy: 0.6493 - val_loss: 1.2346 - val_accuracy: 0.6376\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1056 - accuracy: 0.6499 - val_loss: 1.2328 - val_accuracy: 0.6393\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1036 - accuracy: 0.6507 - val_loss: 1.2310 - val_accuracy: 0.6402\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.1016 - accuracy: 0.6515 - val_loss: 1.2291 - val_accuracy: 0.6414\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0996 - accuracy: 0.6525 - val_loss: 1.2274 - val_accuracy: 0.6428\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0976 - accuracy: 0.6532 - val_loss: 1.2256 - val_accuracy: 0.6427\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0955 - accuracy: 0.6539 - val_loss: 1.2237 - val_accuracy: 0.6431\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0935 - accuracy: 0.6547 - val_loss: 1.2218 - val_accuracy: 0.6436\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0915 - accuracy: 0.6556 - val_loss: 1.2199 - val_accuracy: 0.6440\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0895 - accuracy: 0.6565 - val_loss: 1.2181 - val_accuracy: 0.6454\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0875 - accuracy: 0.6573 - val_loss: 1.2164 - val_accuracy: 0.6462\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0855 - accuracy: 0.6583 - val_loss: 1.2144 - val_accuracy: 0.6472\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0835 - accuracy: 0.6592 - val_loss: 1.2122 - val_accuracy: 0.6483\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0815 - accuracy: 0.6600 - val_loss: 1.2101 - val_accuracy: 0.6492\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0795 - accuracy: 0.6610 - val_loss: 1.2082 - val_accuracy: 0.6495\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0775 - accuracy: 0.6618 - val_loss: 1.2063 - val_accuracy: 0.6501\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0755 - accuracy: 0.6626 - val_loss: 1.2045 - val_accuracy: 0.6516\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0735 - accuracy: 0.6637 - val_loss: 1.2027 - val_accuracy: 0.6528\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0715 - accuracy: 0.6648 - val_loss: 1.2010 - val_accuracy: 0.6535\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0695 - accuracy: 0.6657 - val_loss: 1.1994 - val_accuracy: 0.6549\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0676 - accuracy: 0.6668 - val_loss: 1.1979 - val_accuracy: 0.6559\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0656 - accuracy: 0.6676 - val_loss: 1.1964 - val_accuracy: 0.6564\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0637 - accuracy: 0.6684 - val_loss: 1.1947 - val_accuracy: 0.6575\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0617 - accuracy: 0.6693 - val_loss: 1.1930 - val_accuracy: 0.6585\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0598 - accuracy: 0.6699 - val_loss: 1.1914 - val_accuracy: 0.6591\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0578 - accuracy: 0.6705 - val_loss: 1.1898 - val_accuracy: 0.6599\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0559 - accuracy: 0.6711 - val_loss: 1.1880 - val_accuracy: 0.6605\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0540 - accuracy: 0.6719 - val_loss: 1.1862 - val_accuracy: 0.6610\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0521 - accuracy: 0.6727 - val_loss: 1.1846 - val_accuracy: 0.6622\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0503 - accuracy: 0.6733 - val_loss: 1.1831 - val_accuracy: 0.6626\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0484 - accuracy: 0.6742 - val_loss: 1.1816 - val_accuracy: 0.6633\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0466 - accuracy: 0.6752 - val_loss: 1.1801 - val_accuracy: 0.6638\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0447 - accuracy: 0.6759 - val_loss: 1.1785 - val_accuracy: 0.6645\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0429 - accuracy: 0.6766 - val_loss: 1.1768 - val_accuracy: 0.6653\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0411 - accuracy: 0.6774 - val_loss: 1.1751 - val_accuracy: 0.6667\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0393 - accuracy: 0.6781 - val_loss: 1.1733 - val_accuracy: 0.6672\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0375 - accuracy: 0.6788 - val_loss: 1.1714 - val_accuracy: 0.6685\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0357 - accuracy: 0.6795 - val_loss: 1.1697 - val_accuracy: 0.6694\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0339 - accuracy: 0.6801 - val_loss: 1.1681 - val_accuracy: 0.6701\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0322 - accuracy: 0.6807 - val_loss: 1.1665 - val_accuracy: 0.6710\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0305 - accuracy: 0.6814 - val_loss: 1.1649 - val_accuracy: 0.6715\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0287 - accuracy: 0.6823 - val_loss: 1.1633 - val_accuracy: 0.6721\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0269 - accuracy: 0.6831 - val_loss: 1.1617 - val_accuracy: 0.6731\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0252 - accuracy: 0.6837 - val_loss: 1.1602 - val_accuracy: 0.6740\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0234 - accuracy: 0.6843 - val_loss: 1.1586 - val_accuracy: 0.6749\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0215 - accuracy: 0.6849 - val_loss: 1.1570 - val_accuracy: 0.6759\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0197 - accuracy: 0.6858 - val_loss: 1.1551 - val_accuracy: 0.6772\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0178 - accuracy: 0.6868 - val_loss: 1.1532 - val_accuracy: 0.6786\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0160 - accuracy: 0.6879 - val_loss: 1.1514 - val_accuracy: 0.6785\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0143 - accuracy: 0.6887 - val_loss: 1.1496 - val_accuracy: 0.6797\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0124 - accuracy: 0.6896 - val_loss: 1.1478 - val_accuracy: 0.6798\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0107 - accuracy: 0.6903 - val_loss: 1.1460 - val_accuracy: 0.6807\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0089 - accuracy: 0.6913 - val_loss: 1.1441 - val_accuracy: 0.6821\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0071 - accuracy: 0.6921 - val_loss: 1.1424 - val_accuracy: 0.6827\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0054 - accuracy: 0.6926 - val_loss: 1.1408 - val_accuracy: 0.6833\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0038 - accuracy: 0.6931 - val_loss: 1.1391 - val_accuracy: 0.6840\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0021 - accuracy: 0.6935 - val_loss: 1.1375 - val_accuracy: 0.6840\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0005 - accuracy: 0.6941 - val_loss: 1.1358 - val_accuracy: 0.6848\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9988 - accuracy: 0.6947 - val_loss: 1.1340 - val_accuracy: 0.6856\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9971 - accuracy: 0.6951 - val_loss: 1.1323 - val_accuracy: 0.6863\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9954 - accuracy: 0.6960 - val_loss: 1.1305 - val_accuracy: 0.6870\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9937 - accuracy: 0.6967 - val_loss: 1.1287 - val_accuracy: 0.6877\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9920 - accuracy: 0.6971 - val_loss: 1.1269 - val_accuracy: 0.6888\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9903 - accuracy: 0.6979 - val_loss: 1.1253 - val_accuracy: 0.6891\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9886 - accuracy: 0.6985 - val_loss: 1.1237 - val_accuracy: 0.6894\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9869 - accuracy: 0.6991 - val_loss: 1.1220 - val_accuracy: 0.6902\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9852 - accuracy: 0.6995 - val_loss: 1.1203 - val_accuracy: 0.6904\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9835 - accuracy: 0.7002 - val_loss: 1.1187 - val_accuracy: 0.6910\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9818 - accuracy: 0.7009 - val_loss: 1.1172 - val_accuracy: 0.6911\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9801 - accuracy: 0.7013 - val_loss: 1.1156 - val_accuracy: 0.6918\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9785 - accuracy: 0.7018 - val_loss: 1.1139 - val_accuracy: 0.6926\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9769 - accuracy: 0.7023 - val_loss: 1.1123 - val_accuracy: 0.6932\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9752 - accuracy: 0.7031 - val_loss: 1.1107 - val_accuracy: 0.6941\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9736 - accuracy: 0.7036 - val_loss: 1.1090 - val_accuracy: 0.6946\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9720 - accuracy: 0.7041 - val_loss: 1.1074 - val_accuracy: 0.6950\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9704 - accuracy: 0.7046 - val_loss: 1.1059 - val_accuracy: 0.6954\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9688 - accuracy: 0.7051 - val_loss: 1.1043 - val_accuracy: 0.6958\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9672 - accuracy: 0.7056 - val_loss: 1.1027 - val_accuracy: 0.6968\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9656 - accuracy: 0.7062 - val_loss: 1.1011 - val_accuracy: 0.6973\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9641 - accuracy: 0.7066 - val_loss: 1.0996 - val_accuracy: 0.6978\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9626 - accuracy: 0.7071 - val_loss: 1.0980 - val_accuracy: 0.6979\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9610 - accuracy: 0.7075 - val_loss: 1.0966 - val_accuracy: 0.6989\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9595 - accuracy: 0.7079 - val_loss: 1.0951 - val_accuracy: 0.6991\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9580 - accuracy: 0.7084 - val_loss: 1.0936 - val_accuracy: 0.6997\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9565 - accuracy: 0.7088 - val_loss: 1.0921 - val_accuracy: 0.7000\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9550 - accuracy: 0.7091 - val_loss: 1.0906 - val_accuracy: 0.7003\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9536 - accuracy: 0.7094 - val_loss: 1.0892 - val_accuracy: 0.7011\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9522 - accuracy: 0.7099 - val_loss: 1.0878 - val_accuracy: 0.7013\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9507 - accuracy: 0.7102 - val_loss: 1.0864 - val_accuracy: 0.7018\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9493 - accuracy: 0.7104 - val_loss: 1.0849 - val_accuracy: 0.7021\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9479 - accuracy: 0.7110 - val_loss: 1.0834 - val_accuracy: 0.7027\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9465 - accuracy: 0.7114 - val_loss: 1.0820 - val_accuracy: 0.7034\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9451 - accuracy: 0.7120 - val_loss: 1.0806 - val_accuracy: 0.7038\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9437 - accuracy: 0.7125 - val_loss: 1.0793 - val_accuracy: 0.7047\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9423 - accuracy: 0.7129 - val_loss: 1.0781 - val_accuracy: 0.7050\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9409 - accuracy: 0.7135 - val_loss: 1.0770 - val_accuracy: 0.7053\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9396 - accuracy: 0.7139 - val_loss: 1.0757 - val_accuracy: 0.7055\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9382 - accuracy: 0.7144 - val_loss: 1.0743 - val_accuracy: 0.7060\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9369 - accuracy: 0.7148 - val_loss: 1.0729 - val_accuracy: 0.7068\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9356 - accuracy: 0.7152 - val_loss: 1.0714 - val_accuracy: 0.7073\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9342 - accuracy: 0.7155 - val_loss: 1.0699 - val_accuracy: 0.7076\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9329 - accuracy: 0.7161 - val_loss: 1.0683 - val_accuracy: 0.7082\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9316 - accuracy: 0.7163 - val_loss: 1.0668 - val_accuracy: 0.7087\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9302 - accuracy: 0.7169 - val_loss: 1.0653 - val_accuracy: 0.7089\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9289 - accuracy: 0.7175 - val_loss: 1.0638 - val_accuracy: 0.7095\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9275 - accuracy: 0.7179 - val_loss: 1.0622 - val_accuracy: 0.7107\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9262 - accuracy: 0.7183 - val_loss: 1.0607 - val_accuracy: 0.7107\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9249 - accuracy: 0.7187 - val_loss: 1.0591 - val_accuracy: 0.7109\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9235 - accuracy: 0.7191 - val_loss: 1.0576 - val_accuracy: 0.7115\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9222 - accuracy: 0.7194 - val_loss: 1.0561 - val_accuracy: 0.7121\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9208 - accuracy: 0.7199 - val_loss: 1.0547 - val_accuracy: 0.7125\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9195 - accuracy: 0.7204 - val_loss: 1.0534 - val_accuracy: 0.7131\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9181 - accuracy: 0.7208 - val_loss: 1.0521 - val_accuracy: 0.7132\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9168 - accuracy: 0.7211 - val_loss: 1.0506 - val_accuracy: 0.7138\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9155 - accuracy: 0.7213 - val_loss: 1.0492 - val_accuracy: 0.7141\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9142 - accuracy: 0.7218 - val_loss: 1.0477 - val_accuracy: 0.7146\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9129 - accuracy: 0.7224 - val_loss: 1.0463 - val_accuracy: 0.7150\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9116 - accuracy: 0.7227 - val_loss: 1.0449 - val_accuracy: 0.7154\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9102 - accuracy: 0.7232 - val_loss: 1.0435 - val_accuracy: 0.7158\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9088 - accuracy: 0.7235 - val_loss: 1.0422 - val_accuracy: 0.7163\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9074 - accuracy: 0.7240 - val_loss: 1.0409 - val_accuracy: 0.7169\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9061 - accuracy: 0.7244 - val_loss: 1.0395 - val_accuracy: 0.7172\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9048 - accuracy: 0.7248 - val_loss: 1.0381 - val_accuracy: 0.7174\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9034 - accuracy: 0.7253 - val_loss: 1.0368 - val_accuracy: 0.7181\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9021 - accuracy: 0.7257 - val_loss: 1.0355 - val_accuracy: 0.7180\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.9008 - accuracy: 0.7260 - val_loss: 1.0343 - val_accuracy: 0.7183\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8996 - accuracy: 0.7265 - val_loss: 1.0329 - val_accuracy: 0.7189\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8983 - accuracy: 0.7268 - val_loss: 1.0316 - val_accuracy: 0.7193\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8971 - accuracy: 0.7271 - val_loss: 1.0303 - val_accuracy: 0.7194\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8958 - accuracy: 0.7272 - val_loss: 1.0291 - val_accuracy: 0.7193\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8946 - accuracy: 0.7276 - val_loss: 1.0278 - val_accuracy: 0.7197\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8934 - accuracy: 0.7278 - val_loss: 1.0265 - val_accuracy: 0.7198\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8922 - accuracy: 0.7281 - val_loss: 1.0253 - val_accuracy: 0.7206\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8910 - accuracy: 0.7287 - val_loss: 1.0240 - val_accuracy: 0.7216\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8898 - accuracy: 0.7293 - val_loss: 1.0230 - val_accuracy: 0.7212\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8886 - accuracy: 0.7297 - val_loss: 1.0221 - val_accuracy: 0.7215\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8874 - accuracy: 0.7300 - val_loss: 1.0212 - val_accuracy: 0.7216\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8862 - accuracy: 0.7301 - val_loss: 1.0204 - val_accuracy: 0.7215\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8850 - accuracy: 0.7303 - val_loss: 1.0196 - val_accuracy: 0.7214\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8838 - accuracy: 0.7306 - val_loss: 1.0186 - val_accuracy: 0.7216\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8826 - accuracy: 0.7308 - val_loss: 1.0174 - val_accuracy: 0.7219\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8814 - accuracy: 0.7312 - val_loss: 1.0162 - val_accuracy: 0.7224\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8802 - accuracy: 0.7314 - val_loss: 1.0150 - val_accuracy: 0.7230\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8791 - accuracy: 0.7318 - val_loss: 1.0138 - val_accuracy: 0.7234\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8779 - accuracy: 0.7320 - val_loss: 1.0127 - val_accuracy: 0.7235\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8767 - accuracy: 0.7324 - val_loss: 1.0117 - val_accuracy: 0.7236\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8755 - accuracy: 0.7327 - val_loss: 1.0105 - val_accuracy: 0.7235\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8743 - accuracy: 0.7328 - val_loss: 1.0094 - val_accuracy: 0.7238\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8731 - accuracy: 0.7332 - val_loss: 1.0085 - val_accuracy: 0.7244\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8720 - accuracy: 0.7334 - val_loss: 1.0075 - val_accuracy: 0.7249\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8708 - accuracy: 0.7339 - val_loss: 1.0064 - val_accuracy: 0.7253\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8697 - accuracy: 0.7343 - val_loss: 1.0055 - val_accuracy: 0.7256\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8686 - accuracy: 0.7345 - val_loss: 1.0045 - val_accuracy: 0.7261\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8675 - accuracy: 0.7347 - val_loss: 1.0035 - val_accuracy: 0.7261\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8663 - accuracy: 0.7350 - val_loss: 1.0025 - val_accuracy: 0.7259\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8652 - accuracy: 0.7354 - val_loss: 1.0015 - val_accuracy: 0.7259\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8641 - accuracy: 0.7357 - val_loss: 1.0005 - val_accuracy: 0.7260\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8631 - accuracy: 0.7361 - val_loss: 0.9995 - val_accuracy: 0.7265\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8620 - accuracy: 0.7362 - val_loss: 0.9984 - val_accuracy: 0.7269\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8610 - accuracy: 0.7366 - val_loss: 0.9973 - val_accuracy: 0.7272\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8599 - accuracy: 0.7368 - val_loss: 0.9963 - val_accuracy: 0.7275\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8588 - accuracy: 0.7370 - val_loss: 0.9953 - val_accuracy: 0.7279\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8577 - accuracy: 0.7373 - val_loss: 0.9943 - val_accuracy: 0.7286\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8566 - accuracy: 0.7377 - val_loss: 0.9933 - val_accuracy: 0.7290\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8556 - accuracy: 0.7380 - val_loss: 0.9924 - val_accuracy: 0.7293\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8545 - accuracy: 0.7384 - val_loss: 0.9915 - val_accuracy: 0.7299\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8535 - accuracy: 0.7387 - val_loss: 0.9905 - val_accuracy: 0.7298\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8524 - accuracy: 0.7389 - val_loss: 0.9896 - val_accuracy: 0.7300\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8514 - accuracy: 0.7394 - val_loss: 0.9885 - val_accuracy: 0.7302\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8504 - accuracy: 0.7396 - val_loss: 0.9875 - val_accuracy: 0.7307\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8494 - accuracy: 0.7399 - val_loss: 0.9865 - val_accuracy: 0.7310\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8484 - accuracy: 0.7401 - val_loss: 0.9854 - val_accuracy: 0.7311\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8474 - accuracy: 0.7403 - val_loss: 0.9844 - val_accuracy: 0.7313\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8464 - accuracy: 0.7404 - val_loss: 0.9834 - val_accuracy: 0.7316\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8454 - accuracy: 0.7405 - val_loss: 0.9824 - val_accuracy: 0.7319\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8444 - accuracy: 0.7407 - val_loss: 0.9814 - val_accuracy: 0.7321\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8435 - accuracy: 0.7408 - val_loss: 0.9805 - val_accuracy: 0.7322\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8425 - accuracy: 0.7410 - val_loss: 0.9796 - val_accuracy: 0.7324\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8415 - accuracy: 0.7414 - val_loss: 0.9788 - val_accuracy: 0.7330\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8405 - accuracy: 0.7418 - val_loss: 0.9780 - val_accuracy: 0.7333\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8395 - accuracy: 0.7421 - val_loss: 0.9771 - val_accuracy: 0.7337\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8385 - accuracy: 0.7424 - val_loss: 0.9763 - val_accuracy: 0.7342\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8374 - accuracy: 0.7428 - val_loss: 0.9755 - val_accuracy: 0.7343\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8364 - accuracy: 0.7431 - val_loss: 0.9746 - val_accuracy: 0.7349\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8354 - accuracy: 0.7434 - val_loss: 0.9738 - val_accuracy: 0.7355\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8344 - accuracy: 0.7437 - val_loss: 0.9729 - val_accuracy: 0.7357\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8333 - accuracy: 0.7441 - val_loss: 0.9721 - val_accuracy: 0.7356\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8323 - accuracy: 0.7444 - val_loss: 0.9713 - val_accuracy: 0.7361\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8312 - accuracy: 0.7446 - val_loss: 0.9704 - val_accuracy: 0.7362\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8302 - accuracy: 0.7450 - val_loss: 0.9695 - val_accuracy: 0.7365\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8292 - accuracy: 0.7451 - val_loss: 0.9686 - val_accuracy: 0.7367\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8282 - accuracy: 0.7454 - val_loss: 0.9677 - val_accuracy: 0.7370\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8271 - accuracy: 0.7458 - val_loss: 0.9668 - val_accuracy: 0.7374\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8261 - accuracy: 0.7462 - val_loss: 0.9660 - val_accuracy: 0.7375\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8251 - accuracy: 0.7464 - val_loss: 0.9652 - val_accuracy: 0.7376\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8241 - accuracy: 0.7465 - val_loss: 0.9645 - val_accuracy: 0.7376\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8231 - accuracy: 0.7467 - val_loss: 0.9637 - val_accuracy: 0.7375\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8221 - accuracy: 0.7470 - val_loss: 0.9629 - val_accuracy: 0.7378\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.8211 - accuracy: 0.7472 - val_loss: 0.9620 - val_accuracy: 0.7380\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8200 - accuracy: 0.7476 - val_loss: 0.9610 - val_accuracy: 0.7382\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8190 - accuracy: 0.7478 - val_loss: 0.9601 - val_accuracy: 0.7388\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.8179 - accuracy: 0.7483 - val_loss: 0.9593 - val_accuracy: 0.7391\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8168 - accuracy: 0.7485 - val_loss: 0.9584 - val_accuracy: 0.7390\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8157 - accuracy: 0.7488 - val_loss: 0.9577 - val_accuracy: 0.7398\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8147 - accuracy: 0.7490 - val_loss: 0.9570 - val_accuracy: 0.7401\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8136 - accuracy: 0.7494 - val_loss: 0.9563 - val_accuracy: 0.7404\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8125 - accuracy: 0.7497 - val_loss: 0.9556 - val_accuracy: 0.7406\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8114 - accuracy: 0.7501 - val_loss: 0.9549 - val_accuracy: 0.7408\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8103 - accuracy: 0.7503 - val_loss: 0.9542 - val_accuracy: 0.7413\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8092 - accuracy: 0.7507 - val_loss: 0.9534 - val_accuracy: 0.7415\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8081 - accuracy: 0.7509 - val_loss: 0.9527 - val_accuracy: 0.7417\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.8071 - accuracy: 0.7511 - val_loss: 0.9521 - val_accuracy: 0.7418\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.8060 - accuracy: 0.7514 - val_loss: 0.9513 - val_accuracy: 0.7419\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8048 - accuracy: 0.7516 - val_loss: 0.9504 - val_accuracy: 0.7421\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8036 - accuracy: 0.7521 - val_loss: 0.9496 - val_accuracy: 0.7426\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8025 - accuracy: 0.7523 - val_loss: 0.9488 - val_accuracy: 0.7429\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8014 - accuracy: 0.7526 - val_loss: 0.9480 - val_accuracy: 0.7431\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8002 - accuracy: 0.7526 - val_loss: 0.9474 - val_accuracy: 0.7433\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7992 - accuracy: 0.7527 - val_loss: 0.9467 - val_accuracy: 0.7437\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7981 - accuracy: 0.7530 - val_loss: 0.9459 - val_accuracy: 0.7443\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7971 - accuracy: 0.7532 - val_loss: 0.9452 - val_accuracy: 0.7447\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7961 - accuracy: 0.7534 - val_loss: 0.9444 - val_accuracy: 0.7451\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7951 - accuracy: 0.7538 - val_loss: 0.9436 - val_accuracy: 0.7456\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7941 - accuracy: 0.7540 - val_loss: 0.9429 - val_accuracy: 0.7459\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7931 - accuracy: 0.7541 - val_loss: 0.9421 - val_accuracy: 0.7464\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7921 - accuracy: 0.7544 - val_loss: 0.9412 - val_accuracy: 0.7466\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7911 - accuracy: 0.7545 - val_loss: 0.9402 - val_accuracy: 0.7471\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7901 - accuracy: 0.7548 - val_loss: 0.9393 - val_accuracy: 0.7476\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7891 - accuracy: 0.7548 - val_loss: 0.9384 - val_accuracy: 0.7478\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7882 - accuracy: 0.7551 - val_loss: 0.9376 - val_accuracy: 0.7481\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7872 - accuracy: 0.7552 - val_loss: 0.9368 - val_accuracy: 0.7482\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7862 - accuracy: 0.7555 - val_loss: 0.9360 - val_accuracy: 0.7483\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7852 - accuracy: 0.7556 - val_loss: 0.9353 - val_accuracy: 0.7484\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7842 - accuracy: 0.7558 - val_loss: 0.9346 - val_accuracy: 0.7486\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7833 - accuracy: 0.7562 - val_loss: 0.9338 - val_accuracy: 0.7491\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7823 - accuracy: 0.7564 - val_loss: 0.9330 - val_accuracy: 0.7493\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7814 - accuracy: 0.7568 - val_loss: 0.9323 - val_accuracy: 0.7496\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7804 - accuracy: 0.7570 - val_loss: 0.9315 - val_accuracy: 0.7495\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7795 - accuracy: 0.7572 - val_loss: 0.9308 - val_accuracy: 0.7498\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7786 - accuracy: 0.7575 - val_loss: 0.9301 - val_accuracy: 0.7499\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7776 - accuracy: 0.7576 - val_loss: 0.9294 - val_accuracy: 0.7500\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7767 - accuracy: 0.7579 - val_loss: 0.9288 - val_accuracy: 0.7503\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7758 - accuracy: 0.7582 - val_loss: 0.9282 - val_accuracy: 0.7504\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7749 - accuracy: 0.7584 - val_loss: 0.9276 - val_accuracy: 0.7505\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7740 - accuracy: 0.7585 - val_loss: 0.9271 - val_accuracy: 0.7505\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7730 - accuracy: 0.7586 - val_loss: 0.9266 - val_accuracy: 0.7511\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7721 - accuracy: 0.7590 - val_loss: 0.9261 - val_accuracy: 0.7512\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7712 - accuracy: 0.7593 - val_loss: 0.9256 - val_accuracy: 0.7512\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7703 - accuracy: 0.7595 - val_loss: 0.9250 - val_accuracy: 0.7512\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7693 - accuracy: 0.7599 - val_loss: 0.9245 - val_accuracy: 0.7515\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7684 - accuracy: 0.7600 - val_loss: 0.9240 - val_accuracy: 0.7516\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7675 - accuracy: 0.7602 - val_loss: 0.9234 - val_accuracy: 0.7513\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7666 - accuracy: 0.7604 - val_loss: 0.9228 - val_accuracy: 0.7514\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7657 - accuracy: 0.7607 - val_loss: 0.9222 - val_accuracy: 0.7515\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7648 - accuracy: 0.7609 - val_loss: 0.9215 - val_accuracy: 0.7516\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7639 - accuracy: 0.7610 - val_loss: 0.9209 - val_accuracy: 0.7520\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7630 - accuracy: 0.7613 - val_loss: 0.9202 - val_accuracy: 0.7522\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7621 - accuracy: 0.7614 - val_loss: 0.9195 - val_accuracy: 0.7523\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7612 - accuracy: 0.7617 - val_loss: 0.9189 - val_accuracy: 0.7526\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7603 - accuracy: 0.7620 - val_loss: 0.9182 - val_accuracy: 0.7529\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7595 - accuracy: 0.7622 - val_loss: 0.9176 - val_accuracy: 0.7537\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7586 - accuracy: 0.7626 - val_loss: 0.9170 - val_accuracy: 0.7539\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7577 - accuracy: 0.7627 - val_loss: 0.9164 - val_accuracy: 0.7541\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7569 - accuracy: 0.7628 - val_loss: 0.9158 - val_accuracy: 0.7542\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7560 - accuracy: 0.7632 - val_loss: 0.9152 - val_accuracy: 0.7545\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7552 - accuracy: 0.7633 - val_loss: 0.9146 - val_accuracy: 0.7543\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7543 - accuracy: 0.7634 - val_loss: 0.9142 - val_accuracy: 0.7545\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7535 - accuracy: 0.7636 - val_loss: 0.9137 - val_accuracy: 0.7543\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7527 - accuracy: 0.7638 - val_loss: 0.9131 - val_accuracy: 0.7543\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7518 - accuracy: 0.7640 - val_loss: 0.9126 - val_accuracy: 0.7544\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7510 - accuracy: 0.7642 - val_loss: 0.9122 - val_accuracy: 0.7546\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7502 - accuracy: 0.7642 - val_loss: 0.9116 - val_accuracy: 0.7549\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7494 - accuracy: 0.7644 - val_loss: 0.9109 - val_accuracy: 0.7550\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.7486 - accuracy: 0.7646 - val_loss: 0.9104 - val_accuracy: 0.7552\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7477 - accuracy: 0.7647 - val_loss: 0.9098 - val_accuracy: 0.7551\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7469 - accuracy: 0.7648 - val_loss: 0.9093 - val_accuracy: 0.7551\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7461 - accuracy: 0.7649 - val_loss: 0.9088 - val_accuracy: 0.7553\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7453 - accuracy: 0.7652 - val_loss: 0.9083 - val_accuracy: 0.7552\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7446 - accuracy: 0.7654 - val_loss: 0.9078 - val_accuracy: 0.7552\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7438 - accuracy: 0.7657 - val_loss: 0.9074 - val_accuracy: 0.7554\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7430 - accuracy: 0.7658 - val_loss: 0.9070 - val_accuracy: 0.7557\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7422 - accuracy: 0.7660 - val_loss: 0.9065 - val_accuracy: 0.7557\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7414 - accuracy: 0.7661 - val_loss: 0.9060 - val_accuracy: 0.7560\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7406 - accuracy: 0.7663 - val_loss: 0.9054 - val_accuracy: 0.7559\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7398 - accuracy: 0.7664 - val_loss: 0.9048 - val_accuracy: 0.7558\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7391 - accuracy: 0.7666 - val_loss: 0.9043 - val_accuracy: 0.7562\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7383 - accuracy: 0.7668 - val_loss: 0.9037 - val_accuracy: 0.7563\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7375 - accuracy: 0.7669 - val_loss: 0.9031 - val_accuracy: 0.7563\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7367 - accuracy: 0.7672 - val_loss: 0.9026 - val_accuracy: 0.7564\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7359 - accuracy: 0.7675 - val_loss: 0.9020 - val_accuracy: 0.7565\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7352 - accuracy: 0.7678 - val_loss: 0.9014 - val_accuracy: 0.7565\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7344 - accuracy: 0.7680 - val_loss: 0.9008 - val_accuracy: 0.7566\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7336 - accuracy: 0.7681 - val_loss: 0.9002 - val_accuracy: 0.7566\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7328 - accuracy: 0.7683 - val_loss: 0.8996 - val_accuracy: 0.7568\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7321 - accuracy: 0.7685 - val_loss: 0.8990 - val_accuracy: 0.7570\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7313 - accuracy: 0.7686 - val_loss: 0.8985 - val_accuracy: 0.7571\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7305 - accuracy: 0.7686 - val_loss: 0.8980 - val_accuracy: 0.7572\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7297 - accuracy: 0.7688 - val_loss: 0.8976 - val_accuracy: 0.7574\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7289 - accuracy: 0.7689 - val_loss: 0.8971 - val_accuracy: 0.7576\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7282 - accuracy: 0.7690 - val_loss: 0.8966 - val_accuracy: 0.7578\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7274 - accuracy: 0.7692 - val_loss: 0.8961 - val_accuracy: 0.7579\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7267 - accuracy: 0.7694 - val_loss: 0.8956 - val_accuracy: 0.7581\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7259 - accuracy: 0.7696 - val_loss: 0.8950 - val_accuracy: 0.7580\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7252 - accuracy: 0.7697 - val_loss: 0.8945 - val_accuracy: 0.7584\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7244 - accuracy: 0.7698 - val_loss: 0.8939 - val_accuracy: 0.7586\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7237 - accuracy: 0.7699 - val_loss: 0.8933 - val_accuracy: 0.7587\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7229 - accuracy: 0.7701 - val_loss: 0.8927 - val_accuracy: 0.7590\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7222 - accuracy: 0.7704 - val_loss: 0.8922 - val_accuracy: 0.7590\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7214 - accuracy: 0.7706 - val_loss: 0.8916 - val_accuracy: 0.7592\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7207 - accuracy: 0.7708 - val_loss: 0.8911 - val_accuracy: 0.7593\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7199 - accuracy: 0.7709 - val_loss: 0.8905 - val_accuracy: 0.7593\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7192 - accuracy: 0.7711 - val_loss: 0.8898 - val_accuracy: 0.7592\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7184 - accuracy: 0.7712 - val_loss: 0.8892 - val_accuracy: 0.7597\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7177 - accuracy: 0.7713 - val_loss: 0.8886 - val_accuracy: 0.7596\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7169 - accuracy: 0.7716 - val_loss: 0.8880 - val_accuracy: 0.7598\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7161 - accuracy: 0.7718 - val_loss: 0.8874 - val_accuracy: 0.7600\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7154 - accuracy: 0.7721 - val_loss: 0.8869 - val_accuracy: 0.7603\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7146 - accuracy: 0.7722 - val_loss: 0.8863 - val_accuracy: 0.7603\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7139 - accuracy: 0.7725 - val_loss: 0.8858 - val_accuracy: 0.7605\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7131 - accuracy: 0.7727 - val_loss: 0.8852 - val_accuracy: 0.7605\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7123 - accuracy: 0.7730 - val_loss: 0.8847 - val_accuracy: 0.7610\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.7116 - accuracy: 0.7733 - val_loss: 0.8841 - val_accuracy: 0.7612\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7108 - accuracy: 0.7735 - val_loss: 0.8835 - val_accuracy: 0.7613\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7100 - accuracy: 0.7737 - val_loss: 0.8828 - val_accuracy: 0.7614\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7093 - accuracy: 0.7740 - val_loss: 0.8821 - val_accuracy: 0.7616\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7085 - accuracy: 0.7741 - val_loss: 0.8814 - val_accuracy: 0.7617\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7077 - accuracy: 0.7743 - val_loss: 0.8806 - val_accuracy: 0.7621\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7069 - accuracy: 0.7746 - val_loss: 0.8798 - val_accuracy: 0.7621\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.7062 - accuracy: 0.7747 - val_loss: 0.8791 - val_accuracy: 0.7624\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7054 - accuracy: 0.7748 - val_loss: 0.8783 - val_accuracy: 0.7627\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7046 - accuracy: 0.7750 - val_loss: 0.8775 - val_accuracy: 0.7632\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7039 - accuracy: 0.7752 - val_loss: 0.8768 - val_accuracy: 0.7632\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7031 - accuracy: 0.7753 - val_loss: 0.8761 - val_accuracy: 0.7634\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7024 - accuracy: 0.7756 - val_loss: 0.8754 - val_accuracy: 0.7639\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.7016 - accuracy: 0.7758 - val_loss: 0.8748 - val_accuracy: 0.7641\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7009 - accuracy: 0.7761 - val_loss: 0.8742 - val_accuracy: 0.7641\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7001 - accuracy: 0.7762 - val_loss: 0.8736 - val_accuracy: 0.7642\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6994 - accuracy: 0.7762 - val_loss: 0.8731 - val_accuracy: 0.7641\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6986 - accuracy: 0.7764 - val_loss: 0.8725 - val_accuracy: 0.7642\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6978 - accuracy: 0.7768 - val_loss: 0.8720 - val_accuracy: 0.7644\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6971 - accuracy: 0.7770 - val_loss: 0.8713 - val_accuracy: 0.7645\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6963 - accuracy: 0.7771 - val_loss: 0.8707 - val_accuracy: 0.7649\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6955 - accuracy: 0.7773 - val_loss: 0.8702 - val_accuracy: 0.7651\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6947 - accuracy: 0.7775 - val_loss: 0.8697 - val_accuracy: 0.7651\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6938 - accuracy: 0.7776 - val_loss: 0.8692 - val_accuracy: 0.7656\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6929 - accuracy: 0.7780 - val_loss: 0.8688 - val_accuracy: 0.7657\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6921 - accuracy: 0.7782 - val_loss: 0.8684 - val_accuracy: 0.7661\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6912 - accuracy: 0.7784 - val_loss: 0.8680 - val_accuracy: 0.7662\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6904 - accuracy: 0.7787 - val_loss: 0.8675 - val_accuracy: 0.7664\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6896 - accuracy: 0.7789 - val_loss: 0.8671 - val_accuracy: 0.7668\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6888 - accuracy: 0.7792 - val_loss: 0.8665 - val_accuracy: 0.7671\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6880 - accuracy: 0.7795 - val_loss: 0.8659 - val_accuracy: 0.7673\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6872 - accuracy: 0.7797 - val_loss: 0.8653 - val_accuracy: 0.7677\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6864 - accuracy: 0.7800 - val_loss: 0.8647 - val_accuracy: 0.7678\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6856 - accuracy: 0.7801 - val_loss: 0.8641 - val_accuracy: 0.7677\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6847 - accuracy: 0.7805 - val_loss: 0.8636 - val_accuracy: 0.7682\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6838 - accuracy: 0.7807 - val_loss: 0.8629 - val_accuracy: 0.7685\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6830 - accuracy: 0.7808 - val_loss: 0.8622 - val_accuracy: 0.7685\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6821 - accuracy: 0.7812 - val_loss: 0.8615 - val_accuracy: 0.7689\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6813 - accuracy: 0.7814 - val_loss: 0.8608 - val_accuracy: 0.7696\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6805 - accuracy: 0.7817 - val_loss: 0.8601 - val_accuracy: 0.7697\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6797 - accuracy: 0.7819 - val_loss: 0.8595 - val_accuracy: 0.7698\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6789 - accuracy: 0.7822 - val_loss: 0.8590 - val_accuracy: 0.7701\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6780 - accuracy: 0.7824 - val_loss: 0.8584 - val_accuracy: 0.7700\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6772 - accuracy: 0.7825 - val_loss: 0.8579 - val_accuracy: 0.7706\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6763 - accuracy: 0.7826 - val_loss: 0.8573 - val_accuracy: 0.7708\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6755 - accuracy: 0.7829 - val_loss: 0.8568 - val_accuracy: 0.7709\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6747 - accuracy: 0.7831 - val_loss: 0.8563 - val_accuracy: 0.7707\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6739 - accuracy: 0.7831 - val_loss: 0.8558 - val_accuracy: 0.7707\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6731 - accuracy: 0.7832 - val_loss: 0.8553 - val_accuracy: 0.7708\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6723 - accuracy: 0.7833 - val_loss: 0.8548 - val_accuracy: 0.7709\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6715 - accuracy: 0.7835 - val_loss: 0.8542 - val_accuracy: 0.7711\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6707 - accuracy: 0.7837 - val_loss: 0.8537 - val_accuracy: 0.7711\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6699 - accuracy: 0.7840 - val_loss: 0.8532 - val_accuracy: 0.7712\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6691 - accuracy: 0.7842 - val_loss: 0.8527 - val_accuracy: 0.7714\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6682 - accuracy: 0.7844 - val_loss: 0.8521 - val_accuracy: 0.7716\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6674 - accuracy: 0.7846 - val_loss: 0.8515 - val_accuracy: 0.7718\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6666 - accuracy: 0.7847 - val_loss: 0.8510 - val_accuracy: 0.7719\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6658 - accuracy: 0.7850 - val_loss: 0.8503 - val_accuracy: 0.7718\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6650 - accuracy: 0.7854 - val_loss: 0.8498 - val_accuracy: 0.7721\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6642 - accuracy: 0.7856 - val_loss: 0.8492 - val_accuracy: 0.7725\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6633 - accuracy: 0.7860 - val_loss: 0.8485 - val_accuracy: 0.7729\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6624 - accuracy: 0.7865 - val_loss: 0.8477 - val_accuracy: 0.7732\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6615 - accuracy: 0.7867 - val_loss: 0.8470 - val_accuracy: 0.7737\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6607 - accuracy: 0.7869 - val_loss: 0.8464 - val_accuracy: 0.7743\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6599 - accuracy: 0.7872 - val_loss: 0.8458 - val_accuracy: 0.7747\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6592 - accuracy: 0.7875 - val_loss: 0.8452 - val_accuracy: 0.7749\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6584 - accuracy: 0.7878 - val_loss: 0.8446 - val_accuracy: 0.7753\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6576 - accuracy: 0.7880 - val_loss: 0.8440 - val_accuracy: 0.7757\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6568 - accuracy: 0.7882 - val_loss: 0.8434 - val_accuracy: 0.7761\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6561 - accuracy: 0.7885 - val_loss: 0.8429 - val_accuracy: 0.7766\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6553 - accuracy: 0.7888 - val_loss: 0.8423 - val_accuracy: 0.7772\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6546 - accuracy: 0.7890 - val_loss: 0.8417 - val_accuracy: 0.7774\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6538 - accuracy: 0.7893 - val_loss: 0.8412 - val_accuracy: 0.7776\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6530 - accuracy: 0.7895 - val_loss: 0.8407 - val_accuracy: 0.7777\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6522 - accuracy: 0.7896 - val_loss: 0.8404 - val_accuracy: 0.7778\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6514 - accuracy: 0.7898 - val_loss: 0.8402 - val_accuracy: 0.7779\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6506 - accuracy: 0.7899 - val_loss: 0.8398 - val_accuracy: 0.7787\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6499 - accuracy: 0.7902 - val_loss: 0.8394 - val_accuracy: 0.7789\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6492 - accuracy: 0.7904 - val_loss: 0.8388 - val_accuracy: 0.7793\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6484 - accuracy: 0.7908 - val_loss: 0.8382 - val_accuracy: 0.7795\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6476 - accuracy: 0.7911 - val_loss: 0.8378 - val_accuracy: 0.7795\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6469 - accuracy: 0.7912 - val_loss: 0.8374 - val_accuracy: 0.7797\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6461 - accuracy: 0.7914 - val_loss: 0.8370 - val_accuracy: 0.7798\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6453 - accuracy: 0.7918 - val_loss: 0.8366 - val_accuracy: 0.7802\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6445 - accuracy: 0.7921 - val_loss: 0.8361 - val_accuracy: 0.7802\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6437 - accuracy: 0.7923 - val_loss: 0.8357 - val_accuracy: 0.7811\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6429 - accuracy: 0.7926 - val_loss: 0.8354 - val_accuracy: 0.7815\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6421 - accuracy: 0.7929 - val_loss: 0.8349 - val_accuracy: 0.7817\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6413 - accuracy: 0.7931 - val_loss: 0.8344 - val_accuracy: 0.7824\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6406 - accuracy: 0.7936 - val_loss: 0.8338 - val_accuracy: 0.7825\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6398 - accuracy: 0.7938 - val_loss: 0.8332 - val_accuracy: 0.7824\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6390 - accuracy: 0.7941 - val_loss: 0.8327 - val_accuracy: 0.7822\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6383 - accuracy: 0.7944 - val_loss: 0.8322 - val_accuracy: 0.7826\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6375 - accuracy: 0.7947 - val_loss: 0.8316 - val_accuracy: 0.7827\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6367 - accuracy: 0.7950 - val_loss: 0.8310 - val_accuracy: 0.7828\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6359 - accuracy: 0.7954 - val_loss: 0.8305 - val_accuracy: 0.7835\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6351 - accuracy: 0.7956 - val_loss: 0.8300 - val_accuracy: 0.7837\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6343 - accuracy: 0.7959 - val_loss: 0.8296 - val_accuracy: 0.7839\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6336 - accuracy: 0.7961 - val_loss: 0.8291 - val_accuracy: 0.7845\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6328 - accuracy: 0.7964 - val_loss: 0.8285 - val_accuracy: 0.7851\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6320 - accuracy: 0.7967 - val_loss: 0.8279 - val_accuracy: 0.7857\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6313 - accuracy: 0.7969 - val_loss: 0.8274 - val_accuracy: 0.7860\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6305 - accuracy: 0.7972 - val_loss: 0.8268 - val_accuracy: 0.7866\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6298 - accuracy: 0.7974 - val_loss: 0.8262 - val_accuracy: 0.7868\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6290 - accuracy: 0.7977 - val_loss: 0.8257 - val_accuracy: 0.7872\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6283 - accuracy: 0.7980 - val_loss: 0.8251 - val_accuracy: 0.7878\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6276 - accuracy: 0.7983 - val_loss: 0.8245 - val_accuracy: 0.7883\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6268 - accuracy: 0.7987 - val_loss: 0.8238 - val_accuracy: 0.7887\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6260 - accuracy: 0.7991 - val_loss: 0.8232 - val_accuracy: 0.7888\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6253 - accuracy: 0.7993 - val_loss: 0.8227 - val_accuracy: 0.7891\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6246 - accuracy: 0.7994 - val_loss: 0.8222 - val_accuracy: 0.7892\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6239 - accuracy: 0.7998 - val_loss: 0.8217 - val_accuracy: 0.7896\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6232 - accuracy: 0.8003 - val_loss: 0.8213 - val_accuracy: 0.7897\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6224 - accuracy: 0.8007 - val_loss: 0.8209 - val_accuracy: 0.7896\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6216 - accuracy: 0.8009 - val_loss: 0.8204 - val_accuracy: 0.7898\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6209 - accuracy: 0.8013 - val_loss: 0.8199 - val_accuracy: 0.7906\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6201 - accuracy: 0.8015 - val_loss: 0.8193 - val_accuracy: 0.7907\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6194 - accuracy: 0.8018 - val_loss: 0.8188 - val_accuracy: 0.7909\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6186 - accuracy: 0.8020 - val_loss: 0.8183 - val_accuracy: 0.7915\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6179 - accuracy: 0.8024 - val_loss: 0.8179 - val_accuracy: 0.7917\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6171 - accuracy: 0.8027 - val_loss: 0.8176 - val_accuracy: 0.7917\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6164 - accuracy: 0.8030 - val_loss: 0.8173 - val_accuracy: 0.7921\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6156 - accuracy: 0.8034 - val_loss: 0.8170 - val_accuracy: 0.7922\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6148 - accuracy: 0.8037 - val_loss: 0.8166 - val_accuracy: 0.7923\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6141 - accuracy: 0.8040 - val_loss: 0.8161 - val_accuracy: 0.7926\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6133 - accuracy: 0.8043 - val_loss: 0.8157 - val_accuracy: 0.7929\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6126 - accuracy: 0.8046 - val_loss: 0.8152 - val_accuracy: 0.7936\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6118 - accuracy: 0.8050 - val_loss: 0.8145 - val_accuracy: 0.7942\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6111 - accuracy: 0.8054 - val_loss: 0.8138 - val_accuracy: 0.7944\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6103 - accuracy: 0.8059 - val_loss: 0.8130 - val_accuracy: 0.7949\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6095 - accuracy: 0.8062 - val_loss: 0.8120 - val_accuracy: 0.7954\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6087 - accuracy: 0.8069 - val_loss: 0.8111 - val_accuracy: 0.7960\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6079 - accuracy: 0.8071 - val_loss: 0.8101 - val_accuracy: 0.7962\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6071 - accuracy: 0.8074 - val_loss: 0.8092 - val_accuracy: 0.7967\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6063 - accuracy: 0.8078 - val_loss: 0.8085 - val_accuracy: 0.7973\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6055 - accuracy: 0.8081 - val_loss: 0.8077 - val_accuracy: 0.7976\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6047 - accuracy: 0.8085 - val_loss: 0.8071 - val_accuracy: 0.7979\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6038 - accuracy: 0.8089 - val_loss: 0.8065 - val_accuracy: 0.7983\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6030 - accuracy: 0.8091 - val_loss: 0.8061 - val_accuracy: 0.7984\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6022 - accuracy: 0.8093 - val_loss: 0.8056 - val_accuracy: 0.7987\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6014 - accuracy: 0.8098 - val_loss: 0.8049 - val_accuracy: 0.7992\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6007 - accuracy: 0.8101 - val_loss: 0.8041 - val_accuracy: 0.7993\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5999 - accuracy: 0.8106 - val_loss: 0.8033 - val_accuracy: 0.7997\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5992 - accuracy: 0.8109 - val_loss: 0.8025 - val_accuracy: 0.7999\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5984 - accuracy: 0.8112 - val_loss: 0.8016 - val_accuracy: 0.8004\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5976 - accuracy: 0.8114 - val_loss: 0.8008 - val_accuracy: 0.8006\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5969 - accuracy: 0.8117 - val_loss: 0.8003 - val_accuracy: 0.8008\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5961 - accuracy: 0.8123 - val_loss: 0.7997 - val_accuracy: 0.8014\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5954 - accuracy: 0.8127 - val_loss: 0.7992 - val_accuracy: 0.8018\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5945 - accuracy: 0.8132 - val_loss: 0.7988 - val_accuracy: 0.8022\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5937 - accuracy: 0.8135 - val_loss: 0.7985 - val_accuracy: 0.8025\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5929 - accuracy: 0.8139 - val_loss: 0.7980 - val_accuracy: 0.8030\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5921 - accuracy: 0.8142 - val_loss: 0.7976 - val_accuracy: 0.8033\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5913 - accuracy: 0.8146 - val_loss: 0.7971 - val_accuracy: 0.8038\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5905 - accuracy: 0.8150 - val_loss: 0.7965 - val_accuracy: 0.8041\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5897 - accuracy: 0.8154 - val_loss: 0.7960 - val_accuracy: 0.8046\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5889 - accuracy: 0.8158 - val_loss: 0.7953 - val_accuracy: 0.8050\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5880 - accuracy: 0.8162 - val_loss: 0.7946 - val_accuracy: 0.8059\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5872 - accuracy: 0.8166 - val_loss: 0.7938 - val_accuracy: 0.8064\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5863 - accuracy: 0.8171 - val_loss: 0.7930 - val_accuracy: 0.8070\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5853 - accuracy: 0.8177 - val_loss: 0.7920 - val_accuracy: 0.8076\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5844 - accuracy: 0.8183 - val_loss: 0.7910 - val_accuracy: 0.8084\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5834 - accuracy: 0.8187 - val_loss: 0.7900 - val_accuracy: 0.8091\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5825 - accuracy: 0.8194 - val_loss: 0.7890 - val_accuracy: 0.8093\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5817 - accuracy: 0.8198 - val_loss: 0.7880 - val_accuracy: 0.8095\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5807 - accuracy: 0.8205 - val_loss: 0.7870 - val_accuracy: 0.8102\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5797 - accuracy: 0.8211 - val_loss: 0.7860 - val_accuracy: 0.8107\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5788 - accuracy: 0.8217 - val_loss: 0.7850 - val_accuracy: 0.8114\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5779 - accuracy: 0.8222 - val_loss: 0.7838 - val_accuracy: 0.8118\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5769 - accuracy: 0.8228 - val_loss: 0.7828 - val_accuracy: 0.8125\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5760 - accuracy: 0.8233 - val_loss: 0.7817 - val_accuracy: 0.8128\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5751 - accuracy: 0.8239 - val_loss: 0.7808 - val_accuracy: 0.8135\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5742 - accuracy: 0.8244 - val_loss: 0.7799 - val_accuracy: 0.8142\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5733 - accuracy: 0.8249 - val_loss: 0.7791 - val_accuracy: 0.8149\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5724 - accuracy: 0.8255 - val_loss: 0.7782 - val_accuracy: 0.8154\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5715 - accuracy: 0.8262 - val_loss: 0.7774 - val_accuracy: 0.8161\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5705 - accuracy: 0.8270 - val_loss: 0.7765 - val_accuracy: 0.8173\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5694 - accuracy: 0.8276 - val_loss: 0.7759 - val_accuracy: 0.8171\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5684 - accuracy: 0.8282 - val_loss: 0.7752 - val_accuracy: 0.8179\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5675 - accuracy: 0.8288 - val_loss: 0.7742 - val_accuracy: 0.8191\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5665 - accuracy: 0.8296 - val_loss: 0.7733 - val_accuracy: 0.8192\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5655 - accuracy: 0.8300 - val_loss: 0.7726 - val_accuracy: 0.8193\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5646 - accuracy: 0.8307 - val_loss: 0.7718 - val_accuracy: 0.8203\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5637 - accuracy: 0.8313 - val_loss: 0.7709 - val_accuracy: 0.8211\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5627 - accuracy: 0.8320 - val_loss: 0.7699 - val_accuracy: 0.8214\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5617 - accuracy: 0.8326 - val_loss: 0.7690 - val_accuracy: 0.8218\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5607 - accuracy: 0.8331 - val_loss: 0.7682 - val_accuracy: 0.8222\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5597 - accuracy: 0.8335 - val_loss: 0.7674 - val_accuracy: 0.8227\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5587 - accuracy: 0.8339 - val_loss: 0.7666 - val_accuracy: 0.8232\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5577 - accuracy: 0.8341 - val_loss: 0.7659 - val_accuracy: 0.8236\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5567 - accuracy: 0.8346 - val_loss: 0.7653 - val_accuracy: 0.8237\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5557 - accuracy: 0.8350 - val_loss: 0.7645 - val_accuracy: 0.8242\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5547 - accuracy: 0.8354 - val_loss: 0.7637 - val_accuracy: 0.8244\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5536 - accuracy: 0.8359 - val_loss: 0.7628 - val_accuracy: 0.8246\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5527 - accuracy: 0.8363 - val_loss: 0.7620 - val_accuracy: 0.8248\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5517 - accuracy: 0.8368 - val_loss: 0.7611 - val_accuracy: 0.8248\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5507 - accuracy: 0.8374 - val_loss: 0.7603 - val_accuracy: 0.8254\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5497 - accuracy: 0.8381 - val_loss: 0.7594 - val_accuracy: 0.8261\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5487 - accuracy: 0.8388 - val_loss: 0.7584 - val_accuracy: 0.8262\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5477 - accuracy: 0.8395 - val_loss: 0.7576 - val_accuracy: 0.8268\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5468 - accuracy: 0.8400 - val_loss: 0.7567 - val_accuracy: 0.8276\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5458 - accuracy: 0.8407 - val_loss: 0.7557 - val_accuracy: 0.8281\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5448 - accuracy: 0.8411 - val_loss: 0.7548 - val_accuracy: 0.8284\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5438 - accuracy: 0.8414 - val_loss: 0.7538 - val_accuracy: 0.8287\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5429 - accuracy: 0.8416 - val_loss: 0.7527 - val_accuracy: 0.8287\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5419 - accuracy: 0.8420 - val_loss: 0.7515 - val_accuracy: 0.8290\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5409 - accuracy: 0.8425 - val_loss: 0.7502 - val_accuracy: 0.8296\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5400 - accuracy: 0.8428 - val_loss: 0.7487 - val_accuracy: 0.8302\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5390 - accuracy: 0.8432 - val_loss: 0.7474 - val_accuracy: 0.8310\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5381 - accuracy: 0.8435 - val_loss: 0.7461 - val_accuracy: 0.8314\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5372 - accuracy: 0.8439 - val_loss: 0.7447 - val_accuracy: 0.8325\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5363 - accuracy: 0.8444 - val_loss: 0.7434 - val_accuracy: 0.8328\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5354 - accuracy: 0.8448 - val_loss: 0.7422 - val_accuracy: 0.8335\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5345 - accuracy: 0.8453 - val_loss: 0.7412 - val_accuracy: 0.8340\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5335 - accuracy: 0.8459 - val_loss: 0.7403 - val_accuracy: 0.8342\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5326 - accuracy: 0.8463 - val_loss: 0.7395 - val_accuracy: 0.8346\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5318 - accuracy: 0.8468 - val_loss: 0.7386 - val_accuracy: 0.8351\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5309 - accuracy: 0.8472 - val_loss: 0.7379 - val_accuracy: 0.8354\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5301 - accuracy: 0.8476 - val_loss: 0.7372 - val_accuracy: 0.8358\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5293 - accuracy: 0.8479 - val_loss: 0.7364 - val_accuracy: 0.8366\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5285 - accuracy: 0.8483 - val_loss: 0.7355 - val_accuracy: 0.8369\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5276 - accuracy: 0.8487 - val_loss: 0.7345 - val_accuracy: 0.8374\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5268 - accuracy: 0.8490 - val_loss: 0.7336 - val_accuracy: 0.8378\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5259 - accuracy: 0.8493 - val_loss: 0.7326 - val_accuracy: 0.8380\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5251 - accuracy: 0.8496 - val_loss: 0.7318 - val_accuracy: 0.8382\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5243 - accuracy: 0.8499 - val_loss: 0.7310 - val_accuracy: 0.8381\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5235 - accuracy: 0.8501 - val_loss: 0.7304 - val_accuracy: 0.8383\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5227 - accuracy: 0.8504 - val_loss: 0.7299 - val_accuracy: 0.8386\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5219 - accuracy: 0.8508 - val_loss: 0.7294 - val_accuracy: 0.8388\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5211 - accuracy: 0.8510 - val_loss: 0.7288 - val_accuracy: 0.8395\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5204 - accuracy: 0.8514 - val_loss: 0.7281 - val_accuracy: 0.8397\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.5196 - accuracy: 0.8516 - val_loss: 0.7274 - val_accuracy: 0.8401\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5188 - accuracy: 0.8521 - val_loss: 0.7266 - val_accuracy: 0.8407\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5180 - accuracy: 0.8525 - val_loss: 0.7258 - val_accuracy: 0.8407\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5172 - accuracy: 0.8528 - val_loss: 0.7251 - val_accuracy: 0.8415\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5164 - accuracy: 0.8534 - val_loss: 0.7244 - val_accuracy: 0.8422\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5155 - accuracy: 0.8539 - val_loss: 0.7238 - val_accuracy: 0.8426\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5146 - accuracy: 0.8543 - val_loss: 0.7232 - val_accuracy: 0.8431\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5138 - accuracy: 0.8546 - val_loss: 0.7226 - val_accuracy: 0.8434\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5130 - accuracy: 0.8548 - val_loss: 0.7221 - val_accuracy: 0.8439\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5122 - accuracy: 0.8551 - val_loss: 0.7215 - val_accuracy: 0.8439\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5114 - accuracy: 0.8553 - val_loss: 0.7211 - val_accuracy: 0.8442\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5106 - accuracy: 0.8557 - val_loss: 0.7205 - val_accuracy: 0.8446\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5098 - accuracy: 0.8561 - val_loss: 0.7200 - val_accuracy: 0.8448\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5089 - accuracy: 0.8564 - val_loss: 0.7195 - val_accuracy: 0.8451\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5082 - accuracy: 0.8568 - val_loss: 0.7191 - val_accuracy: 0.8458\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5074 - accuracy: 0.8572 - val_loss: 0.7187 - val_accuracy: 0.8462\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5066 - accuracy: 0.8576 - val_loss: 0.7182 - val_accuracy: 0.8468\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.5058 - accuracy: 0.8579 - val_loss: 0.7175 - val_accuracy: 0.8468\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5051 - accuracy: 0.8582 - val_loss: 0.7168 - val_accuracy: 0.8468\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5042 - accuracy: 0.8588 - val_loss: 0.7160 - val_accuracy: 0.8474\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5033 - accuracy: 0.8591 - val_loss: 0.7153 - val_accuracy: 0.8474\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5024 - accuracy: 0.8595 - val_loss: 0.7147 - val_accuracy: 0.8475\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5016 - accuracy: 0.8599 - val_loss: 0.7141 - val_accuracy: 0.8477\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5007 - accuracy: 0.8603 - val_loss: 0.7134 - val_accuracy: 0.8481\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4999 - accuracy: 0.8607 - val_loss: 0.7125 - val_accuracy: 0.8482\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4990 - accuracy: 0.8610 - val_loss: 0.7115 - val_accuracy: 0.8490\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4982 - accuracy: 0.8613 - val_loss: 0.7102 - val_accuracy: 0.8498\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4974 - accuracy: 0.8617 - val_loss: 0.7090 - val_accuracy: 0.8498\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4965 - accuracy: 0.8620 - val_loss: 0.7081 - val_accuracy: 0.8498\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4956 - accuracy: 0.8625 - val_loss: 0.7073 - val_accuracy: 0.8496\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4947 - accuracy: 0.8628 - val_loss: 0.7066 - val_accuracy: 0.8503\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4940 - accuracy: 0.8632 - val_loss: 0.7059 - val_accuracy: 0.8504\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4932 - accuracy: 0.8633 - val_loss: 0.7052 - val_accuracy: 0.8508\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4926 - accuracy: 0.8636 - val_loss: 0.7046 - val_accuracy: 0.8511\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4919 - accuracy: 0.8638 - val_loss: 0.7041 - val_accuracy: 0.8513\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4913 - accuracy: 0.8638 - val_loss: 0.7035 - val_accuracy: 0.8515\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4907 - accuracy: 0.8641 - val_loss: 0.7030 - val_accuracy: 0.8517\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4901 - accuracy: 0.8641 - val_loss: 0.7025 - val_accuracy: 0.8515\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4895 - accuracy: 0.8643 - val_loss: 0.7020 - val_accuracy: 0.8517\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4889 - accuracy: 0.8645 - val_loss: 0.7015 - val_accuracy: 0.8516\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4883 - accuracy: 0.8646 - val_loss: 0.7009 - val_accuracy: 0.8518\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4877 - accuracy: 0.8648 - val_loss: 0.7004 - val_accuracy: 0.8520\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4871 - accuracy: 0.8649 - val_loss: 0.6999 - val_accuracy: 0.8521\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4865 - accuracy: 0.8651 - val_loss: 0.6994 - val_accuracy: 0.8528\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4859 - accuracy: 0.8652 - val_loss: 0.6988 - val_accuracy: 0.8534\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4853 - accuracy: 0.8655 - val_loss: 0.6983 - val_accuracy: 0.8534\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4848 - accuracy: 0.8656 - val_loss: 0.6977 - val_accuracy: 0.8535\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4842 - accuracy: 0.8658 - val_loss: 0.6971 - val_accuracy: 0.8536\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4836 - accuracy: 0.8660 - val_loss: 0.6966 - val_accuracy: 0.8539\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4830 - accuracy: 0.8661 - val_loss: 0.6961 - val_accuracy: 0.8540\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4824 - accuracy: 0.8662 - val_loss: 0.6956 - val_accuracy: 0.8545\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4819 - accuracy: 0.8664 - val_loss: 0.6951 - val_accuracy: 0.8548\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4813 - accuracy: 0.8665 - val_loss: 0.6947 - val_accuracy: 0.8551\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4808 - accuracy: 0.8667 - val_loss: 0.6943 - val_accuracy: 0.8551\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4802 - accuracy: 0.8669 - val_loss: 0.6938 - val_accuracy: 0.8553\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4797 - accuracy: 0.8670 - val_loss: 0.6934 - val_accuracy: 0.8556\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4791 - accuracy: 0.8672 - val_loss: 0.6929 - val_accuracy: 0.8554\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4786 - accuracy: 0.8671 - val_loss: 0.6925 - val_accuracy: 0.8554\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4780 - accuracy: 0.8674 - val_loss: 0.6920 - val_accuracy: 0.8558\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4775 - accuracy: 0.8676 - val_loss: 0.6916 - val_accuracy: 0.8563\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4770 - accuracy: 0.8679 - val_loss: 0.6911 - val_accuracy: 0.8563\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4764 - accuracy: 0.8681 - val_loss: 0.6906 - val_accuracy: 0.8564\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4759 - accuracy: 0.8682 - val_loss: 0.6902 - val_accuracy: 0.8566\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4754 - accuracy: 0.8684 - val_loss: 0.6897 - val_accuracy: 0.8566\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4749 - accuracy: 0.8685 - val_loss: 0.6893 - val_accuracy: 0.8566\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4744 - accuracy: 0.8687 - val_loss: 0.6889 - val_accuracy: 0.8566\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4738 - accuracy: 0.8688 - val_loss: 0.6886 - val_accuracy: 0.8568\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4733 - accuracy: 0.8689 - val_loss: 0.6882 - val_accuracy: 0.8568\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4728 - accuracy: 0.8690 - val_loss: 0.6877 - val_accuracy: 0.8569\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4723 - accuracy: 0.8691 - val_loss: 0.6873 - val_accuracy: 0.8571\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4718 - accuracy: 0.8694 - val_loss: 0.6869 - val_accuracy: 0.8572\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4712 - accuracy: 0.8695 - val_loss: 0.6864 - val_accuracy: 0.8573\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4707 - accuracy: 0.8699 - val_loss: 0.6858 - val_accuracy: 0.8577\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4702 - accuracy: 0.8700 - val_loss: 0.6853 - val_accuracy: 0.8579\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4697 - accuracy: 0.8703 - val_loss: 0.6847 - val_accuracy: 0.8582\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4691 - accuracy: 0.8704 - val_loss: 0.6842 - val_accuracy: 0.8582\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4686 - accuracy: 0.8706 - val_loss: 0.6837 - val_accuracy: 0.8582\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4681 - accuracy: 0.8706 - val_loss: 0.6832 - val_accuracy: 0.8583\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4676 - accuracy: 0.8709 - val_loss: 0.6827 - val_accuracy: 0.8590\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4671 - accuracy: 0.8709 - val_loss: 0.6822 - val_accuracy: 0.8591\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4666 - accuracy: 0.8710 - val_loss: 0.6817 - val_accuracy: 0.8595\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4661 - accuracy: 0.8712 - val_loss: 0.6811 - val_accuracy: 0.8597\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4657 - accuracy: 0.8713 - val_loss: 0.6805 - val_accuracy: 0.8604\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4652 - accuracy: 0.8716 - val_loss: 0.6799 - val_accuracy: 0.8606\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4647 - accuracy: 0.8718 - val_loss: 0.6794 - val_accuracy: 0.8610\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4642 - accuracy: 0.8720 - val_loss: 0.6789 - val_accuracy: 0.8612\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4637 - accuracy: 0.8722 - val_loss: 0.6786 - val_accuracy: 0.8611\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4632 - accuracy: 0.8723 - val_loss: 0.6782 - val_accuracy: 0.8612\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4627 - accuracy: 0.8724 - val_loss: 0.6779 - val_accuracy: 0.8612\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4623 - accuracy: 0.8724 - val_loss: 0.6776 - val_accuracy: 0.8612\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4618 - accuracy: 0.8725 - val_loss: 0.6773 - val_accuracy: 0.8612\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4613 - accuracy: 0.8727 - val_loss: 0.6769 - val_accuracy: 0.8612\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4609 - accuracy: 0.8729 - val_loss: 0.6766 - val_accuracy: 0.8612\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4604 - accuracy: 0.8731 - val_loss: 0.6762 - val_accuracy: 0.8615\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4600 - accuracy: 0.8733 - val_loss: 0.6758 - val_accuracy: 0.8616\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4595 - accuracy: 0.8735 - val_loss: 0.6755 - val_accuracy: 0.8617\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4590 - accuracy: 0.8738 - val_loss: 0.6751 - val_accuracy: 0.8618\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4586 - accuracy: 0.8740 - val_loss: 0.6748 - val_accuracy: 0.8621\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4581 - accuracy: 0.8740 - val_loss: 0.6745 - val_accuracy: 0.8623\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4576 - accuracy: 0.8742 - val_loss: 0.6744 - val_accuracy: 0.8625\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4571 - accuracy: 0.8744 - val_loss: 0.6742 - val_accuracy: 0.8624\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4567 - accuracy: 0.8745 - val_loss: 0.6740 - val_accuracy: 0.8625\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4562 - accuracy: 0.8745 - val_loss: 0.6739 - val_accuracy: 0.8625\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4557 - accuracy: 0.8745 - val_loss: 0.6737 - val_accuracy: 0.8626\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4553 - accuracy: 0.8746 - val_loss: 0.6734 - val_accuracy: 0.8629\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4548 - accuracy: 0.8747 - val_loss: 0.6731 - val_accuracy: 0.8629\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4544 - accuracy: 0.8748 - val_loss: 0.6726 - val_accuracy: 0.8629\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4539 - accuracy: 0.8750 - val_loss: 0.6721 - val_accuracy: 0.8630\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4535 - accuracy: 0.8751 - val_loss: 0.6716 - val_accuracy: 0.8630\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4531 - accuracy: 0.8752 - val_loss: 0.6710 - val_accuracy: 0.8630\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4527 - accuracy: 0.8755 - val_loss: 0.6705 - val_accuracy: 0.8631\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.4523 - accuracy: 0.8756 - val_loss: 0.6700 - val_accuracy: 0.8631\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4519 - accuracy: 0.8756 - val_loss: 0.6695 - val_accuracy: 0.8631\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4515 - accuracy: 0.8758 - val_loss: 0.6692 - val_accuracy: 0.8631\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4511 - accuracy: 0.8759 - val_loss: 0.6688 - val_accuracy: 0.8633\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4507 - accuracy: 0.8760 - val_loss: 0.6685 - val_accuracy: 0.8633\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4503 - accuracy: 0.8762 - val_loss: 0.6682 - val_accuracy: 0.8633\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4499 - accuracy: 0.8764 - val_loss: 0.6680 - val_accuracy: 0.8635\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4495 - accuracy: 0.8764 - val_loss: 0.6676 - val_accuracy: 0.8636\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4491 - accuracy: 0.8765 - val_loss: 0.6673 - val_accuracy: 0.8636\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4487 - accuracy: 0.8766 - val_loss: 0.6668 - val_accuracy: 0.8638\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4483 - accuracy: 0.8766 - val_loss: 0.6664 - val_accuracy: 0.8640\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4479 - accuracy: 0.8767 - val_loss: 0.6658 - val_accuracy: 0.8645\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4475 - accuracy: 0.8769 - val_loss: 0.6653 - val_accuracy: 0.8648\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4471 - accuracy: 0.8770 - val_loss: 0.6648 - val_accuracy: 0.8650\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4467 - accuracy: 0.8772 - val_loss: 0.6644 - val_accuracy: 0.8650\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4463 - accuracy: 0.8773 - val_loss: 0.6641 - val_accuracy: 0.8652\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4460 - accuracy: 0.8774 - val_loss: 0.6639 - val_accuracy: 0.8652\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4456 - accuracy: 0.8774 - val_loss: 0.6636 - val_accuracy: 0.8652\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4452 - accuracy: 0.8774 - val_loss: 0.6633 - val_accuracy: 0.8653\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4449 - accuracy: 0.8775 - val_loss: 0.6629 - val_accuracy: 0.8653\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4445 - accuracy: 0.8776 - val_loss: 0.6625 - val_accuracy: 0.8655\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4441 - accuracy: 0.8777 - val_loss: 0.6621 - val_accuracy: 0.8656\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4438 - accuracy: 0.8778 - val_loss: 0.6618 - val_accuracy: 0.8658\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4434 - accuracy: 0.8780 - val_loss: 0.6614 - val_accuracy: 0.8658\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4431 - accuracy: 0.8780 - val_loss: 0.6611 - val_accuracy: 0.8660\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4427 - accuracy: 0.8782 - val_loss: 0.6607 - val_accuracy: 0.8661\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4423 - accuracy: 0.8782 - val_loss: 0.6603 - val_accuracy: 0.8660\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4420 - accuracy: 0.8784 - val_loss: 0.6601 - val_accuracy: 0.8660\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4416 - accuracy: 0.8784 - val_loss: 0.6598 - val_accuracy: 0.8659\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4412 - accuracy: 0.8786 - val_loss: 0.6595 - val_accuracy: 0.8661\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4409 - accuracy: 0.8785 - val_loss: 0.6592 - val_accuracy: 0.8661\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.4405 - accuracy: 0.8786 - val_loss: 0.6589 - val_accuracy: 0.8663\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4401 - accuracy: 0.8787 - val_loss: 0.6585 - val_accuracy: 0.8663\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4398 - accuracy: 0.8787 - val_loss: 0.6581 - val_accuracy: 0.8666\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4394 - accuracy: 0.8788 - val_loss: 0.6577 - val_accuracy: 0.8667\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4390 - accuracy: 0.8789 - val_loss: 0.6573 - val_accuracy: 0.8670\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4387 - accuracy: 0.8791 - val_loss: 0.6570 - val_accuracy: 0.8672\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4383 - accuracy: 0.8792 - val_loss: 0.6568 - val_accuracy: 0.8673\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4379 - accuracy: 0.8793 - val_loss: 0.6565 - val_accuracy: 0.8674\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4376 - accuracy: 0.8794 - val_loss: 0.6562 - val_accuracy: 0.8675\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4372 - accuracy: 0.8793 - val_loss: 0.6558 - val_accuracy: 0.8679\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4369 - accuracy: 0.8795 - val_loss: 0.6554 - val_accuracy: 0.8678\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4365 - accuracy: 0.8795 - val_loss: 0.6550 - val_accuracy: 0.8678\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4362 - accuracy: 0.8796 - val_loss: 0.6545 - val_accuracy: 0.8684\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4358 - accuracy: 0.8797 - val_loss: 0.6540 - val_accuracy: 0.8683\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4355 - accuracy: 0.8798 - val_loss: 0.6536 - val_accuracy: 0.8684\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4351 - accuracy: 0.8798 - val_loss: 0.6533 - val_accuracy: 0.8685\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4348 - accuracy: 0.8799 - val_loss: 0.6530 - val_accuracy: 0.8684\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.4345 - accuracy: 0.8800 - val_loss: 0.6528 - val_accuracy: 0.8685\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4341 - accuracy: 0.8800 - val_loss: 0.6525 - val_accuracy: 0.8687\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4338 - accuracy: 0.8801 - val_loss: 0.6521 - val_accuracy: 0.8686\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4335 - accuracy: 0.8802 - val_loss: 0.6516 - val_accuracy: 0.8690\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.4332 - accuracy: 0.8804 - val_loss: 0.6511 - val_accuracy: 0.8690\n"
     ]
    }
   ],
   "source": [
    "# third train\n",
    "keras_model_cce3 = keras_dense_model()\n",
    "\n",
    "keras_model_cce3.summary()\n",
    "\n",
    "keras_model_cce3.compile(\n",
    "    optimizer = optimizers.Adam(0.001),\n",
    "    loss = 'sparse_categorical_crossentropy', \n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "history_train_cce3 = keras_model_cce3.fit(\n",
    "    Xtrain, Ytrain, \n",
    "    validation_data=(Xtest, Ytest),\n",
    "    epochs = 1000, batch_size = Xtrain.shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PG1dqKIya0a2"
   },
   "outputs": [],
   "source": [
    "train_aucy1 = np.array(history_train_cce1.history['accuracy']).reshape(-1,1)\n",
    "train_aucy2 = np.array(history_train_cce2.history['accuracy']).reshape(-1,1)\n",
    "train_aucy3 = np.array(history_train_cce3.history['accuracy']).reshape(-1,1)\n",
    "#history_train_cce1.history['val_accuracy']\n",
    "aucy = np.concatenate((train_aucy1, train_aucy2, train_aucy3), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "c93-iGzXa0a3",
    "outputId": "15018529-2ee0-4b19-c73b-e7018890268c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcb7cb857b8>]"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot for average training accuracy\n",
    "mean_aucy = np.mean(aucy, 1)\n",
    "plt.plot(mean_aucy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "5uCKmUpifiKF",
    "outputId": "f32e893e-f1d7-4f07-b8f0-e624772b9dd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcb7ca590b8>]"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot for std training accuracy\n",
    "std_aucy = np.std(aucy, 1)\n",
    "plt.plot(std_aucy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQZLklcQnKds"
   },
   "outputs": [],
   "source": [
    "test_aucy1 = np.array(history_train_cce1.history['val_accuracy']).reshape(-1,1)\n",
    "test_aucy2 = np.array(history_train_cce2.history['val_accuracy']).reshape(-1,1)\n",
    "test_aucy3 = np.array(history_train_cce3.history['val_accuracy']).reshape(-1,1)\n",
    "#history_train_cce1.history['val_accuracy']\n",
    "aucy_test = np.concatenate((test_aucy1, test_aucy2, test_aucy3), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "8uMvBFaYnK1E",
    "outputId": "9ff1a134-b6a6-4582-8177-d987f8c15da6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcb8450e160>]"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot for average testing accuracy\n",
    "mean_aucy_test = np.mean(aucy_test, 1)\n",
    "plt.plot(mean_aucy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "XWCH_XHenls3",
    "outputId": "e4076949-f1d3-4014-964c-9068a8bb6439"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcb84d346a0>]"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot for std testing accuracy\n",
    "std_aucy_test = np.std(aucy_test, 1)\n",
    "plt.plot(std_aucy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "cM0WXDJCtRmV",
    "outputId": "e5ebd902-3821-4d96-9b8e-826de6097f63"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 92,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.plot_model(keras_model_cce3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Xyu01PGtx4s",
    "outputId": "09d5b2fa-f77b-46eb-fbb8-37c31f8b5e02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 25,450\n",
      "Trainable params: 25,450\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model_cce3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5856WpUtyC3"
   },
   "source": [
    "batch size:256\n",
    "\n",
    "optimizer:adam\n",
    "\n",
    "learning rate:0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zuUqR9ooa0a3"
   },
   "source": [
    "# Problem 4. Convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0AIKSnDrWRuk"
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oCsIKcjcwdEg"
   },
   "outputs": [],
   "source": [
    "X_train = Xtrain.reshape(-1,28,28,1) / 255\n",
    "X_test = Xtest.reshape(-1,28,28,1) / 255\n",
    "\n",
    "Y_train = np_utils.to_categorical(Ytrain, 10) \n",
    "Y_test = np_utils.to_categorical(Ytest, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DkSfT3L7a0a4"
   },
   "outputs": [],
   "source": [
    "def cnn():\n",
    "  model = models.Sequential()\n",
    "  model.add(layers.Conv2D(10, (5, 5), activation='relu', input_shape=(28,28,1)))\n",
    "  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "  model.add(layers.Conv2D(20, (5, 5), activation='relu'))\n",
    "  model.add(layers.MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "  model.add(layers.Dropout(0.5))\n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dense(50, activation='relu'))\n",
    "  model.add(layers.Dropout(0.5))\n",
    "  model.add(layers.Dense(10, activation='softmax'))\n",
    "  return model\n",
    "cnn_model = cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dZK8pKEfsj0-",
    "outputId": "da445a2d-2375-4f7d-f190-2b9c26afaf9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 24, 24, 10)        260       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 20)          5020      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 20)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 20)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 50)                16050     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 21,840\n",
      "Trainable params: 21,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "235/235 [==============================] - 23s 100ms/step - loss: 0.9772 - accuracy: 0.6711 - val_loss: 0.1788 - val_accuracy: 0.9508\n",
      "Epoch 2/40\n",
      "235/235 [==============================] - 24s 101ms/step - loss: 0.3648 - accuracy: 0.8880 - val_loss: 0.1065 - val_accuracy: 0.9677\n",
      "Epoch 3/40\n",
      "235/235 [==============================] - 23s 98ms/step - loss: 0.2747 - accuracy: 0.9175 - val_loss: 0.0836 - val_accuracy: 0.9742\n",
      "Epoch 4/40\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 0.2351 - accuracy: 0.9294 - val_loss: 0.0674 - val_accuracy: 0.9781\n",
      "Epoch 5/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.2082 - accuracy: 0.9380 - val_loss: 0.0609 - val_accuracy: 0.9813\n",
      "Epoch 6/40\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 0.1873 - accuracy: 0.9439 - val_loss: 0.0536 - val_accuracy: 0.9838\n",
      "Epoch 7/40\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 0.1735 - accuracy: 0.9493 - val_loss: 0.0479 - val_accuracy: 0.9853\n",
      "Epoch 8/40\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 0.1615 - accuracy: 0.9536 - val_loss: 0.0441 - val_accuracy: 0.9870\n",
      "Epoch 9/40\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 0.1603 - accuracy: 0.9530 - val_loss: 0.0431 - val_accuracy: 0.9873\n",
      "Epoch 10/40\n",
      "235/235 [==============================] - 22s 96ms/step - loss: 0.1443 - accuracy: 0.9574 - val_loss: 0.0399 - val_accuracy: 0.9880\n",
      "Epoch 11/40\n",
      "235/235 [==============================] - 22s 95ms/step - loss: 0.1417 - accuracy: 0.9587 - val_loss: 0.0375 - val_accuracy: 0.9880\n",
      "Epoch 12/40\n",
      "235/235 [==============================] - 22s 94ms/step - loss: 0.1351 - accuracy: 0.9604 - val_loss: 0.0355 - val_accuracy: 0.9874\n",
      "Epoch 13/40\n",
      "235/235 [==============================] - 22s 95ms/step - loss: 0.1346 - accuracy: 0.9604 - val_loss: 0.0360 - val_accuracy: 0.9884\n",
      "Epoch 14/40\n",
      "235/235 [==============================] - 22s 95ms/step - loss: 0.1268 - accuracy: 0.9621 - val_loss: 0.0326 - val_accuracy: 0.9894\n",
      "Epoch 15/40\n",
      "235/235 [==============================] - 22s 94ms/step - loss: 0.1205 - accuracy: 0.9650 - val_loss: 0.0336 - val_accuracy: 0.9891\n",
      "Epoch 16/40\n",
      "235/235 [==============================] - 22s 95ms/step - loss: 0.1181 - accuracy: 0.9649 - val_loss: 0.0360 - val_accuracy: 0.9877\n",
      "Epoch 17/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.1148 - accuracy: 0.9665 - val_loss: 0.0350 - val_accuracy: 0.9888\n",
      "Epoch 18/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.1124 - accuracy: 0.9675 - val_loss: 0.0329 - val_accuracy: 0.9896\n",
      "Epoch 19/40\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 0.1154 - accuracy: 0.9659 - val_loss: 0.0307 - val_accuracy: 0.9904\n",
      "Epoch 20/40\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 0.1061 - accuracy: 0.9698 - val_loss: 0.0334 - val_accuracy: 0.9893\n",
      "Epoch 21/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.1113 - accuracy: 0.9665 - val_loss: 0.0303 - val_accuracy: 0.9901\n",
      "Epoch 22/40\n",
      "235/235 [==============================] - 22s 96ms/step - loss: 0.1056 - accuracy: 0.9693 - val_loss: 0.0306 - val_accuracy: 0.9899\n",
      "Epoch 23/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.1048 - accuracy: 0.9685 - val_loss: 0.0295 - val_accuracy: 0.9899\n",
      "Epoch 24/40\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 0.1011 - accuracy: 0.9697 - val_loss: 0.0293 - val_accuracy: 0.9905\n",
      "Epoch 25/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.1014 - accuracy: 0.9701 - val_loss: 0.0282 - val_accuracy: 0.9906\n",
      "Epoch 26/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.1021 - accuracy: 0.9702 - val_loss: 0.0281 - val_accuracy: 0.9913\n",
      "Epoch 27/40\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 0.1006 - accuracy: 0.9705 - val_loss: 0.0287 - val_accuracy: 0.9909\n",
      "Epoch 28/40\n",
      "235/235 [==============================] - 22s 95ms/step - loss: 0.0957 - accuracy: 0.9710 - val_loss: 0.0276 - val_accuracy: 0.9908\n",
      "Epoch 29/40\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 0.0943 - accuracy: 0.9720 - val_loss: 0.0271 - val_accuracy: 0.9914\n",
      "Epoch 30/40\n",
      "235/235 [==============================] - 22s 96ms/step - loss: 0.0939 - accuracy: 0.9714 - val_loss: 0.0251 - val_accuracy: 0.9918\n",
      "Epoch 31/40\n",
      "235/235 [==============================] - 23s 99ms/step - loss: 0.0954 - accuracy: 0.9723 - val_loss: 0.0275 - val_accuracy: 0.9908\n",
      "Epoch 32/40\n",
      "235/235 [==============================] - 23s 99ms/step - loss: 0.0922 - accuracy: 0.9726 - val_loss: 0.0254 - val_accuracy: 0.9914\n",
      "Epoch 33/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.0927 - accuracy: 0.9718 - val_loss: 0.0253 - val_accuracy: 0.9916\n",
      "Epoch 34/40\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 0.0936 - accuracy: 0.9722 - val_loss: 0.0250 - val_accuracy: 0.9916\n",
      "Epoch 35/40\n",
      "235/235 [==============================] - 22s 96ms/step - loss: 0.0896 - accuracy: 0.9736 - val_loss: 0.0276 - val_accuracy: 0.9916\n",
      "Epoch 36/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.0867 - accuracy: 0.9735 - val_loss: 0.0255 - val_accuracy: 0.9916\n",
      "Epoch 37/40\n",
      "235/235 [==============================] - 22s 96ms/step - loss: 0.0894 - accuracy: 0.9736 - val_loss: 0.0268 - val_accuracy: 0.9915\n",
      "Epoch 38/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.0884 - accuracy: 0.9738 - val_loss: 0.0281 - val_accuracy: 0.9905\n",
      "Epoch 39/40\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 0.0868 - accuracy: 0.9750 - val_loss: 0.0260 - val_accuracy: 0.9907\n",
      "Epoch 40/40\n",
      "235/235 [==============================] - 23s 98ms/step - loss: 0.0878 - accuracy: 0.9740 - val_loss: 0.0257 - val_accuracy: 0.9918\n"
     ]
    }
   ],
   "source": [
    "# first train\n",
    "cnn_model.summary()\n",
    "cnn_model.compile(\n",
    "    optimizer = optimizers.Adam(0.001),\n",
    "    loss = 'sparse_categorical_crossentropy', \n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "history_train_cnn_model = cnn_model.fit(\n",
    "    X_train, Ytrain, \n",
    "    validation_data=(X_test, Ytest),\n",
    "    epochs = 40, batch_size = 256\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y6_BdrLntlaZ",
    "outputId": "12910bd1-a0ef-4a36-9eb0-3fcaac3b3bc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 24, 24, 10)        260       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 20)          5020      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 4, 4, 20)          0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4, 4, 20)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 50)                16050     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 21,840\n",
      "Trainable params: 21,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "235/235 [==============================] - 24s 100ms/step - loss: 0.9359 - accuracy: 0.6932 - val_loss: 0.1664 - val_accuracy: 0.9510\n",
      "Epoch 2/40\n",
      "235/235 [==============================] - 24s 100ms/step - loss: 0.3654 - accuracy: 0.8907 - val_loss: 0.1050 - val_accuracy: 0.9684\n",
      "Epoch 3/40\n",
      "235/235 [==============================] - 23s 99ms/step - loss: 0.2807 - accuracy: 0.9171 - val_loss: 0.0802 - val_accuracy: 0.9752\n",
      "Epoch 4/40\n",
      "235/235 [==============================] - 23s 100ms/step - loss: 0.2371 - accuracy: 0.9312 - val_loss: 0.0653 - val_accuracy: 0.9808\n",
      "Epoch 5/40\n",
      "235/235 [==============================] - 23s 100ms/step - loss: 0.2083 - accuracy: 0.9405 - val_loss: 0.0575 - val_accuracy: 0.9821\n",
      "Epoch 6/40\n",
      "235/235 [==============================] - 23s 100ms/step - loss: 0.1894 - accuracy: 0.9448 - val_loss: 0.0487 - val_accuracy: 0.9844\n",
      "Epoch 7/40\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 0.1755 - accuracy: 0.9487 - val_loss: 0.0457 - val_accuracy: 0.9852\n",
      "Epoch 8/40\n",
      "235/235 [==============================] - 23s 98ms/step - loss: 0.1664 - accuracy: 0.9520 - val_loss: 0.0410 - val_accuracy: 0.9863\n",
      "Epoch 9/40\n",
      "235/235 [==============================] - 23s 98ms/step - loss: 0.1531 - accuracy: 0.9553 - val_loss: 0.0388 - val_accuracy: 0.9869\n",
      "Epoch 10/40\n",
      "235/235 [==============================] - 23s 98ms/step - loss: 0.1471 - accuracy: 0.9579 - val_loss: 0.0360 - val_accuracy: 0.9881\n",
      "Epoch 11/40\n",
      "235/235 [==============================] - 23s 99ms/step - loss: 0.1395 - accuracy: 0.9598 - val_loss: 0.0353 - val_accuracy: 0.9890\n",
      "Epoch 12/40\n",
      "235/235 [==============================] - 23s 98ms/step - loss: 0.1347 - accuracy: 0.9606 - val_loss: 0.0334 - val_accuracy: 0.9899\n",
      "Epoch 13/40\n",
      "235/235 [==============================] - 23s 98ms/step - loss: 0.1353 - accuracy: 0.9607 - val_loss: 0.0348 - val_accuracy: 0.9888\n",
      "Epoch 14/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.1282 - accuracy: 0.9631 - val_loss: 0.0356 - val_accuracy: 0.9881\n",
      "Epoch 15/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.1245 - accuracy: 0.9639 - val_loss: 0.0290 - val_accuracy: 0.9912\n",
      "Epoch 16/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.1239 - accuracy: 0.9630 - val_loss: 0.0308 - val_accuracy: 0.9899\n",
      "Epoch 17/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.1180 - accuracy: 0.9658 - val_loss: 0.0287 - val_accuracy: 0.9915\n",
      "Epoch 18/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.1126 - accuracy: 0.9678 - val_loss: 0.0306 - val_accuracy: 0.9900\n",
      "Epoch 19/40\n",
      "235/235 [==============================] - 22s 95ms/step - loss: 0.1140 - accuracy: 0.9664 - val_loss: 0.0298 - val_accuracy: 0.9895\n",
      "Epoch 20/40\n",
      "235/235 [==============================] - 22s 96ms/step - loss: 0.1128 - accuracy: 0.9672 - val_loss: 0.0252 - val_accuracy: 0.9914\n",
      "Epoch 21/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.1088 - accuracy: 0.9685 - val_loss: 0.0265 - val_accuracy: 0.9919\n",
      "Epoch 22/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.1082 - accuracy: 0.9688 - val_loss: 0.0280 - val_accuracy: 0.9909\n",
      "Epoch 23/40\n",
      "235/235 [==============================] - 22s 95ms/step - loss: 0.1037 - accuracy: 0.9694 - val_loss: 0.0266 - val_accuracy: 0.9909\n",
      "Epoch 24/40\n",
      "235/235 [==============================] - 22s 96ms/step - loss: 0.1056 - accuracy: 0.9693 - val_loss: 0.0272 - val_accuracy: 0.9909\n",
      "Epoch 25/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.1018 - accuracy: 0.9707 - val_loss: 0.0252 - val_accuracy: 0.9915\n",
      "Epoch 26/40\n",
      "235/235 [==============================] - 22s 95ms/step - loss: 0.1016 - accuracy: 0.9704 - val_loss: 0.0244 - val_accuracy: 0.9918\n",
      "Epoch 27/40\n",
      "235/235 [==============================] - 22s 94ms/step - loss: 0.1005 - accuracy: 0.9701 - val_loss: 0.0257 - val_accuracy: 0.9915\n",
      "Epoch 28/40\n",
      "235/235 [==============================] - 22s 94ms/step - loss: 0.1004 - accuracy: 0.9715 - val_loss: 0.0246 - val_accuracy: 0.9921\n",
      "Epoch 29/40\n",
      "235/235 [==============================] - 22s 95ms/step - loss: 0.0960 - accuracy: 0.9714 - val_loss: 0.0229 - val_accuracy: 0.9923\n",
      "Epoch 30/40\n",
      "235/235 [==============================] - 22s 94ms/step - loss: 0.0958 - accuracy: 0.9725 - val_loss: 0.0263 - val_accuracy: 0.9913\n",
      "Epoch 31/40\n",
      "235/235 [==============================] - 23s 99ms/step - loss: 0.0966 - accuracy: 0.9725 - val_loss: 0.0233 - val_accuracy: 0.9926\n",
      "Epoch 32/40\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 0.0940 - accuracy: 0.9722 - val_loss: 0.0236 - val_accuracy: 0.9928\n",
      "Epoch 33/40\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 0.0911 - accuracy: 0.9732 - val_loss: 0.0238 - val_accuracy: 0.9918\n",
      "Epoch 34/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.0907 - accuracy: 0.9729 - val_loss: 0.0267 - val_accuracy: 0.9915\n",
      "Epoch 35/40\n",
      "235/235 [==============================] - 23s 98ms/step - loss: 0.0906 - accuracy: 0.9734 - val_loss: 0.0240 - val_accuracy: 0.9923\n",
      "Epoch 36/40\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 0.0901 - accuracy: 0.9731 - val_loss: 0.0232 - val_accuracy: 0.9920\n",
      "Epoch 37/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.0897 - accuracy: 0.9737 - val_loss: 0.0233 - val_accuracy: 0.9921\n",
      "Epoch 38/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.0879 - accuracy: 0.9742 - val_loss: 0.0251 - val_accuracy: 0.9910\n",
      "Epoch 39/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.0873 - accuracy: 0.9742 - val_loss: 0.0230 - val_accuracy: 0.9928\n",
      "Epoch 40/40\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 0.0879 - accuracy: 0.9738 - val_loss: 0.0244 - val_accuracy: 0.9919\n"
     ]
    }
   ],
   "source": [
    "# second train\n",
    "cnn_model2 = cnn()\n",
    "cnn_model2.summary()\n",
    "cnn_model2.compile(\n",
    "    optimizer = optimizers.Adam(0.001),\n",
    "    loss = 'sparse_categorical_crossentropy', \n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "history_train_cnn_model2 = cnn_model2.fit(\n",
    "    X_train, Ytrain, \n",
    "    validation_data=(X_test, Ytest),\n",
    "    epochs = 40, batch_size = 256\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eJwsxSCH2h45",
    "outputId": "381a6a65-dc8f-4d06-b52e-a867b9a15f5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 24, 24, 10)        260       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 20)          5020      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 4, 4, 20)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4, 4, 20)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 50)                16050     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 21,840\n",
      "Trainable params: 21,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "235/235 [==============================] - 23s 98ms/step - loss: 1.0214 - accuracy: 0.6514 - val_loss: 0.1764 - val_accuracy: 0.9500\n",
      "Epoch 2/40\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 0.3669 - accuracy: 0.8897 - val_loss: 0.1046 - val_accuracy: 0.9673\n",
      "Epoch 3/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.2728 - accuracy: 0.9185 - val_loss: 0.0796 - val_accuracy: 0.9749\n",
      "Epoch 4/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.2239 - accuracy: 0.9350 - val_loss: 0.0662 - val_accuracy: 0.9788\n",
      "Epoch 5/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.2023 - accuracy: 0.9406 - val_loss: 0.0596 - val_accuracy: 0.9803\n",
      "Epoch 6/40\n",
      "235/235 [==============================] - 22s 95ms/step - loss: 0.1860 - accuracy: 0.9462 - val_loss: 0.0506 - val_accuracy: 0.9836\n",
      "Epoch 7/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.1684 - accuracy: 0.9510 - val_loss: 0.0459 - val_accuracy: 0.9856\n",
      "Epoch 8/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.1573 - accuracy: 0.9542 - val_loss: 0.0428 - val_accuracy: 0.9869\n",
      "Epoch 9/40\n",
      "235/235 [==============================] - 22s 95ms/step - loss: 0.1494 - accuracy: 0.9560 - val_loss: 0.0403 - val_accuracy: 0.9878\n",
      "Epoch 10/40\n",
      "235/235 [==============================] - 22s 95ms/step - loss: 0.1417 - accuracy: 0.9589 - val_loss: 0.0377 - val_accuracy: 0.9886\n",
      "Epoch 11/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.1394 - accuracy: 0.9599 - val_loss: 0.0365 - val_accuracy: 0.9890\n",
      "Epoch 12/40\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 0.1301 - accuracy: 0.9625 - val_loss: 0.0365 - val_accuracy: 0.9884\n",
      "Epoch 13/40\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 0.1249 - accuracy: 0.9635 - val_loss: 0.0326 - val_accuracy: 0.9897\n",
      "Epoch 14/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.1236 - accuracy: 0.9649 - val_loss: 0.0328 - val_accuracy: 0.9891\n",
      "Epoch 15/40\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 0.1204 - accuracy: 0.9650 - val_loss: 0.0321 - val_accuracy: 0.9900\n",
      "Epoch 16/40\n",
      "235/235 [==============================] - 22s 95ms/step - loss: 0.1150 - accuracy: 0.9671 - val_loss: 0.0313 - val_accuracy: 0.9904\n",
      "Epoch 17/40\n",
      "235/235 [==============================] - 22s 95ms/step - loss: 0.1142 - accuracy: 0.9673 - val_loss: 0.0307 - val_accuracy: 0.9902\n",
      "Epoch 18/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.1101 - accuracy: 0.9677 - val_loss: 0.0303 - val_accuracy: 0.9908\n",
      "Epoch 19/40\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 0.1103 - accuracy: 0.9684 - val_loss: 0.0289 - val_accuracy: 0.9908\n",
      "Epoch 20/40\n",
      "235/235 [==============================] - 23s 99ms/step - loss: 0.1099 - accuracy: 0.9685 - val_loss: 0.0287 - val_accuracy: 0.9917\n",
      "Epoch 21/40\n",
      "235/235 [==============================] - 23s 99ms/step - loss: 0.1040 - accuracy: 0.9696 - val_loss: 0.0286 - val_accuracy: 0.9916\n",
      "Epoch 22/40\n",
      "235/235 [==============================] - 23s 98ms/step - loss: 0.1022 - accuracy: 0.9704 - val_loss: 0.0282 - val_accuracy: 0.9917\n",
      "Epoch 23/40\n",
      "235/235 [==============================] - 23s 98ms/step - loss: 0.1006 - accuracy: 0.9706 - val_loss: 0.0267 - val_accuracy: 0.9919\n",
      "Epoch 24/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.0991 - accuracy: 0.9707 - val_loss: 0.0260 - val_accuracy: 0.9925\n",
      "Epoch 25/40\n",
      "235/235 [==============================] - 23s 97ms/step - loss: 0.0989 - accuracy: 0.9704 - val_loss: 0.0268 - val_accuracy: 0.9924\n",
      "Epoch 26/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.0977 - accuracy: 0.9711 - val_loss: 0.0267 - val_accuracy: 0.9914\n",
      "Epoch 27/40\n",
      "235/235 [==============================] - 23s 96ms/step - loss: 0.0945 - accuracy: 0.9727 - val_loss: 0.0263 - val_accuracy: 0.9919\n",
      "Epoch 28/40\n",
      "235/235 [==============================] - 23s 98ms/step - loss: 0.0932 - accuracy: 0.9721 - val_loss: 0.0282 - val_accuracy: 0.9908\n",
      "Epoch 29/40\n",
      "235/235 [==============================] - 24s 100ms/step - loss: 0.0929 - accuracy: 0.9733 - val_loss: 0.0271 - val_accuracy: 0.9912\n",
      "Epoch 30/40\n",
      "235/235 [==============================] - 24s 101ms/step - loss: 0.0931 - accuracy: 0.9730 - val_loss: 0.0259 - val_accuracy: 0.9918\n",
      "Epoch 31/40\n",
      "235/235 [==============================] - 23s 100ms/step - loss: 0.0938 - accuracy: 0.9725 - val_loss: 0.0256 - val_accuracy: 0.9923\n",
      "Epoch 32/40\n",
      "235/235 [==============================] - 23s 100ms/step - loss: 0.0879 - accuracy: 0.9740 - val_loss: 0.0254 - val_accuracy: 0.9920\n",
      "Epoch 33/40\n",
      "235/235 [==============================] - 24s 102ms/step - loss: 0.0899 - accuracy: 0.9733 - val_loss: 0.0255 - val_accuracy: 0.9916\n",
      "Epoch 34/40\n",
      "235/235 [==============================] - 24s 103ms/step - loss: 0.0857 - accuracy: 0.9739 - val_loss: 0.0240 - val_accuracy: 0.9917\n",
      "Epoch 35/40\n",
      "235/235 [==============================] - 24s 102ms/step - loss: 0.0876 - accuracy: 0.9742 - val_loss: 0.0259 - val_accuracy: 0.9912\n",
      "Epoch 36/40\n",
      "235/235 [==============================] - 24s 103ms/step - loss: 0.0878 - accuracy: 0.9733 - val_loss: 0.0254 - val_accuracy: 0.9922\n",
      "Epoch 37/40\n",
      "235/235 [==============================] - 25s 105ms/step - loss: 0.0857 - accuracy: 0.9750 - val_loss: 0.0253 - val_accuracy: 0.9915\n",
      "Epoch 38/40\n",
      "235/235 [==============================] - 24s 103ms/step - loss: 0.0860 - accuracy: 0.9743 - val_loss: 0.0237 - val_accuracy: 0.9922\n",
      "Epoch 39/40\n",
      "235/235 [==============================] - 24s 101ms/step - loss: 0.0820 - accuracy: 0.9755 - val_loss: 0.0234 - val_accuracy: 0.9931\n",
      "Epoch 40/40\n",
      "235/235 [==============================] - 24s 101ms/step - loss: 0.0849 - accuracy: 0.9750 - val_loss: 0.0254 - val_accuracy: 0.9922\n"
     ]
    }
   ],
   "source": [
    "# third train\n",
    "cnn_model3 = cnn()\n",
    "cnn_model3.summary()\n",
    "cnn_model3.compile(\n",
    "    optimizer = optimizers.Adam(0.001),\n",
    "    loss = 'sparse_categorical_crossentropy', \n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "history_train_cnn_model3 = cnn_model3.fit(\n",
    "    X_train, Ytrain, \n",
    "    validation_data=(X_test, Ytest),\n",
    "    epochs = 40, batch_size = 256\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uV9HdAby2zvF"
   },
   "outputs": [],
   "source": [
    "train_aucy1_cnn = np.array(history_train_cnn_model.history['accuracy']).reshape(-1,1)\n",
    "train_aucy2_cnn = np.array(history_train_cnn_model2.history['accuracy']).reshape(-1,1)\n",
    "train_aucy3_cnn = np.array(history_train_cnn_model3.history['accuracy']).reshape(-1,1)\n",
    "#history_train_cce1.history['val_accuracy']\n",
    "aucy_cnn = np.concatenate((train_aucy1_cnn, train_aucy2_cnn, train_aucy3_cnn), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "-05S6D1Lo1B7",
    "outputId": "a2283645-4e7f-47a1-96c2-116bf76d6ba7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcb8c970860>]"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot for average training accuracy\n",
    "mean_aucy_cnn = np.mean(aucy_cnn, 1)\n",
    "plt.plot(mean_aucy_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "xf3cOmPmo5t1",
    "outputId": "e6881b0d-8b1f-4112-f87f-466717087d34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcb8c92d588>]"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxV1bn/8c+Tk5wMDGEKiExBARVRQSLOVktVtFW0dcC2XrUoHbRae3u9eG2t9da29mer9Wq11qHUVkGpA1osdcAqVYGAILOGSRKRhCmMmZ/fH2cHDslJcjJxouf7fr3OK3uvvfY6a29lP2evtfZe5u6IiIhES0l0BUREpONRcBARkXoUHEREpB4FBxERqUfBQURE6klNdAXaQq9evTw3NzfR1RAR+UxZsGDBZnfPibXtcxEccnNzyc/PT3Q1REQ+U8xsfUPb4mpWMrNxZrbKzArMbHKM7elmNi3YPtfMcoP0nmY228x2mdkDUfm7mNmiqM9mM7sv2Ha1mZVEbbu2uQcsIiKt0+Sdg5mFgAeBs4FCYL6ZzXD35VHZJgLb3H2ImU0A7gYuB8qAnwAjgg8A7r4TGBn1HQuA56LKm+buN7T4qEREpFXiuXMYAxS4+xp3rwCmAuPr5BkPTAmWpwNjzczcfbe7zyESJGIys2FAb+DtZtdeRETaRTzBoR+wIWq9MEiLmcfdq4BSoGecdZhA5E4h+j0eXzOzD8xsupkNiLWTmU0ys3wzyy8pKYnzq0REJB4dYSjrBODpqPWXgFx3PxZ4lf13JAdw90fcPc/d83JyYna2i4hIC8UTHIqA6F/v/YO0mHnMLBXIBrY0VbCZHQekuvuC2jR33+Lu5cHqo8DoOOooIiJtKJ7gMB8YamaDzSxM5Jf+jDp5ZgBXBcuXAG94fK97vYID7xows75RqxcCK+IoR0RE2lCTo5XcvcrMbgBmASHgcXdfZmZ3AvnuPgN4DHjSzAqArUQCCABmtg7oCoTN7CLgnKiRTpcB59f5yhvN7EKgKijr6lYcX6Pmr9vKm6uK+eHZRxBKsfb6GhGRzxz7PMznkJeX5y15CO6Pb63hrpkrWHLHOXTJSGuHmomIdFxmtsDd82Jt6wgd0gmTEQ4BsLeiOsE1ERHpWJI6OGSlRYLDHgUHEZEDJHdwqL1zqFRwEBGJltTBITOsOwcRkViSOzikqc9BRCSWpA4OWeHISN49FVUJromISMeS1MEhU30OIiIxJXVwyNJQVhGRmJI6OGRqKKuISEzJHRzUrCQiElNSB4f01BRSTM1KIiJ1JXVwMDOywqlqVhIRqSOpgwNARlqIvZUayioiEi3pg0NWOKQ7BxGROhQcwiH1OYiI1JH0wSEzHNJoJRGROhQc0tSsJCJSV9IHB/U5iIjUl/TBITOcSpmalUREDpD0wSErLaS3soqI1BFXcDCzcWa2yswKzGxyjO3pZjYt2D7XzHKD9J5mNtvMdpnZA3X2eTMoc1Hw6d1YWe0lU81KIiL1NBkczCwEPAicBwwHrjCz4XWyTQS2ufsQ4F7g7iC9DPgJ8KMGiv+Gu48MPsVNlNUuMjWUVUSknnjuHMYABe6+xt0rgKnA+Dp5xgNTguXpwFgzM3ff7e5ziASJeMUsqxn7N0tWWoiqGqeyuqa9vkJE5DMnnuDQD9gQtV4YpMXM4+5VQCnQM46ynwialH4SFQBaWlaLaB5pEZH6Etkh/Q13PwY4Pfhc2ZydzWySmeWbWX5JSUmLK5GpCX9EROqJJzgUAQOi1vsHaTHzmFkqkA1saaxQdy8K/u4EniLSfBV3We7+iLvnuXteTk5OHIcRW5bmdBARqSee4DAfGGpmg80sDEwAZtTJMwO4Kli+BHjD3b2hAs0s1cx6BctpwFeApS0pq7Uy01IBNJxVRCRKalMZ3L3KzG4AZgEh4HF3X2ZmdwL57j4DeAx40swKgK1EAggAZrYO6AqEzewi4BxgPTArCAwh4DXgj8EuDZbVHjSPtIhIfU0GBwB3nwnMrJN2e9RyGXBpA/vmNlDs6AbyN1hWe1CHtIhIfUn/hHRmmvocRETqSvrgoGYlEZH6FBzCtR3SCg4iIrWSPjjUNitptJKIyH4KDkGzkl7bLSKyX9IHh3BqCqkppmYlEZEoSR8cQK/tFhGpS8GBSL+DRiuJiOyn4EBkOKuecxAR2U/Bgcg80mpWEhHZT8GB2jsHDWUVEaml4ECkz0F3DiIi+yk4oHmkRUTqUnBAHdIiInUpOBAJDmpWEhHZT8EByNBzDiIiB1BwYH+zUjvORioi8pmi4EDktd3VNU5FdU2iqyIi0iEoOBA1G5yalkREAAUHQPNIi4jUFVdwMLNxZrbKzArMbHKM7elmNi3YPtfMcoP0nmY228x2mdkDUfmzzOzvZrbSzJaZ2a+itl1tZiVmtij4XNv6w2zcvqlCNZxVRASIIziYWQh4EDgPGA5cYWbD62SbCGxz9yHAvcDdQXoZ8BPgRzGKvsfdjwRGAaea2XlR26a5+8jg82izjqgF1KwkInKgeO4cxgAF7r7G3SuAqcD4OnnGA1OC5enAWDMzd9/t7nOIBIl93H2Pu88OliuAhUD/VhxHq2geaRGRA8UTHPoBG6LWC4O0mHncvQooBXrGUwEz6wZcALwelfw1M/vAzKab2YB4ymmNzHDkNGgeaRGRiIR2SJtZKvA0cL+7rwmSXwJy3f1Y4FX235HU3XeSmeWbWX5JSUmr6pGZFrlz0DzSIiIR8QSHIiD613v/IC1mnuCCnw1siaPsR4CP3P2+2gR33+Lu5cHqo8DoWDu6+yPunufueTk5OXF8VcOyNFpJROQA8QSH+cBQMxtsZmFgAjCjTp4ZwFXB8iXAG97E48Zm9nMiQeQHddL7Rq1eCKyIo46touAgInKg1KYyuHuVmd0AzAJCwOPuvszM7gTy3X0G8BjwpJkVAFuJBBAAzGwd0BUIm9lFwDnADuA2YCWw0MwAHghGJt1oZhcCVUFZV7fRsTYoI6zRSiIi0ZoMDgDuPhOYWSft9qjlMuDSBvbNbaBYayD/rcCt8dSrrWSl6TkHEZFoekIaSA2lEA6lqFlJRCSg4BCIzAanoawiIqDgsI/mkRYR2U/BIaCpQkVE9lNwCESalRQcRERAwWEfzSMtIrKfgkMgIy3EHjUriYgACg77ZIVDlOnOQUQEUHDYJyucyp5KDWUVEQEFh33UIS0isp+CQ0DPOYiI7KfgEKh9zqGJl8mKiCQFBYdAZjiEO5RX1SS6KiIiCafgEKh9M6ualkREFBz2ydw34Y9GLImIKDgEMsOaR1pEpJaCQ0DNSiIi+yk4BDSPtIjIfgoOAc0jLSKyn4JDoPbOQXM6iIgoOOyTlRbpkFazkohInMHBzMaZ2SozKzCzyTG2p5vZtGD7XDPLDdJ7mtlsM9tlZg/U2We0mS0J9rnfzCxI72Fmr5rZR8Hf7q0/zKZl7mtW0lBWEZEmg4OZhYAHgfOA4cAVZja8TraJwDZ3HwLcC9wdpJcBPwF+FKPoh4DrgKHBZ1yQPhl43d2HAq8H6+0uUx3SIiL7xHPnMAYocPc17l4BTAXG18kzHpgSLE8HxpqZuftud59DJEjsY2Z9ga7u/p5HXmb0Z+CiGGVNiUpvV5lp6nMQEakVT3DoB2yIWi8M0mLmcfcqoBTo2USZhQ2U2cfdNwbLnwJ9YhVgZpPMLN/M8ktKSuI4jMaFUoz01BSNVhIRoYN3SAd3FTFfk+ruj7h7nrvn5eTktMn3aR5pEZGIeIJDETAgar1/kBYzj5mlAtnAlibK7N9AmZuCZqfa5qfiOOrYJjSng4hIRDzBYT4w1MwGm1kYmADMqJNnBnBVsHwJ8IY3MjFC0Gy0w8xOCkYp/QfwYoyyropKb3eZ4ZDerSQiAqQ2lcHdq8zsBmAWEAIed/dlZnYnkO/uM4DHgCfNrADYSiSAAGBm64CuQNjMLgLOcfflwPeAPwGZwCvBB+BXwDNmNhFYD1zWFgcaj6xwqt7KKiJCHMEBwN1nAjPrpN0etVwGXNrAvrkNpOcDI2KkbwHGxlOvtpapPgcREaCDd0gfbJlpIQ1lFRFBweEAWeGQhrKKiKDgcAA1K4mIRCg4RMkKq1lJRAQUHA4Qec5Bo5VERBQcomSGUymrrKGmpsFHNEREkoKCQ5TaCX/KqtS0JCLJTcEhiuaRFhGJUHCIkpGmeaRFREDB4QCaR1pEJELBIYqalUREIhQcomSmRV41peGsIpLsFByi1M4jrT4HEUl2Cg5R1OcgIhKh4BAlM019DiIioOBwgCw1K4mIAAoOB8jUaCUREUDB4QAZqepzEBEBBYcDpKRYZDY4DWUVkSSn4FBHlib8ERGJLziY2TgzW2VmBWY2Ocb2dDObFmyfa2a5UdtuDdJXmdm5QdoRZrYo6rPDzH4QbLvDzIqitp3fNocan4w0TRUqIpLaVAYzCwEPAmcDhcB8M5vh7sujsk0Etrn7EDObANwNXG5mw4EJwNHAocBrZjbM3VcBI6PKLwKejyrvXne/p/WH13yaDU5EJL47hzFAgbuvcfcKYCowvk6e8cCUYHk6MNbMLEif6u7l7r4WKAjKizYWWO3u61t6EG1JzUoiIvEFh37Ahqj1wiAtZh53rwJKgZ5x7jsBeLpO2g1m9oGZPW5m3WNVyswmmVm+meWXlJTEcRjxyQyrWUlEJKEd0mYWBi4Eno1Kfgg4nEiz00bgN7H2dfdH3D3P3fNycnLarE6ZaSH2VGq0kogkt3iCQxEwIGq9f5AWM4+ZpQLZwJY49j0PWOjum2oT3H2Tu1e7ew3wR+o3Q7WrrHCq7hxEJOnFExzmA0PNbHDwS38CMKNOnhnAVcHyJcAb7u5B+oRgNNNgYCgwL2q/K6jTpGRmfaNWLwaWxnswbUHNSiIicYxWcvcqM7sBmAWEgMfdfZmZ3Qnku/sM4DHgSTMrALYSCSAE+Z4BlgNVwPXuXg1gZp2IjID6dp2v/LWZjQQcWBdje7vKCofYo9FKIpLkmgwOAO4+E5hZJ+32qOUy4NIG9r0LuCtG+m4indZ106+Mp07tJTNNo5VERPSEdB2Z4RAVVTVU13iiqyIikjAKDnVowh8REQWHejLDmkdaRETBoY7a2eA0YklEkpmCQx1qVhIRUXCoR7PBiYgoONSTpWYlEREFh7p05yAiouBQj/ocREQUHOqpHcqqeaRFJJkpONRR2+egZiURSWYKDnWoz0FERMGhnvTUFMygTH0OIpLEFBzqMDOy9GZWEUlyCg4xZIZTFRxEJKkpOMSQGU7RaCURSWoKDjFkpaXqOQcRSWoKDjFkhtXnICLJTcEhhqxwSO9WEpGkpuAQg+aRFpFkF1dwMLNxZrbKzArMbHKM7elmNi3YPtfMcqO23RqkrzKzc6PS15nZEjNbZGb5Uek9zOxVM/so+Nu9dYfYfJnhkJ5zEJGk1mRwMLMQ8CBwHjAcuMLMhtfJNhHY5u5DgHuBu4N9hwMTgKOBccDvg/JqneXuI909LyptMvC6uw8FXg/WD6os9TmISJKL585hDFDg7mvcvQKYCoyvk2c8MCVYng6MNTML0qe6e7m7rwUKgvIaE13WFOCiOOrYprLCqZpDWkSSWjzBoR+wIWq9MEiLmcfdq4BSoGcT+zrwTzNbYGaTovL0cfeNwfKnQJ9YlTKzSWaWb2b5JSUlcRxG/DLSQhrKKiJJLZEd0qe5+/FEmquuN7Mz6mZwdycSROpx90fcPc/d83Jyctq0YlnhEJXVTmV1TZuWKyLyWRFPcCgCBkSt9w/SYuYxs1QgG9jS2L7uXvu3GHie/c1Nm8ysb1BWX6A4/sNpG5rwR0SSXTzBYT4w1MwGm1mYSAfzjDp5ZgBXBcuXAG8Ev/pnABOC0UyDgaHAPDPrZGZdAMysE3AOsDRGWVcBL7bs0Fqu9rXdetZBRJJValMZ3L3KzG4AZgEh4HF3X2ZmdwL57j4DeAx40swKgK1EAghBvmeA5UAVcL27V5tZH+D5SJ81qcBT7v6P4Ct/BTxjZhOB9cBlbXi8ccnUhD8ikuSaDA4A7j4TmFkn7fao5TLg0gb2vQu4q07aGuC4BvJvAcbGU6/2kqU7BxFJcnpCOoZ980hXajiriCQnBYcYsjRVqIgkOQWHGNTnICLJTsEhhtrRSnq/kogkKwWHGNSsJCLJTsEhhqy0SIe0goOIJCsFhxgywpHTonmkRSRZKTjEEA6lEEoxvT5DRJKWgkMMZkaWZoMTkSSm4NCATM0jLSJJTMGhAZlhzekgIslLwaEBmWpWEpEkpuDQgCw1K4lIElNwaIDmkRaRZKbg0IDIPNKaJlREkpOCQwMizUq6cxCR5KTg0ICssDqkRSR5KTg0QM85iEgyU3BoQGaannMQkeSl4NCArHCIqhqnokqd0iKSfOIKDmY2zsxWmVmBmU2OsT3dzKYF2+eaWW7UtluD9FVmdm6QNsDMZpvZcjNbZmY3ReW/w8yKzGxR8Dm/9YfZfPvmkVbTkogkodSmMphZCHgQOBsoBOab2Qx3Xx6VbSKwzd2HmNkE4G7gcjMbDkwAjgYOBV4zs2FAFfCf7r7QzLoAC8zs1agy73X3e9rqIFti34Q/lVVkk5bIqoiIHHTx3DmMAQrcfY27VwBTgfF18owHpgTL04GxZmZB+lR3L3f3tUABMMbdN7r7QgB33wmsAPq1/nDaTu080rpzEJFkFE9w6AdsiFovpP6FfF8ed68CSoGe8ewbNEGNAuZGJd9gZh+Y2eNm1j1Wpcxskpnlm1l+SUlJHIfRPJltMFVoeVU17t5WVRIROWgS2iFtZp2BvwE/cPcdQfJDwOHASGAj8JtY+7r7I+6e5+55OTk5bV632mallo5Y2r6nghN+/hqPvLWmLaslInJQxBMcioABUev9g7SYecwsFcgGtjS2r5mlEQkMf3X352ozuPsmd6929xrgj0SatQ66rFbeOby46BN2lFXxu9c/YtOOsrasmohIu4snOMwHhprZYDMLE+lgnlEnzwzgqmD5EuANj7SnzAAmBKOZBgNDgXlBf8RjwAp3/210QWbWN2r1YmBpcw+qLWS0ss/h2QUbGNgji6pq5+5/rGzLqomItLsmg0PQh3ADMItIx/Ez7r7MzO40swuDbI8BPc2sAPghMDnYdxnwDLAc+AdwvbtXA6cCVwJfjDFk9ddmtsTMPgDOAm5uq4NtjqzaoayVzX+/0oqNO1hatINrTs3lW6cN5rmFRSzesL2tqygi0m6aHMoK4O4zgZl10m6PWi4DLm1g37uAu+qkzQGsgfxXxlOn9taaZqXpCwpJCxnjR/YjLWRMX1DInS8vZ/p3TiZy0yQi0rHpCekG1I5Wam6zUmV1DS+8X8SXjupDj05humSk8V/nDmPB+m3MWPxJe1RVRKTNKTg0oKXPObyxspgtuyu4NK//vrRLRg/g6EO78qtXVuq5CRH5TFBwaEBaKIW0kLGnmUNZn80vpHeXdM4Yun94bSjF+OkFR7OxtExDW9vZ6pJd/Pzl5ZTppYkiraLg0IjMtOa9trtkZzmzVxVz8fH9SA0deGrHDO7Bl4/py8P/Ws3G0r1tXVUB3J3/eW4Jj85ZywNvFCS6OiKfaQoOjWjuPNIvvF9EdY1z6egBMbdPPu9Iqt25+xUNbW0Pb6wsZu7arfTrlskf3lpNQfHORFdJ5DNLwaERmeH455F2d55dsIFRA7sxpHfnmHkG9Mhi0umH8cKiT1j48ba2rGrSq6qu4ZevrOSwXp147nunkBVO5X+eX6rXl4i0kIJDIyLNSvHdOXxQWMqHm3Y1eNdQ67tnHk7vLunc+dJyamoSd+FaXbKL8qqD3y7/aWkZN019n2/9aT5/eW89n5a2zdPjzy4opKB4F7eMO5I+XTO49bwjmbd2K9MXFLZJ+SLJRsGhEc2ZR/rZBRvISEvhK8f1bTRfp/RUbhl3JIs2bOfFxXXfQtL+1m3ezbefzGfsb/7Ffzw2r1nNZq3h7kyd9zFn//ZfzFr2KQXFu/jxC0s56Zevc8H/zeG+1z5kaVFpi37p7y6v4revfkjeoO6ce3QfAC7LG0DeoO78YuYKtu2uaOvDaZY9FVW8uKiIq5+Yx1n3vMk7qzcntD4i8YjrIbhklRkOsbOs6YtnWWU1MxZ9wrijD6FrRtNzP3x1VD+efHcdv3plJcP7ZnPEIV3aoLaN276ngvtfL+DJ99aRFkrhsrz+TF9QyNVPzOeJq0+gU3r7/a+wYeseJj/3Af8u2MJJh/Xg7q8dy8AeWRQU7+K1FcW8tmITv3v9I+577SP6Zmcw9qjefPuMwxnQIyuu8h99ey0lO8t5+Juj9z1kmJJi/PziEXzl/jn88pUV/PqS49rt+GKprnHeWb2Z598vYtbST9ldUU2/bpmkhoyrH5/PfRNGcv4xjf+QEEkkBYdGZKaF2LB1D1XVNfVGH0X75/JN7Cir4tK8xpuUaqWkGHdceDQTHnmPc+97ixH9uvK14/tz4XGH0rNzeltVH4CKqhr+8t56fvf6R+wsq+TyEwZw89nD6N0lg1OH9OLmaYu45on5PHFN2weImhrnz++u4+5/rCKUYtx18QiuOGEgKSmRC/jQPl0Y2qcL3z3zcDbvKmf2ykigmL6gkNdXFPPMt09uMkAU7yzjD2+t5vxjDmH0oAPf7n7kIV2ZePpg/vCvNVwyegBjBvdo1fFUVtfws5eWUbhtL92zwnTPCtOjUxrdO4X3raeGjH8u+5QXF31C8c5yumSkcsFxh3LxqH6ckNuDHWWVXDsln+ufWsidFx7NlSfntqpOB8vv3yzgzZUlPPCNUfTukpHo6shBYJ+HDru8vDzPz89v83L/9O+13PHSck4d0pP7J4xq8MJ95WNzWVOym7dvOWvfhS8em3eV89LiT/jbwkKWFu0gNcU484jefO34fnzxqN6kp4YOyF9T42zfW8nmXeVs3llOWVU1ndPT6JKRSuf01H1/U0MpuDv/XL6JX85cwbotezh9aC9u+/JRHHlI1wPKnLH4E34w9X3yBvVo0wCxpmQXt0z/gPz12/jCsBx+8dVj6NctM659l3+yg68/+h6dwqk8852TG93vtueXMG3+Bl794RcY3KtTve17Kqo4+7dvkRUO8fcbTyec2vKW1Ptf/4jfvvohw/t2ZWd5Jdt2V7KrvP6dZVoo8t/xq6P6cdaRvfe9xLHW3opqvv/0Ql5bUcyNXxzCzWcP69CvVZk672MmP7cEgKG9O/PUdSeR06Vtf8RIYpjZAnfPi7lNwaFxz+Rv4McvLCWnczoPffN4ju3f7YDtn2zfy6l3v8H3vziUH549rMXfs+rTnTy3sJDn3y+ieGc52ZlpnDakF7vKqyLBYFc5W3ZVUBVHJ3ZmWoiMtBS27alkSO/O3PblozhzWE6DF6CXFn/CD6Yt4viB3XjimjF0bkWA2FtRzR/fXsODswtIT03h9guO5mvH92v2xW9pUSlf/+N7dMsK88y3T+aQ7Pq/VguKd3HufW/xzRMH8rPxIxos6/UVm5g4JZ9bxh3B984c0uxjAlj2SSnjH/g35x/Tl/uvGLUvvbyqmu17Ktm6u4JteyrYVVbFCbk96N4p3Gh5VdU13Pb8Uqblb+CKMQP43/EjGr07TZQ3VxUzcUo+pw7pxaTTD+O6P+czoEcmT113Er3a+C5XDj4Fh1ZaUljKd/6ygJJd5fx8/AguO2F/89EDb3zEPf/8kLdvOSvuNvLGVNc4cwo289zCQhZ+vI3uWWF6dU6nV+fav+n06hJZz0gLsbu8il1lVewM/u4qj3x2llVxbP9sLh3dP66LzssffMJNUxcxakA3/vSt5geImhrnhUVF/L9Zq9hYWsb5xxzCHRccTe+uLW+CWLRhO998dC69u6QzddJJ9cq67s/5vLt6C//6rzObbI77zpMLePPDYl69+QvN/u9UUVXDhQ/MYcvuCl69+Qy6ZTV+4Y+Xu/Obf37IA7MLOGd4H+6/YlS9u4ytuyt4d/UW3lm9mXfXbCE7M41vnTqY80Yc0u7BZGlRKZf/4V0G9ezEM985mc7pqbyzejPf+tN8BvXoxFPXndjmzaBycCk4tIGtuyv4/tML+XfBFr5+4kB+esFwwqEUzrrnTQ7JzmDqpJPb9fsPhr9/sJEbp77f7AAxd80Wfv73FSwpKuWYftn8+MtHceJhPdukTgvWb+XKx+ZxaLdMpk7a/2t13tqtXPaHd/mvc4/g+rOavhvYWLqXL/3mX5wwuAdPXH1Cs+5k7pm1igdmF/DYVXmMPapPi4+lIVPeWccdLy3jhEE9+N0VI1m5cSfvrN7Mvwu2sHxjZILETuEQYwb3YN2WPazdvJt+3TKZeNpgLjthQKvu9BpStH0vFz/4b1JTjOevP5U+UYH53wWRADG4Vyeeuu4kejRyl1RWWc20+Rt45K01lFfVMLBHJoN6dmJgjywG9cxiYI8sBvbMIqdzeoub1h56czV/eW89XTJS6ZaVRvesMN1q+4OC5ezMNDqlh+iSHvnbOT2VzhmpZKaFOnSTXntTcGgjVdU13PPPD3n4X6sZOaAb3zptMDc+/T6/ufQ4vja6f9MFfAbMXLKR7z/9Psf2z+bqU3LJ7dmJ3F6dyM6sPwpr3ebd/PKVFcxatom+2RncMu4Ixh/Xr1n9LvGYu2YLVz0xj9yekYtR96w0Lvr9O2wqLWP2j87c9wbdpjw2Zy3/+/Jyfv+N4+MeKbR4w3a++tA7XDyqH/dc2n4jnl7+4BN+OG0xFdWRhy7DoRRGD+rOKYf35JQhvTi2fzZpoRRqapzXVmzij2+vYf66bXTJSOUbJw7i6lNyYza9tUTp3kouffgdNpaW8bfvnsKwPvVH0835aDMTp8znsJzOPHXtifWa0cqrqnkmv5AH3yjg0x1lnJDbncN6dWb91t18vGUPG3eUEX3p6ZKeym1fPooJYwY2q64Pvbmau/+xkhMH9yA7M43teyrZtqci+FRS3UQzbIpFhpd/YVgOPzrnCHJj9Fu1Vk2Nt/m/ibai4NDGXlmykR89u5jdFdV0Tk9l3m1j900O9HnwypKN3PzMIsqing7v0SlMbs8scnt1YnDPTmzZXcFf564nLZTCd79wONeefljcF+mWqP21enhOZ75x0v5FxgYAAAxySURBVEBue34pv77kWC6Lc4QYRIL7+Af/TeG2vdw3YSRnHdG70fxlldV85f/msLu8ilk3nxHXMOXWWLB+G3M+2szoQd3Jy+1er4mprvc/3sajb6/llaUbCaUYFxx3KN/9wuEMjXExj1d5VTVXPT6PBeu3MeWaMZwypFeDed/6sIRr/5zPkJzOPHXdiXTLClNRVcP0BYU88MZHfFJaxuhB3fnh2cM45fCeB/xCL6uspmj7Xj7esof1W3bzj2Wf8t6arfzonGFcf9aQuH7NPz5nLXe+vJwLjzuUey8fSajOBdjd2VlexbbdFezYG2lu3V2+v+m1dnnzrgpeXFRERVUNV4wZyI1jh7ZJh3vR9r385IWlLPx4G7eceyQTThjQ7CCxaMN2Nm7fSzg1JfIJpexbTk9NIRwK0aNzuMV3jwoO7aCgeCc3TV3EGcNy+O9xRx7U7z4Yyiqr+XhrpAlj3ebdrNuyO1jew6c7ykixyINmPzx7WKv6FZrjzVXFTPrzAiqqazjykC78/cbT610QmrJ+y26+/eQCVn66k++eeTj/efawBtvufzFzBY+8tYY/f2sMZwzLiZmnI9iwdQ+PzVnLM/kb2FtZzYXHHcpNY4dyWE7s17g0xN25edoiXlj0CfdefhwXj2r6brj2v8nQPp25YsxAHnpzNUXb9zJqYDdu/tIwTh/aK64LfWV1DbdM/4Dn3y/iqpMH8dMLjm70QvrU3I/5n+eXMO7oQ/i/r48irZX9L8U7y/i/1wt4et7HhFNTuO70w7jujMNadNGtrnGefHcdv561CncY1qcziwtLOX5gN+66+BiO6tu1yTKWFJby61krefujph+Y/N+LRnDlSYOaXU9QcJA2tqeiirLKmkbbmtvL6ys2cetzS7jv8pGN/qptTFllNT97aRlPz9vAmNwe3H/FqHpNMvPXRfo0vj5mIHddfExbVL3dbd1dwSNvrWHKO+sor6rm4lH9uXHsEAb1jK+ppLZvJd5+nFqzVxbz7ScjQfu4/tn84OxhjY6Oa0hNjfOLmSt4dM5avnJsX35z2XH1hnNDZKbF/5q+mLOO6M3D3xzdquHJda3dvJt7Zq3i70s20rNTmBvHDuWKMQPj/o4PN+3kv//2Ae9/vJ0zhuVw10Uj6N89k78tLOIXM1dQureSiacN5qaxQ2MOGy8o3sVvX13FzCWf0j0rjevPGsKpQ3pRUVVDRXVN5G9VDeVR66MGduPwZv4QqKXgIJ8r7t4mnYgvvF/E/zy/hIy0EPdePpIvBHcHeyqqOO93b1Pjzj9uOqNdnx5vD5t3lfPwm6t58r31VNU4l47uzw1fHEL/7vtHae0sq2Rp0Q6WFpWypKiUpUWlrNm8myvGDOAXFx/T7PO78ONt7Cyr4ow47xQa4u784a01/OqVlZw2pBcPXzn6gF/vLy3+hJumvs8ph/fi0avymmx6a6lFG7bzy5krmLt2KwN7ZHHeiEMYOaAbxw3oRt/sjHrHWF5VzYOzV/PQmwV0Tk/lpxcczfiRhx6Qb9vuCu7+x0qmzt/AodkZ/Gz8CM4eHhngULR9L7977UOmLygkMy3EtacfxrWnD6ZLOzdlKjiINKCgeBfX/3UhHxbv5Pozh/CDLw3lf19ezpR31zN10kmc1EajrhKheEcZv39zNU/N/RjHGT+yHxVVNfsCQa2+2RmM6JfNmNweXHNqbod43uLZ/A1Mfm4Jw/t25YlrTqBX53RmLfuU7/11IaMHdedP15zQ7v187s6bH5bw+9kFLN5Qum+wQO8u6fsCxagBkeeebp+xjILiXVw8qh8//vJRjQ7xnb9uK7c9v4QPN+3i7OF9GNA9i7/MXQ8O3zxpENefdfhBGyLc6uBgZuOA3wEh4FF3/1Wd7enAn4HRwBbgcndfF2y7FZgIVAM3uvusxso0s8HAVKAnsAC40t0bfXOagoO0xt6Kau6YsYxp+RsY0a8rS4t2cM2pufz0gqMTXbU2sbF0Lw/OLmDa/A306pzOiH7ZHNsvmxH9szmmX3aHfZjt9RWbuP6phfTNzmTSGYdx+4tLGdEvmycnntguw3cbU15VzYqNO1n08TYWF5ayaMN21kYF2H7dMrnr4hGc2cQgh1qV1TU8Nmct9732IRVVNVwyuj83fWlY3G8RaCutCg5mFgI+BM4GCoH5wBXuvjwqz/eAY939O2Y2AbjY3S83s+HA08AY4FDgNaD2MeKYZZrZM8Bz7j7VzB4GFrv7Q43VUcFB2sLfFhTy4xeW0jc7g7/feHq7jr5KhOoab3YHfqItWL+Va56Yz46yKkb068pfrz0p5rDqRNi+p4LFhaV8WrqXrxx7aIuaH0t2llNRXXPQg0Kt1gaHk4E73P3cYP1WAHf/ZVSeWUGed80sFfgUyAEmR+etzRfsVq9M4FdACXCIu1fV/e6GKDhIW9m0o4y0UEpCOtsltg837eTpeR9z4xeHNvlaEmmexoJDPI2L/YANUeuFQVrMPO5eBZQSaRZqaN+G0nsC24MyGvouAMxskpnlm1l+SUlJHIch0rQ+XTMUGDqYYX268NMLjlZgOMgS3/PUQu7+iLvnuXteTk7HHYMuIvJZFE9wKAKiH0PtH6TFzBM0K2UT6ZhuaN+G0rcA3YIyGvouERFpZ/EEh/nAUDMbbGZhYAIwo06eGcBVwfIlwBse6cyYAUwws/RgFNJQYF5DZQb7zA7KICjzxZYfnoiItEST3etBx/ANwCwiw04fd/dlZnYnkO/uM4DHgCfNrADYSuRiT5DvGWA5UAVc7+7VALHKDL7yv4GpZvZz4P2gbBEROYj0EJyISJJq7WglERFJMgoOIiJSj4KDiIjU87noczCzEmB9C3fvBTT90vTEUN1aRnVrGdWtZT7LdRvk7jEfFPtcBIfWMLP8hjpkEk11axnVrWVUt5b5vNZNzUoiIlKPgoOIiNSj4ACPJLoCjVDdWkZ1axnVrWU+l3VL+j4HERGpT3cOIiJSj4KDiIjUk9TBwczGmdkqMysws8mJrk80M1tnZkvMbJGZJfTFUWb2uJkVm9nSqLQeZvaqmX0U/O3egep2h5kVBedukZmdn6C6DTCz2Wa23MyWmdlNQXrCz10jdUv4uTOzDDObZ2aLg7r9LEgfbGZzg3+v04I3OneUuv3JzNZGnbeRB7tuUXUMmdn7ZvZysN6y8+buSfkh8jbY1cBhQBhYDAxPdL2i6rcO6JXoegR1OQM4HlgalfZrYHKwPBm4uwPV7Q7gRx3gvPUFjg+WuxCZN314Rzh3jdQt4ecOMKBzsJwGzAVOAp4BJgTpDwPf7UB1+xNwSaL/nwvq9UPgKeDlYL1F5y2Z7xzGAAXuvsbdK4CpwPgE16lDcve3iLyKPdp4YEqwPAW46KBWKtBA3ToEd9/o7guD5Z3ACiLT3ib83DVSt4TziF3BalrwceCLwPQgPVHnraG6dQhm1h/4MvBosG608Lwlc3CIZ27sRHLgn2a2wMwmJboyMfRx943B8qdAn0RWJoYbzOyDoNkpIU1e0cwsFxhF5Jdmhzp3deoGHeDcBU0ji4Bi4FUid/lxzS9/sOvm7rXn7a7gvN1rZumJqBtwH3ALUBOs96SF5y2Zg0NHd5q7Hw+cB1xvZmckukIN8cj9aof59QQ8BBwOjAQ2Ar9JZGXMrDPwN+AH7r4jeluiz12MunWIc+fu1e4+kshUwWOAIxNRj1jq1s3MRgC3EqnjCUAPIpOWHVRm9hWg2N0XtEV5yRwc4pkbO2HcvSj4Www8T+QfSEeyycz6AgR/ixNcn33cfVPwD7gG+CMJPHdmlkbk4vtXd38uSO4Q5y5W3TrSuQvqs53I1MEn08Hml4+q27igmc7dvRx4gsSct1OBC81sHZFm8i8Cv6OF5y2Zg0M8c2MnhJl1MrMutcvAOcDSxvc66KLnDe9Qc33XXngDF5Ogcxe09z4GrHD330ZtSvi5a6huHeHcmVmOmXULljOBs4n0iSR8fvkG6rYyKtgbkTb9g37e3P1Wd+/v7rlErmdvuPs3aOl5S3TPeiI/wPlERmmsBm5LdH2i6nUYkdFTi4Flia4b8DSRJoZKIm2WE4m0Zb4OfAS8BvToQHV7ElgCfEDkQtw3QXU7jUiT0QfAouBzfkc4d43ULeHnDjiWyPzxHxC5yN4epB8GzAMKgGeB9A5UtzeC87YU+AvBiKZEfYAz2T9aqUXnTa/PEBGRepK5WUlERBqg4CAiIvUoOIiISD0KDiIiUo+Cg4iI1KPgICIi9Sg4iIhIPf8ftOz5fYB7dKYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot for std training accuracy\n",
    "std_aucy_cnn = np.std(aucy_cnn, 1)\n",
    "plt.plot(std_aucy_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "48LOrIbDo53S"
   },
   "outputs": [],
   "source": [
    "test_aucy1_cnn = np.array(history_train_cnn_model.history['val_accuracy']).reshape(-1,1)\n",
    "test_aucy2_cnn = np.array(history_train_cnn_model2.history['val_accuracy']).reshape(-1,1)\n",
    "test_aucy3_cnn = np.array(history_train_cnn_model3.history['val_accuracy']).reshape(-1,1)\n",
    "aucy_test_cnn = np.concatenate((test_aucy1_cnn, test_aucy2_cnn, test_aucy3_cnn), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "izrqB7ztpbEj",
    "outputId": "203da4fe-d632-475f-addc-3ef5e8cf2319"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcb799e4c50>]"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot for average testing accuracy\n",
    "mean_aucy_test_cnn = np.mean(aucy_test_cnn, 1)\n",
    "plt.plot(mean_aucy_test_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "3CF-LHxIpbG5",
    "outputId": "90bd0971-aa44-4a54-9ba8-da00bf23f9ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcb799c4518>]"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "std_aucy_test_cnn = np.std(aucy_test_cnn, 1)\n",
    "plt.plot(std_aucy_test_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 953
    },
    "id": "-DpHg1tpqkJx",
    "outputId": "d8496082-8372-4395-e753-41845d48e114"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.plot_model(cnn_model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hpv-Mqhttk-e",
    "outputId": "a0927ddc-6321-4a3c-dc23-d11433d9690c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 24, 24, 10)        260       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 20)          5020      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 4, 4, 20)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4, 4, 20)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 50)                16050     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 21,840\n",
      "Trainable params: 21,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYiQUfi5tdZb"
   },
   "source": [
    "batch size:256\n",
    "\n",
    "optimizer:adam\n",
    "\n",
    "learning rate:0.001"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW5",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
